---
layout: post
title: the (old) density of Height-Balanced Histograms
date: 
type: post
parent_id: '0'
published: false
password: ''
status: draft
categories: []
tags: []
meta: {}
author:
  login: alberto.dellera
  email: alberto.dellera@gmail.com
  display_name: Alberto Dell'Era
  first_name: Alberto
  last_name: Dell'Era
permalink: "/"
---
<p>In this and in the next post we are going to explore the formula used by dbms_stats to compute the "density" column statistic, and especially we are going to show and discuss the <b>rationale</b> for it. We will rehash also how density is used by the CBO to estimate the cardinality of a simple equality filter predicate. We will consider, for simplicity, only the (most complex) case of Height-Balanced histograms, filtered value inside the min-max interval of the filter column, and not-null values.</p>
<p>In this post we will discuss the pre-10.2.0.4 behaviour; in the next post we will discuss the 10.2.0.4 (and 11g) behaviour, that is, the new "NewDensity" computation that supersedes the previous one, relabeled as "OldDensity" (both the "NewDensity" and "OldDensity" names can be considered somewhat "official", sice they are used in 11g 10053 trace files).</p>
<p>So, we are going to consider a simple filter predicate on table t ("value" is the column name, "client_value" a client-provided literal):<br />
[sql]<br />
select ...<br />
  from t<br />
 where value = <client_value>;<br />
[/sql]<br />
as a test case, we will consider the one contained in script TODO (a zip file that contains both the script and its log), run in 9.2.0.8. This test case builds the following distribution for value:<br />
[sql]<br />
SQL> select value, count(*)<br />
  2    from t<br />
  3   group by value<br />
  4   order by value;</p>
<p>     VALUE   COUNT(*)<br />
---------- ----------<br />
         1          1<br />
         2          2<br />
         4          4<br />
         8          8<br />
        16         16<br />
        64         64<br />
[/sql]<br />
And then computes a SIZE 5 Height-Balanced histogram. The resulting histogram from dba_histograms is as follows (note that I have added the column POPULARITY that marks popular values with "1"; EP is short for column ENDPOINT_NUMBER, VALUE is column ENDPOINT_VALUE):<br />
[sql]<br />
SQL> select ep, value, popularity from formatted_hist;</p>
<p>        EP      VALUE POPULARITY<br />
---------- ---------- ----------<br />
         0          1          0<br />
         1         16          0<br />
         5         64          1<br />
[/sql]<br />
As it is well known, when client_value is a popular value (i.e. 64 in this case), density is not used for the expected cardinality estimation. When client_value is not popular (that is, either equal to a nonpopular value - 1 and 16 in this case - or not contained in the histograms - 2.4 for example) but contained in the closed min-max interval (1-64 in this case), the formula used for the expected cardinality estimation is equal to (Note: I'm going to use the conventions defined in this previous TODO post, that I'm going to reference a lot in the following):<br />
[text]<br />
E[count(client_value)] = density * num_rows<br />
[/text]<br />
in our case, since from the script log we see that density = .115789474 and num_rows=95, we get density * num_rows=11 (note the perfectly integer value).</p>
<p>The formula used by dbms_stats was published in Jonathan Lewis' book <a href="http://www.jlcomp.demon.co.uk/cbo_book/ind_book.html">Cost Based Oracle</a> (page 172) and Wolfgang Breitling's presentation <a href="http://www.centrexcc.com/">Histograms - Myths and Facts</a>. The key fact is that the formula takes as input the rows of what I've nicknamed the not-popular subtable (NPS), that is, the original table without the rows whose values are  popular values (in this case, 64 is the only popular value). Letting num_rows_nps the number of rows of the NPS (for our example, num_rows_nps=1+2+4+8+16=31), we have:<br />
[text]<br />
   density = (1 / num_rows) *<br />
   sum (count (value) ^ 2) / num_rows_nps<br />
   summed over all values of the NPS<br />
[/text]<br />
The script performs this calculation automatically; it is anyway instructive to perform the calculation manually at least one time:<br />
density = (1/95) * (1*1+2*2+4*4+8*8+16*16) * (1/31)= .115789474<br />
that matches perfectly the density we observed in the script log before.</p>
<p>But what is the statistical rationale for this seemingly strange computation ? Well, the resulting expected cardinality computation is<br />
[text]<br />
E[count(client_value)] = sum (count (value) ^ 2) / num_rows_nps<br />
for client_value not popular<br />
[/text]<br />
which is exactly the "Matched count(:x) and w(:x)" (the third) case considered in the previous post mentioned above, <i>applied to the NPS instead of the whole table</i>.</p>
<p>So, after having understood the previous post, explaining the rationale behind "density" is relatively simple. The CBO knows that client_value is not a popular values, hence it is contained in the NPS, and applies the usual reasoning and assumptions that it makes for tables without histograms to the NPS - but changing the assumption about the shape of w(client_value). It assumes that the more a certain client_value is represented in the table, the more it will be submitted by the client; more precisely, that if X% of rows has a certain common value, X% of user-submitted statements that "hit" the NPS will ask for that value. Density is pre-set by dbms_stats to produce the resulting value.</p>
<p>As we will see in the next post, the "NewDensity" changes in 10.2.0.4 consist mostly in replacing this assumption about w(client_value) with the standard assumptions made for columns without histograms - hence this assumption can be considered "deprecated".</p>
<p>In the next post, we will discuss the new, improved formulae.<br />
</client_value></p>
