<?xml version="1.0" encoding="UTF-8" ?>
<!-- This is a WordPress eXtended RSS file generated by WordPress as an export of your site. -->
<!-- It contains information about your site's posts, pages, comments, categories, and other content. -->
<!-- You may use this file to transfer that content from one site to another. -->
<!-- This file is not intended to serve as a complete backup of your site. -->

<!-- To import this information into a WordPress site follow these steps: -->
<!-- 1. Log in to that site as an administrator. -->
<!-- 2. Go to Tools: Import in the WordPress admin panel. -->
<!-- 3. Install the "WordPress" importer from the list. -->
<!-- 4. Activate & Run Importer. -->
<!-- 5. Upload this file using the form provided on that page. -->
<!-- 6. You will first be asked to map the authors in this export file to users -->
<!--    on the site. For each author, you may choose to map to an -->
<!--    existing user on the site or to create a new user. -->
<!-- 7. WordPress will then import each of the posts, pages, comments, categories, etc. -->
<!--    contained in this file into your site. -->

	<!-- generator="WordPress/5.5.5" created="2021-05-16 13:32" -->
<rss version="2.0"
	xmlns:excerpt="http://wordpress.org/export/1.2/excerpt/"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:wp="http://wordpress.org/export/1.2/"
>

<channel>
	<title>Alberto Dell&#039;Era&#039;s blog</title>
	<link>http://www.adellera.it</link>
	<description>Not only Oracle</description>
	<pubDate>Sun, 16 May 2021 13:32:52 +0000</pubDate>
	<language>en-US</language>
	<wp:wxr_version>1.2</wp:wxr_version>
	<wp:base_site_url>http://www.adellera.it</wp:base_site_url>
	<wp:base_blog_url>http://www.adellera.it</wp:base_blog_url>

		<wp:author><wp:author_id>1</wp:author_id><wp:author_login><![CDATA[user]]></wp:author_login><wp:author_email><![CDATA[user@example.com]]></wp:author_email><wp:author_display_name><![CDATA[user]]></wp:author_display_name><wp:author_first_name><![CDATA[]]></wp:author_first_name><wp:author_last_name><![CDATA[]]></wp:author_last_name></wp:author>
	<wp:author><wp:author_id>2</wp:author_id><wp:author_login><![CDATA[alberto.dellera]]></wp:author_login><wp:author_email><![CDATA[alberto.dellera@gmail.com]]></wp:author_email><wp:author_display_name><![CDATA[Alberto Dell'Era]]></wp:author_display_name><wp:author_first_name><![CDATA[Alberto]]></wp:author_first_name><wp:author_last_name><![CDATA[Dell'Era]]></wp:author_last_name></wp:author>

		<wp:category>
		<wp:term_id>2</wp:term_id>
		<wp:category_nicename><![CDATA[ash]]></wp:category_nicename>
		<wp:category_parent><![CDATA[]]></wp:category_parent>
		<wp:cat_name><![CDATA[ash]]></wp:cat_name>
	</wp:category>
		<wp:category>
		<wp:term_id>3</wp:term_id>
		<wp:category_nicename><![CDATA[ash-math]]></wp:category_nicename>
		<wp:category_parent><![CDATA[ash]]></wp:category_parent>
		<wp:cat_name><![CDATA[ash math]]></wp:cat_name>
	</wp:category>
		<wp:category>
		<wp:term_id>4</wp:term_id>
		<wp:category_nicename><![CDATA[case-studies]]></wp:category_nicename>
		<wp:category_parent><![CDATA[]]></wp:category_parent>
		<wp:cat_name><![CDATA[case studies]]></wp:cat_name>
	</wp:category>
		<wp:category>
		<wp:term_id>5</wp:term_id>
		<wp:category_nicename><![CDATA[cbo]]></wp:category_nicename>
		<wp:category_parent><![CDATA[]]></wp:category_parent>
		<wp:cat_name><![CDATA[CBO]]></wp:cat_name>
	</wp:category>
		<wp:category>
		<wp:term_id>6</wp:term_id>
		<wp:category_nicename><![CDATA[compression]]></wp:category_nicename>
		<wp:category_parent><![CDATA[]]></wp:category_parent>
		<wp:cat_name><![CDATA[compression]]></wp:cat_name>
	</wp:category>
		<wp:category>
		<wp:term_id>7</wp:term_id>
		<wp:category_nicename><![CDATA[indexes]]></wp:category_nicename>
		<wp:category_parent><![CDATA[]]></wp:category_parent>
		<wp:cat_name><![CDATA[Indexes]]></wp:cat_name>
	</wp:category>
		<wp:category>
		<wp:term_id>8</wp:term_id>
		<wp:category_nicename><![CDATA[materialized-views]]></wp:category_nicename>
		<wp:category_parent><![CDATA[]]></wp:category_parent>
		<wp:cat_name><![CDATA[materialized views]]></wp:cat_name>
	</wp:category>
		<wp:category>
		<wp:term_id>9</wp:term_id>
		<wp:category_nicename><![CDATA[performance-tuning]]></wp:category_nicename>
		<wp:category_parent><![CDATA[]]></wp:category_parent>
		<wp:cat_name><![CDATA[performance tuning]]></wp:cat_name>
	</wp:category>
		<wp:category>
		<wp:term_id>10</wp:term_id>
		<wp:category_nicename><![CDATA[siebel]]></wp:category_nicename>
		<wp:category_parent><![CDATA[]]></wp:category_parent>
		<wp:cat_name><![CDATA[siebel]]></wp:cat_name>
	</wp:category>
		<wp:category>
		<wp:term_id>11</wp:term_id>
		<wp:category_nicename><![CDATA[social-events]]></wp:category_nicename>
		<wp:category_parent><![CDATA[]]></wp:category_parent>
		<wp:cat_name><![CDATA[Social Events]]></wp:cat_name>
	</wp:category>
		<wp:category>
		<wp:term_id>12</wp:term_id>
		<wp:category_nicename><![CDATA[technical-meetings]]></wp:category_nicename>
		<wp:category_parent><![CDATA[]]></wp:category_parent>
		<wp:cat_name><![CDATA[Technical Meetings]]></wp:cat_name>
	</wp:category>
		<wp:category>
		<wp:term_id>13</wp:term_id>
		<wp:category_nicename><![CDATA[tools]]></wp:category_nicename>
		<wp:category_parent><![CDATA[]]></wp:category_parent>
		<wp:cat_name><![CDATA[tools]]></wp:cat_name>
	</wp:category>
		<wp:category>
		<wp:term_id>1</wp:term_id>
		<wp:category_nicename><![CDATA[uncategorized]]></wp:category_nicename>
		<wp:category_parent><![CDATA[]]></wp:category_parent>
		<wp:cat_name><![CDATA[Uncategorized]]></wp:cat_name>
	</wp:category>
		<wp:category>
		<wp:term_id>14</wp:term_id>
		<wp:category_nicename><![CDATA[xplan]]></wp:category_nicename>
		<wp:category_parent><![CDATA[]]></wp:category_parent>
		<wp:cat_name><![CDATA[xplan]]></wp:cat_name>
	</wp:category>
		<wp:category>
		<wp:term_id>15</wp:term_id>
		<wp:category_nicename><![CDATA[xtrace]]></wp:category_nicename>
		<wp:category_parent><![CDATA[]]></wp:category_parent>
		<wp:cat_name><![CDATA[xtrace]]></wp:cat_name>
	</wp:category>
					<wp:term><wp:term_id>16</wp:term_id><wp:term_taxonomy>nav_menu</wp:term_taxonomy><wp:term_slug><![CDATA[primarymenu]]></wp:term_slug><wp:term_name><![CDATA[PrimaryMenu]]></wp:term_name>
</wp:term>

	<generator>https://wordpress.org/?v=5.5.5</generator>

<image>
	<url>http://www.adellera.it/wp-content/uploads/2018/05/cropped-faccione-32x32.jpeg</url>
	<title>Alberto Dell&#039;Era&#039;s blog</title>
	<link>http://www.adellera.it</link>
	<width>32</width>
	<height>32</height>
</image> 

		<item>
		<title>post_0005</title>
		<link>http://www.adellera.it/blog/2009/05/24/order-keys-inside-index-blocks/post_0005/</link>
		<pubDate>Sun, 24 May 2009 15:52:34 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2009/05/post_0005.zip</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>240</wp:post_id>
		<wp:post_date><![CDATA[2009-05-24 17:52:34]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-05-24 15:52:34]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[post_0005]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>233</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2009/05/post_0005.zip]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2009/05/post_0005.zip]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>post_0030_join_mv</title>
		<link>http://www.adellera.it/post_0030_join_mv/</link>
		<pubDate>Tue, 04 Aug 2009 14:27:16 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2009/08/post_0030_join_mv.zip</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>282</wp:post_id>
		<wp:post_date><![CDATA[2009-08-04 16:27:16]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-08-04 14:27:16]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[post_0030_join_mv]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2009/08/post_0030_join_mv.zip]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2009/08/post_0030_join_mv.zip]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>post_0050_single_table_mv</title>
		<link>http://www.adellera.it/post_0050_single_table_mv/</link>
		<pubDate>Tue, 11 Aug 2009 15:05:43 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2009/08/post_0050_single_table_mv.zip</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>296</wp:post_id>
		<wp:post_date><![CDATA[2009-08-11 17:05:43]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-08-11 15:05:43]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[post_0050_single_table_mv]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2009/08/post_0050_single_table_mv.zip]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2009/08/post_0050_single_table_mv.zip]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>density_post</title>
		<link>http://www.adellera.it/density_post/</link>
		<pubDate>Sat, 10 Oct 2009 13:40:50 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2009/10/density_post.zip</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>338</wp:post_id>
		<wp:post_date><![CDATA[2009-10-10 15:40:50]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-10-10 13:40:50]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[density_post]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2009/10/density_post.zip]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2009/10/density_post.zip]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>density_post_freq</title>
		<link>http://www.adellera.it/density_post_freq/</link>
		<pubDate>Fri, 23 Oct 2009 15:52:47 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2009/10/density_post_freq.zip</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>351</wp:post_id>
		<wp:post_date><![CDATA[2009-10-23 17:52:47]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-10-23 15:52:47]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[density_post_freq]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2009/10/density_post_freq.zip]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2009/10/density_post_freq.zip]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>11gr2_mv_logs</title>
		<link>http://www.adellera.it/11gr2_mv_logs/</link>
		<pubDate>Tue, 03 Nov 2009 17:09:55 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2009/11/11gr2_mv_logs.zip</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>375</wp:post_id>
		<wp:post_date><![CDATA[2009-11-03 19:09:55]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-11-03 17:09:55]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[11gr2_mv_logs]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2009/11/11gr2_mv_logs.zip]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2009/11/11gr2_mv_logs.zip]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>11gr2_join_mv_on_commit</title>
		<link>http://www.adellera.it/11gr2_join_mv_on_commit/</link>
		<pubDate>Sun, 22 Nov 2009 14:52:54 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2009/11/11gr2_join_mv_on_commit.zip</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>384</wp:post_id>
		<wp:post_date><![CDATA[2009-11-22 16:52:54]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-11-22 14:52:54]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[11gr2_join_mv_on_commit]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2009/11/11gr2_join_mv_on_commit.zip]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2009/11/11gr2_join_mv_on_commit.zip]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>tool_lines</title>
		<link>http://www.adellera.it/tool_lines/</link>
		<pubDate>Wed, 06 Jan 2010 21:42:01 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2010/01/tool_lines.bmp</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>401</wp:post_id>
		<wp:post_date><![CDATA[2010-01-06 23:42:01]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2010-01-06 21:42:01]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[tool_lines]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2010/01/tool_lines.bmp]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2010/01/tool_lines.bmp]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attachment_metadata]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:4:{s:5:"width";i:744;s:6:"height";i:425;s:4:"file";s:22:"2010/01/tool_lines.bmp";s:10:"image_meta";a:12:{s:8:"aperture";s:1:"0";s:6:"credit";s:0:"";s:6:"camera";s:0:"";s:7:"caption";s:0:"";s:17:"created_timestamp";s:1:"0";s:9:"copyright";s:0:"";s:12:"focal_length";s:1:"0";s:3:"iso";s:1:"0";s:13:"shutter_speed";s:1:"0";s:5:"title";s:0:"";s:11:"orientation";s:1:"0";s:8:"keywords";a:0:{}}}]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>tool_lines1</title>
		<link>http://www.adellera.it/blog/2010/01/06/tweet/tool_lines1/</link>
		<pubDate>Wed, 06 Jan 2010 21:43:43 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2010/01/tool_lines1.bmp</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>402</wp:post_id>
		<wp:post_date><![CDATA[2010-01-06 23:43:43]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2010-01-06 21:43:43]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[tool_lines1]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>399</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2010/01/tool_lines1.bmp]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2010/01/tool_lines1.bmp]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attachment_metadata]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:4:{s:5:"width";i:744;s:6:"height";i:425;s:4:"file";s:23:"2010/01/tool_lines1.bmp";s:10:"image_meta";a:12:{s:8:"aperture";s:1:"0";s:6:"credit";s:0:"";s:6:"camera";s:0:"";s:7:"caption";s:0:"";s:17:"created_timestamp";s:1:"0";s:9:"copyright";s:0:"";s:12:"focal_length";s:1:"0";s:3:"iso";s:1:"0";s:13:"shutter_speed";s:1:"0";s:5:"title";s:0:"";s:11:"orientation";s:1:"0";s:8:"keywords";a:0:{}}}]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>tool_prof</title>
		<link>http://www.adellera.it/blog/2010/01/06/tweet/tool_prof/</link>
		<pubDate>Wed, 06 Jan 2010 21:48:24 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2010/01/tool_prof.bmp</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>409</wp:post_id>
		<wp:post_date><![CDATA[2010-01-06 23:48:24]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2010-01-06 21:48:24]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[tool_prof]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>399</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2010/01/tool_prof.bmp]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2010/01/tool_prof.bmp]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attachment_metadata]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:4:{s:5:"width";i:736;s:6:"height";i:287;s:4:"file";s:21:"2010/01/tool_prof.bmp";s:10:"image_meta";a:12:{s:8:"aperture";s:1:"0";s:6:"credit";s:0:"";s:6:"camera";s:0:"";s:7:"caption";s:0:"";s:17:"created_timestamp";s:1:"0";s:9:"copyright";s:0:"";s:12:"focal_length";s:1:"0";s:3:"iso";s:1:"0";s:13:"shutter_speed";s:1:"0";s:5:"title";s:0:"";s:11:"orientation";s:1:"0";s:8:"keywords";a:0:{}}}]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>tool_lines2</title>
		<link>http://www.adellera.it/blog/2010/01/06/tweet/tool_lines2/</link>
		<pubDate>Wed, 06 Jan 2010 21:55:43 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2010/01/tool_lines2.bmp</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>412</wp:post_id>
		<wp:post_date><![CDATA[2010-01-06 23:55:43]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2010-01-06 21:55:43]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[tool_lines2]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>399</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2010/01/tool_lines2.bmp]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2010/01/tool_lines2.bmp]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attachment_metadata]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:4:{s:5:"width";i:613;s:6:"height";i:425;s:4:"file";s:23:"2010/01/tool_lines2.bmp";s:10:"image_meta";a:12:{s:8:"aperture";s:1:"0";s:6:"credit";s:0:"";s:6:"camera";s:0:"";s:7:"caption";s:0:"";s:17:"created_timestamp";s:1:"0";s:9:"copyright";s:0:"";s:12:"focal_length";s:1:"0";s:3:"iso";s:1:"0";s:13:"shutter_speed";s:1:"0";s:5:"title";s:0:"";s:11:"orientation";s:1:"0";s:8:"keywords";a:0:{}}}]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>tool_prof1</title>
		<link>http://www.adellera.it/blog/2010/01/06/tweet/tool_prof1/</link>
		<pubDate>Wed, 06 Jan 2010 21:56:38 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2010/01/tool_prof1.bmp</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>413</wp:post_id>
		<wp:post_date><![CDATA[2010-01-06 23:56:38]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2010-01-06 21:56:38]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[tool_prof1]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>399</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2010/01/tool_prof1.bmp]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2010/01/tool_prof1.bmp]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attachment_metadata]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:4:{s:5:"width";i:595;s:6:"height";i:287;s:4:"file";s:22:"2010/01/tool_prof1.bmp";s:10:"image_meta";a:12:{s:8:"aperture";s:1:"0";s:6:"credit";s:0:"";s:6:"camera";s:0:"";s:7:"caption";s:0:"";s:17:"created_timestamp";s:1:"0";s:9:"copyright";s:0:"";s:12:"focal_length";s:1:"0";s:3:"iso";s:1:"0";s:13:"shutter_speed";s:1:"0";s:5:"title";s:0:"";s:11:"orientation";s:1:"0";s:8:"keywords";a:0:{}}}]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>join_mv_use_stats_lock</title>
		<link>http://www.adellera.it/join_mv_use_stats_lock/</link>
		<pubDate>Thu, 11 Mar 2010 20:20:23 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2010/03/join_mv_use_stats_lock.zip</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>425</wp:post_id>
		<wp:post_date><![CDATA[2010-03-11 22:20:23]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2010-03-11 20:20:23]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[join_mv_use_stats_lock]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2010/03/join_mv_use_stats_lock.zip]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2010/03/join_mv_use_stats_lock.zip]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>xtrace_hello_10_2_0_4_lines</title>
		<link>http://www.adellera.it/xtrace_hello_10_2_0_4_lines/</link>
		<pubDate>Thu, 08 Apr 2010 16:10:23 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2010/04/xtrace_hello_10_2_0_4_lines.gif</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>434</wp:post_id>
		<wp:post_date><![CDATA[2010-04-08 18:10:23]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2010-04-08 16:10:23]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[xtrace_hello_10_2_0_4_lines]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2010/04/xtrace_hello_10_2_0_4_lines.gif]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2010/04/xtrace_hello_10_2_0_4_lines.gif]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attachment_metadata]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:5:{s:5:"width";i:583;s:6:"height";i:586;s:4:"file";s:39:"2010/04/xtrace_hello_10_2_0_4_lines.gif";s:5:"sizes";a:6:{s:9:"thumbnail";a:4:{s:4:"file";s:39:"xtrace_hello_10_2_0_4_lines-150x150.gif";s:5:"width";i:150;s:6:"height";i:150;s:9:"mime-type";s:9:"image/gif";}s:6:"medium";a:4:{s:4:"file";s:39:"xtrace_hello_10_2_0_4_lines-298x300.gif";s:5:"width";i:298;s:6:"height";i:300;s:9:"mime-type";s:9:"image/gif";}s:40:"tech-literacy-small-featured-image-width";a:4:{s:4:"file";s:39:"xtrace_hello_10_2_0_4_lines-450x300.gif";s:5:"width";i:450;s:6:"height";i:300;s:9:"mime-type";s:9:"image/gif";}s:30:"tech-literacy-blog-large-width";a:4:{s:4:"file";s:39:"xtrace_hello_10_2_0_4_lines-583x300.gif";s:5:"width";i:583;s:6:"height";i:300;s:9:"mime-type";s:9:"image/gif";}s:25:"tech-literacy-service-img";a:4:{s:4:"file";s:39:"xtrace_hello_10_2_0_4_lines-100x100.gif";s:5:"width";i:100;s:6:"height";i:100;s:9:"mime-type";s:9:"image/gif";}s:30:"tech-literacy-recent-posts-img";a:4:{s:4:"file";s:39:"xtrace_hello_10_2_0_4_lines-380x270.gif";s:5:"width";i:380;s:6:"height";i:270;s:9:"mime-type";s:9:"image/gif";}}s:10:"image_meta";a:12:{s:8:"aperture";s:1:"0";s:6:"credit";s:0:"";s:6:"camera";s:0:"";s:7:"caption";s:0:"";s:17:"created_timestamp";s:1:"0";s:9:"copyright";s:0:"";s:12:"focal_length";s:1:"0";s:3:"iso";s:1:"0";s:13:"shutter_speed";s:1:"0";s:5:"title";s:0:"";s:11:"orientation";s:1:"0";s:8:"keywords";a:0:{}}}]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>xtrace_exec_flow_11_2_0_1_lines_no_binds</title>
		<link>http://www.adellera.it/xtrace_exec_flow_11_2_0_1_lines_no_binds/</link>
		<pubDate>Sun, 16 May 2010 15:16:16 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2010/05/xtrace_exec_flow_11_2_0_1_lines_no_binds.gif</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>446</wp:post_id>
		<wp:post_date><![CDATA[2010-05-16 17:16:16]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2010-05-16 15:16:16]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[xtrace_exec_flow_11_2_0_1_lines_no_binds]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2010/05/xtrace_exec_flow_11_2_0_1_lines_no_binds.gif]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2010/05/xtrace_exec_flow_11_2_0_1_lines_no_binds.gif]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attachment_metadata]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:5:{s:5:"width";i:477;s:6:"height";i:154;s:4:"file";s:52:"2010/05/xtrace_exec_flow_11_2_0_1_lines_no_binds.gif";s:5:"sizes";a:5:{s:9:"thumbnail";a:4:{s:4:"file";s:52:"xtrace_exec_flow_11_2_0_1_lines_no_binds-150x150.gif";s:5:"width";i:150;s:6:"height";i:150;s:9:"mime-type";s:9:"image/gif";}s:6:"medium";a:4:{s:4:"file";s:51:"xtrace_exec_flow_11_2_0_1_lines_no_binds-300x97.gif";s:5:"width";i:300;s:6:"height";i:97;s:9:"mime-type";s:9:"image/gif";}s:40:"tech-literacy-small-featured-image-width";a:4:{s:4:"file";s:52:"xtrace_exec_flow_11_2_0_1_lines_no_binds-450x154.gif";s:5:"width";i:450;s:6:"height";i:154;s:9:"mime-type";s:9:"image/gif";}s:25:"tech-literacy-service-img";a:4:{s:4:"file";s:52:"xtrace_exec_flow_11_2_0_1_lines_no_binds-100x100.gif";s:5:"width";i:100;s:6:"height";i:100;s:9:"mime-type";s:9:"image/gif";}s:30:"tech-literacy-recent-posts-img";a:4:{s:4:"file";s:52:"xtrace_exec_flow_11_2_0_1_lines_no_binds-380x154.gif";s:5:"width";i:380;s:6:"height";i:154;s:9:"mime-type";s:9:"image/gif";}}s:10:"image_meta";a:12:{s:8:"aperture";s:1:"0";s:6:"credit";s:0:"";s:6:"camera";s:0:"";s:7:"caption";s:0:"";s:17:"created_timestamp";s:1:"0";s:9:"copyright";s:0:"";s:12:"focal_length";s:1:"0";s:3:"iso";s:1:"0";s:13:"shutter_speed";s:1:"0";s:5:"title";s:0:"";s:11:"orientation";s:1:"0";s:8:"keywords";a:0:{}}}]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>xtrace_exec_flow_11_2_0_1_lines_with_binds</title>
		<link>http://www.adellera.it/xtrace_exec_flow_11_2_0_1_lines_with_binds/</link>
		<pubDate>Sun, 16 May 2010 15:16:38 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2010/05/xtrace_exec_flow_11_2_0_1_lines_with_binds.gif</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>447</wp:post_id>
		<wp:post_date><![CDATA[2010-05-16 17:16:38]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2010-05-16 15:16:38]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[xtrace_exec_flow_11_2_0_1_lines_with_binds]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2010/05/xtrace_exec_flow_11_2_0_1_lines_with_binds.gif]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2010/05/xtrace_exec_flow_11_2_0_1_lines_with_binds.gif]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attachment_metadata]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:5:{s:5:"width";i:477;s:6:"height";i:419;s:4:"file";s:54:"2010/05/xtrace_exec_flow_11_2_0_1_lines_with_binds.gif";s:5:"sizes";a:6:{s:9:"thumbnail";a:4:{s:4:"file";s:54:"xtrace_exec_flow_11_2_0_1_lines_with_binds-150x150.gif";s:5:"width";i:150;s:6:"height";i:150;s:9:"mime-type";s:9:"image/gif";}s:6:"medium";a:4:{s:4:"file";s:54:"xtrace_exec_flow_11_2_0_1_lines_with_binds-300x264.gif";s:5:"width";i:300;s:6:"height";i:264;s:9:"mime-type";s:9:"image/gif";}s:40:"tech-literacy-small-featured-image-width";a:4:{s:4:"file";s:54:"xtrace_exec_flow_11_2_0_1_lines_with_binds-450x300.gif";s:5:"width";i:450;s:6:"height";i:300;s:9:"mime-type";s:9:"image/gif";}s:30:"tech-literacy-blog-large-width";a:4:{s:4:"file";s:54:"xtrace_exec_flow_11_2_0_1_lines_with_binds-477x300.gif";s:5:"width";i:477;s:6:"height";i:300;s:9:"mime-type";s:9:"image/gif";}s:25:"tech-literacy-service-img";a:4:{s:4:"file";s:54:"xtrace_exec_flow_11_2_0_1_lines_with_binds-100x100.gif";s:5:"width";i:100;s:6:"height";i:100;s:9:"mime-type";s:9:"image/gif";}s:30:"tech-literacy-recent-posts-img";a:4:{s:4:"file";s:54:"xtrace_exec_flow_11_2_0_1_lines_with_binds-380x270.gif";s:5:"width";i:380;s:6:"height";i:270;s:9:"mime-type";s:9:"image/gif";}}s:10:"image_meta";a:12:{s:8:"aperture";s:1:"0";s:6:"credit";s:0:"";s:6:"camera";s:0:"";s:7:"caption";s:0:"";s:17:"created_timestamp";s:1:"0";s:9:"copyright";s:0:"";s:12:"focal_length";s:1:"0";s:3:"iso";s:1:"0";s:13:"shutter_speed";s:1:"0";s:5:"title";s:0:"";s:11:"orientation";s:1:"0";s:8:"keywords";a:0:{}}}]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>mv_fast_becomes_complete</title>
		<link>http://www.adellera.it/mv_fast_becomes_complete/</link>
		<pubDate>Sun, 16 Sep 2012 16:18:46 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2012/09/mv_fast_becomes_complete.zip</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>522</wp:post_id>
		<wp:post_date><![CDATA[2012-09-16 18:18:46]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2012-09-16 16:18:46]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[mv_fast_becomes_complete]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2012/09/mv_fast_becomes_complete.zip]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2012/09/mv_fast_becomes_complete.zip]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>overlapping_ranges_with_priority</title>
		<link>http://www.adellera.it/overlapping_ranges_with_priority/</link>
		<pubDate>Sun, 30 Sep 2012 13:38:42 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2012/09/overlapping_ranges_with_priority.zip</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>584</wp:post_id>
		<wp:post_date><![CDATA[2012-09-30 15:38:42]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2012-09-30 13:38:42]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[overlapping_ranges_with_priority]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2012/09/overlapping_ranges_with_priority.zip]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2012/09/overlapping_ranges_with_priority.zip]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>oltp_compress_migrated_rows</title>
		<link>http://www.adellera.it/oltp_compress_migrated_rows/</link>
		<pubDate>Sun, 07 Apr 2013 16:12:36 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2013/04/oltp_compress_migrated_rows.zip</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>588</wp:post_id>
		<wp:post_date><![CDATA[2013-04-07 18:12:36]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2013-04-07 16:12:36]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[oltp_compress_migrated_rows]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2013/04/oltp_compress_migrated_rows.zip]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2013/04/oltp_compress_migrated_rows.zip]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>join_mv_outer_part1_unique</title>
		<link>http://www.adellera.it/join_mv_outer_part1_unique/</link>
		<pubDate>Sun, 21 Apr 2013 16:05:50 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2013/04/join_mv_outer_part1_unique.zip</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>698</wp:post_id>
		<wp:post_date><![CDATA[2013-04-21 18:05:50]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2013-04-21 16:05:50]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[join_mv_outer_part1_unique]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2013/04/join_mv_outer_part1_unique.zip]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2013/04/join_mv_outer_part1_unique.zip]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>About</title>
		<link>http://www.adellera.it/about/</link>
		<pubDate>Wed, 29 Apr 2009 13:41:52 +0000</pubDate>
		<dc:creator><![CDATA[user]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?page_id=2</guid>
		<description></description>
		<content:encoded><![CDATA[<img class="alignleft size-full wp-image-841" src="http://34.247.94.223/wp-content/uploads/2018/05/faccione.jpeg" alt="" width="128" height="128" /> I've spent all my professional life working within the Italian Telecommunications sector since 1996, specializing in the Oracle database full-time since 1999. I currently work for a big (2600+ employees) consultancy firm as an Oracle specialist, very often optimizing customers' systems ("Performance Tuning"), and developing for the flagship customer Web portal of one of the largest Italian mobile operators. I also hold a Math-oriented degree in Electronics Engineering from the "Politecnico di Milano" University.

I am honoured of being a member of <a href="http://www.oaktable.net">OakTable Network</a>, the famous organization of Oracle professionals distinguished by the use of the Scientific Method (and related ethics) for all their activities.

I currently live in Milano (Northern Italy).

I welcome any comment, feedback, correction and question.

<a href="mailto:alberto.dellera@gmail.com">alberto.dellera@gmail.com</a>

<a href="https://github.com/alberto-dellera">https://github.com/alberto-dellera</a>

<a href="http://it.linkedin.com/in/adellera">
<img src="https://static.licdn.com/scds/common/u/img/webpromo/btn_viewmy_160x25.png" alt="View Alberto Dell'Era's profile on LinkedIn" width="160" height="25" border="0" />
</a>]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>112</wp:post_id>
		<wp:post_date><![CDATA[2009-04-29 15:41:52]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-04-29 13:41:52]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[about]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>100</wp:menu_order>
		<wp:post_type><![CDATA[page]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
														<wp:postmeta>
		<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
		<wp:meta_value><![CDATA[2]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_oembed_316cf6bae781995203c27627f3adcbe3]]></wp:meta_key>
		<wp:meta_value><![CDATA[{{unknown}}]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_page_template]]></wp:meta_key>
		<wp:meta_value><![CDATA[default]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>join_mv_outer_part2</title>
		<link>http://www.adellera.it/join_mv_outer_part2/</link>
		<pubDate>Fri, 26 Apr 2013 10:17:15 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2013/04/join_mv_outer_part2.zip</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>741</wp:post_id>
		<wp:post_date><![CDATA[2013-04-26 12:17:15]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2013-04-26 10:17:15]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[join_mv_outer_part2]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2013/04/join_mv_outer_part2.zip]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2013/04/join_mv_outer_part2.zip]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>force_parallel_query</title>
		<link>http://www.adellera.it/force_parallel_query/</link>
		<pubDate>Fri, 17 May 2013 11:57:28 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2013/05/force_parallel_query.zip</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>760</wp:post_id>
		<wp:post_date><![CDATA[2013-05-17 13:57:28]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2013-05-17 11:57:28]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[force_parallel_query]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2013/05/force_parallel_query.zip]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2013/05/force_parallel_query.zip]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>gby_mv_intro</title>
		<link>http://www.adellera.it/gby_mv_intro/</link>
		<pubDate>Fri, 02 Aug 2013 16:19:06 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2013/08/gby_mv_intro.zip</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>767</wp:post_id>
		<wp:post_date><![CDATA[2013-08-02 18:19:06]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2013-08-02 16:19:06]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[gby_mv_intro]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2013/08/gby_mv_intro.zip]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2013/08/gby_mv_intro.zip]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>post_0270_gby_mv_sum</title>
		<link>http://www.adellera.it/post_0270_gby_mv_sum/</link>
		<pubDate>Sun, 18 Aug 2013 20:12:41 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2013/08/post_0270_gby_mv_sum.zip</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>790</wp:post_id>
		<wp:post_date><![CDATA[2013-08-18 22:12:41]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2013-08-18 20:12:41]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[post_0270_gby_mv_sum]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2013/08/post_0270_gby_mv_sum.zip]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2013/08/post_0270_gby_mv_sum.zip]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>post_0280_gby_mv_max</title>
		<link>http://www.adellera.it/post_0280_gby_mv_max/</link>
		<pubDate>Thu, 22 Aug 2013 16:25:22 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2013/08/post_0280_gby_mv_max.zip</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>803</wp:post_id>
		<wp:post_date><![CDATA[2013-08-22 18:25:22]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2013-08-22 16:25:22]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[post_0280_gby_mv_max]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2013/08/post_0280_gby_mv_max.zip]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2013/08/post_0280_gby_mv_max.zip]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>ashevents</title>
		<link>http://www.adellera.it/blog/2016/06/23/ash-math-of-time_waited-explained-with-pictures-and-simulation/events/</link>
		<pubDate>Thu, 23 Jun 2016 09:24:17 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2016/06/events.png</guid>
		<description></description>
		<content:encoded><![CDATA[histogram of event stream]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>825</wp:post_id>
		<wp:post_date><![CDATA[2016-06-23 11:24:17]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2016-06-23 09:24:17]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[events]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>817</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2016/06/events.png]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2016/06/events.png]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attachment_metadata]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:5:{s:5:"width";i:480;s:6:"height";i:480;s:4:"file";s:18:"2016/06/events.png";s:5:"sizes";a:6:{s:9:"thumbnail";a:4:{s:4:"file";s:18:"events-150x150.png";s:5:"width";i:150;s:6:"height";i:150;s:9:"mime-type";s:9:"image/png";}s:6:"medium";a:4:{s:4:"file";s:18:"events-300x300.png";s:5:"width";i:300;s:6:"height";i:300;s:9:"mime-type";s:9:"image/png";}s:40:"tech-literacy-small-featured-image-width";a:4:{s:4:"file";s:18:"events-450x300.png";s:5:"width";i:450;s:6:"height";i:300;s:9:"mime-type";s:9:"image/png";}s:30:"tech-literacy-blog-large-width";a:4:{s:4:"file";s:18:"events-480x300.png";s:5:"width";i:480;s:6:"height";i:300;s:9:"mime-type";s:9:"image/png";}s:25:"tech-literacy-service-img";a:4:{s:4:"file";s:18:"events-100x100.png";s:5:"width";i:100;s:6:"height";i:100;s:9:"mime-type";s:9:"image/png";}s:30:"tech-literacy-recent-posts-img";a:4:{s:4:"file";s:18:"events-380x270.png";s:5:"width";i:380;s:6:"height";i:270;s:9:"mime-type";s:9:"image/png";}}s:10:"image_meta";a:12:{s:8:"aperture";s:1:"0";s:6:"credit";s:0:"";s:6:"camera";s:0:"";s:7:"caption";s:0:"";s:17:"created_timestamp";s:1:"0";s:9:"copyright";s:0:"";s:12:"focal_length";s:1:"0";s:3:"iso";s:1:"0";s:13:"shutter_speed";s:1:"0";s:5:"title";s:0:"";s:11:"orientation";s:1:"0";s:8:"keywords";a:0:{}}}]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attachment_image_alt]]></wp:meta_key>
		<wp:meta_value><![CDATA[histogram of event stream]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>ashcombined</title>
		<link>http://www.adellera.it/blog/2016/06/23/ash-math-of-time_waited-explained-with-pictures-and-simulation/combined/</link>
		<pubDate>Thu, 23 Jun 2016 09:26:28 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2016/06/combined.png</guid>
		<description></description>
		<content:encoded><![CDATA[histogram of events and samples combined]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>828</wp:post_id>
		<wp:post_date><![CDATA[2016-06-23 11:26:28]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2016-06-23 09:26:28]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[combined]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>817</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2016/06/combined.png]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2016/06/combined.png]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attachment_metadata]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:5:{s:5:"width";i:480;s:6:"height";i:480;s:4:"file";s:20:"2016/06/combined.png";s:5:"sizes";a:6:{s:9:"thumbnail";a:4:{s:4:"file";s:20:"combined-150x150.png";s:5:"width";i:150;s:6:"height";i:150;s:9:"mime-type";s:9:"image/png";}s:6:"medium";a:4:{s:4:"file";s:20:"combined-300x300.png";s:5:"width";i:300;s:6:"height";i:300;s:9:"mime-type";s:9:"image/png";}s:40:"tech-literacy-small-featured-image-width";a:4:{s:4:"file";s:20:"combined-450x300.png";s:5:"width";i:450;s:6:"height";i:300;s:9:"mime-type";s:9:"image/png";}s:30:"tech-literacy-blog-large-width";a:4:{s:4:"file";s:20:"combined-480x300.png";s:5:"width";i:480;s:6:"height";i:300;s:9:"mime-type";s:9:"image/png";}s:25:"tech-literacy-service-img";a:4:{s:4:"file";s:20:"combined-100x100.png";s:5:"width";i:100;s:6:"height";i:100;s:9:"mime-type";s:9:"image/png";}s:30:"tech-literacy-recent-posts-img";a:4:{s:4:"file";s:20:"combined-380x270.png";s:5:"width";i:380;s:6:"height";i:270;s:9:"mime-type";s:9:"image/png";}}s:10:"image_meta";a:12:{s:8:"aperture";s:1:"0";s:6:"credit";s:0:"";s:6:"camera";s:0:"";s:7:"caption";s:0:"";s:17:"created_timestamp";s:1:"0";s:9:"copyright";s:0:"";s:12:"focal_length";s:1:"0";s:3:"iso";s:1:"0";s:13:"shutter_speed";s:1:"0";s:5:"title";s:0:"";s:11:"orientation";s:1:"0";s:8:"keywords";a:0:{}}}]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attachment_image_alt]]></wp:meta_key>
		<wp:meta_value><![CDATA[histogram of events and samples combined]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>post_0310_ash_math</title>
		<link>http://www.adellera.it/post_0310_ash_math/</link>
		<pubDate>Thu, 23 Jun 2016 09:37:35 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2016/06/post_0310_ash_math.zip</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>834</wp:post_id>
		<wp:post_date><![CDATA[2016-06-23 11:37:35]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2016-06-23 09:37:35]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[post_0310_ash_math]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2016/06/post_0310_ash_math.zip]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2016/06/post_0310_ash_math.zip]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>faccione</title>
		<link>http://www.adellera.it/about/faccione/</link>
		<pubDate>Sat, 05 May 2018 15:11:07 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2018/05/faccione.jpeg</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>841</wp:post_id>
		<wp:post_date><![CDATA[2018-05-05 15:11:07]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2018-05-05 15:11:07]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[closed]]></wp:ping_status>
		<wp:post_name><![CDATA[faccione]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>112</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2018/05/faccione.jpeg]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2018/05/faccione.jpeg]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attachment_metadata]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:5:{s:5:"width";i:128;s:6:"height";i:128;s:4:"file";s:21:"2018/05/faccione.jpeg";s:5:"sizes";a:1:{s:25:"tech-literacy-service-img";a:4:{s:4:"file";s:21:"faccione-100x100.jpeg";s:5:"width";i:100;s:6:"height";i:100;s:9:"mime-type";s:10:"image/jpeg";}}s:10:"image_meta";a:12:{s:8:"aperture";s:1:"0";s:6:"credit";s:0:"";s:6:"camera";s:0:"";s:7:"caption";s:0:"";s:17:"created_timestamp";s:1:"0";s:9:"copyright";s:0:"";s:12:"focal_length";s:1:"0";s:3:"iso";s:1:"0";s:13:"shutter_speed";s:1:"0";s:5:"title";s:0:"";s:11:"orientation";s:1:"0";s:8:"keywords";a:0:{}}}]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>Featured Links</title>
		<link>http://www.adellera.it/featured-links/</link>
		<pubDate>Sat, 05 May 2018 16:34:32 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/?page_id=851</guid>
		<description></description>
		<content:encoded><![CDATA[<h4>Links (alphabetical order)</h4>
<ul class="links">
 	<li><a href="https://connor-mcdonald.com/">Connor McDonald</a></li>
 	<li><a href="http://www.jlcomp.demon.co.uk/">Jonathan Lewis</a></li>
 	<li><a href="http://www.juliandyke.com/">Julian Dyke</a></li>
 	<li><a href="http://www.oaktable.net/">Oak Table</a></li>
 	<li><a href="http://www.ixora.com.au/">Steve Adams</a></li>
 	<li><a href="http://www.centrexcc.com/">Wolfgang Breitling</a></li>
</ul>
<h4>Blogroll (alphabetical order)</h4>
<ul class="links">
 	<li><a href="http://www.oracle-developer.net/">Adrian Billington</a></li>
 	<li><a href="http://blogs.oracle.com/optimizer/">CBO Development Group</a></li>
 	<li><a href="http://antognini.ch/blog/">Christian Antognini</a></li>
 	<li><a href="http://coskan.wordpress.com/">Coskan Gundogar</a></li>
 	<li><a href="http://oracledoug.com/serendipity/">Doug Burns</a></li>
 	<li><a href="http://structureddata.org/">Greg Rahn</a></li>
 	<li><a href="http://iggyfernandez.wordpress.com/">Iggy Fernandez</a></li>
 	<li><a href="http://www.jamesmorle.com/">James Morle</a></li>
 	<li><a href="http://jonathanlewis.wordpress.com/all-postings/">Jonathan Lewis</a></li>
 	<li><a href="http://kevinclosson.wordpress.com/">Kevin Closson</a></li>
 	<li><a href="http://oracle-randolf.blogspot.it/">Randolf Geist</a></li>
 	<li><a href="https://richardfoote.wordpress.com/">Richard Foote</a></li>
 	<li><a href="http://orainternals.wordpress.com">Riyaj Shamsudeen</a></li>
 	<li><a href="http://blog.tanelpoder.com/">Tanel Poder</a></li>
 	<li><a href="http://thehelsinkideclaration.blogspot.com/">Toon Koppelaars</a></li>
</ul>]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>851</wp:post_id>
		<wp:post_date><![CDATA[2018-05-05 17:34:32]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2018-05-05 16:34:32]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[closed]]></wp:comment_status>
		<wp:ping_status><![CDATA[closed]]></wp:ping_status>
		<wp:post_name><![CDATA[featured-links]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>90</wp:menu_order>
		<wp:post_type><![CDATA[page]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
														<wp:postmeta>
		<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
		<wp:meta_value><![CDATA[2]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_portfolio_layout]]></wp:meta_key>
		<wp:meta_value><![CDATA[2col]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_masonry]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_sidebar]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_text]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_portfolio_filter_status]]></wp:meta_key>
		<wp:meta_value><![CDATA[show]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_gap]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_blogpage_layout]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_pagesidebar_layout]]></wp:meta_key>
		<wp:meta_value><![CDATA[right]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_sidebar_one]]></wp:meta_key>
		<wp:meta_value><![CDATA[sidebar-1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_sidebar_two]]></wp:meta_key>
		<wp:meta_value><![CDATA[sidebar-1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_title_bar]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_title_text]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_breadcrumb]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_breadcrumb_char]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>cropped-faccione.jpeg</title>
		<link>http://www.adellera.it/cropped-faccione-jpeg/</link>
		<pubDate>Sun, 06 May 2018 09:29:31 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/wp-content/uploads/2018/05/cropped-faccione.jpeg</guid>
		<description></description>
		<content:encoded><![CDATA[http://34.247.94.223/wp-content/uploads/2018/05/cropped-faccione.jpeg]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>869</wp:post_id>
		<wp:post_date><![CDATA[2018-05-06 10:29:31]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2018-05-06 09:29:31]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[closed]]></wp:ping_status>
		<wp:post_name><![CDATA[cropped-faccione-jpeg]]></wp:post_name>
		<wp:status><![CDATA[inherit]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[attachment]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
						<wp:attachment_url><![CDATA[http://www.adellera.it/wp-content/uploads/2018/05/cropped-faccione.jpeg]]></wp:attachment_url>
											<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attached_file]]></wp:meta_key>
		<wp:meta_value><![CDATA[2018/05/cropped-faccione.jpeg]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attachment_context]]></wp:meta_key>
		<wp:meta_value><![CDATA[site-icon]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_wp_attachment_metadata]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:5:{s:5:"width";i:512;s:6:"height";i:512;s:4:"file";s:29:"2018/05/cropped-faccione.jpeg";s:5:"sizes";a:15:{s:9:"thumbnail";a:4:{s:4:"file";s:29:"cropped-faccione-150x150.jpeg";s:5:"width";i:150;s:6:"height";i:150;s:9:"mime-type";s:10:"image/jpeg";}s:6:"medium";a:4:{s:4:"file";s:29:"cropped-faccione-300x300.jpeg";s:5:"width";i:300;s:6:"height";i:300;s:9:"mime-type";s:10:"image/jpeg";}s:29:"tech-literacy-blog-full-width";a:4:{s:4:"file";s:29:"cropped-faccione-512x350.jpeg";s:5:"width";i:512;s:6:"height";i:350;s:9:"mime-type";s:10:"image/jpeg";}s:40:"tech-literacy-small-featured-image-width";a:4:{s:4:"file";s:29:"cropped-faccione-450x350.jpeg";s:5:"width";i:450;s:6:"height";i:350;s:9:"mime-type";s:10:"image/jpeg";}s:30:"tech-literacy-blog-large-width";a:4:{s:4:"file";s:29:"cropped-faccione-512x350.jpeg";s:5:"width";i:512;s:6:"height";i:350;s:9:"mime-type";s:10:"image/jpeg";}s:29:"tech-literacy-thumbnail-large";a:4:{s:4:"file";s:29:"cropped-faccione-400x200.jpeg";s:5:"width";i:400;s:6:"height";i:200;s:9:"mime-type";s:10:"image/jpeg";}s:29:"tech-literacy-thumbnail-small";a:4:{s:4:"file";s:28:"cropped-faccione-130x90.jpeg";s:5:"width";i:130;s:6:"height";i:90;s:9:"mime-type";s:10:"image/jpeg";}s:39:"tech-literacy-magazine_slider_thumbnail";a:4:{s:4:"file";s:29:"cropped-faccione-512x430.jpeg";s:5:"width";i:512;s:6:"height";i:430;s:9:"mime-type";s:10:"image/jpeg";}s:30:"tech-literacy-highlighted-post";a:4:{s:4:"file";s:29:"cropped-faccione-512x300.jpeg";s:5:"width";i:512;s:6:"height";i:300;s:9:"mime-type";s:10:"image/jpeg";}s:25:"tech-literacy-service-img";a:4:{s:4:"file";s:29:"cropped-faccione-100x100.jpeg";s:5:"width";i:100;s:6:"height";i:100;s:9:"mime-type";s:10:"image/jpeg";}s:30:"tech-literacy-recent-posts-img";a:4:{s:4:"file";s:29:"cropped-faccione-380x270.jpeg";s:5:"width";i:380;s:6:"height";i:270;s:9:"mime-type";s:10:"image/jpeg";}s:13:"site_icon-270";a:4:{s:4:"file";s:29:"cropped-faccione-270x270.jpeg";s:5:"width";i:270;s:6:"height";i:270;s:9:"mime-type";s:10:"image/jpeg";}s:13:"site_icon-192";a:4:{s:4:"file";s:29:"cropped-faccione-192x192.jpeg";s:5:"width";i:192;s:6:"height";i:192;s:9:"mime-type";s:10:"image/jpeg";}s:13:"site_icon-180";a:4:{s:4:"file";s:29:"cropped-faccione-180x180.jpeg";s:5:"width";i:180;s:6:"height";i:180;s:9:"mime-type";s:10:"image/jpeg";}s:12:"site_icon-32";a:4:{s:4:"file";s:27:"cropped-faccione-32x32.jpeg";s:5:"width";i:32;s:6:"height";i:32;s:9:"mime-type";s:10:"image/jpeg";}}s:10:"image_meta";a:12:{s:8:"aperture";s:1:"0";s:6:"credit";s:0:"";s:6:"camera";s:0:"";s:7:"caption";s:0:"";s:17:"created_timestamp";s:1:"0";s:9:"copyright";s:0:"";s:12:"focal_length";s:1:"0";s:3:"iso";s:1:"0";s:13:"shutter_speed";s:1:"0";s:5:"title";s:0:"";s:11:"orientation";s:1:"0";s:8:"keywords";a:0:{}}}]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_oembed_c3105c33c304b4d79dc3af0a3fab3682]]></wp:meta_key>
		<wp:meta_value><![CDATA[{{unknown}}]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>Archived</title>
		<link>http://www.adellera.it/archived/</link>
		<pubDate>Sun, 06 May 2018 15:17:47 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/?page_id=914</guid>
		<description></description>
		<content:encoded><![CDATA[[child_pages]]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>914</wp:post_id>
		<wp:post_date><![CDATA[2018-05-06 16:17:47]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2018-05-06 15:17:47]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[closed]]></wp:comment_status>
		<wp:ping_status><![CDATA[closed]]></wp:ping_status>
		<wp:post_name><![CDATA[archived]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[page]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
														<wp:postmeta>
		<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
		<wp:meta_value><![CDATA[2]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_portfolio_layout]]></wp:meta_key>
		<wp:meta_value><![CDATA[2col]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_masonry]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_sidebar]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_text]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_portfolio_filter_status]]></wp:meta_key>
		<wp:meta_value><![CDATA[show]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_gap]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_blogpage_layout]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_pagesidebar_layout]]></wp:meta_key>
		<wp:meta_value><![CDATA[right]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_sidebar_one]]></wp:meta_key>
		<wp:meta_value><![CDATA[sidebar-1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_sidebar_two]]></wp:meta_key>
		<wp:meta_value><![CDATA[sidebar-1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_title_bar]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_title_text]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_breadcrumb]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_breadcrumb_char]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title></title>
		<link>http://www.adellera.it/blog/2018/05/06/941/</link>
		<pubDate>Sun, 06 May 2018 16:01:55 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/?p=941</guid>
		<description></description>
		<content:encoded><![CDATA[ ]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>941</wp:post_id>
		<wp:post_date><![CDATA[2018-05-06 17:01:55]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2018-05-06 16:01:55]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[closed]]></wp:comment_status>
		<wp:ping_status><![CDATA[closed]]></wp:ping_status>
		<wp:post_name><![CDATA[941]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>2</wp:menu_order>
		<wp:post_type><![CDATA[nav_menu_item]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="nav_menu" nicename="primarymenu"><![CDATA[PrimaryMenu]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_type]]></wp:meta_key>
		<wp:meta_value><![CDATA[post_type]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_menu_item_parent]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_object_id]]></wp:meta_key>
		<wp:meta_value><![CDATA[914]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_object]]></wp:meta_key>
		<wp:meta_value><![CDATA[page]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_target]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_classes]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:1:{i:0;s:0:"";}]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_xfn]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_url]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>investigations</title>
		<link>http://www.adellera.it/blog/2018/05/06/investigations/</link>
		<pubDate>Sun, 06 May 2018 16:01:55 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/?p=942</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>942</wp:post_id>
		<wp:post_date><![CDATA[2018-05-06 17:01:55]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2018-05-06 16:01:55]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[closed]]></wp:comment_status>
		<wp:ping_status><![CDATA[closed]]></wp:ping_status>
		<wp:post_name><![CDATA[investigations]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>914</wp:post_parent>
		<wp:menu_order>3</wp:menu_order>
		<wp:post_type><![CDATA[nav_menu_item]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="nav_menu" nicename="primarymenu"><![CDATA[PrimaryMenu]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_type]]></wp:meta_key>
		<wp:meta_value><![CDATA[post_type]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_menu_item_parent]]></wp:meta_key>
		<wp:meta_value><![CDATA[941]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_object_id]]></wp:meta_key>
		<wp:meta_value><![CDATA[917]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_object]]></wp:meta_key>
		<wp:meta_value><![CDATA[page]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_target]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_classes]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:1:{i:0;s:0:"";}]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_xfn]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_url]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>personal</title>
		<link>http://www.adellera.it/blog/2018/05/06/personal/</link>
		<pubDate>Sun, 06 May 2018 16:01:55 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/?p=943</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>943</wp:post_id>
		<wp:post_date><![CDATA[2018-05-06 17:01:55]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2018-05-06 16:01:55]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[closed]]></wp:comment_status>
		<wp:ping_status><![CDATA[closed]]></wp:ping_status>
		<wp:post_name><![CDATA[personal]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>914</wp:post_parent>
		<wp:menu_order>4</wp:menu_order>
		<wp:post_type><![CDATA[nav_menu_item]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="nav_menu" nicename="primarymenu"><![CDATA[PrimaryMenu]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_type]]></wp:meta_key>
		<wp:meta_value><![CDATA[post_type]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_menu_item_parent]]></wp:meta_key>
		<wp:meta_value><![CDATA[941]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_object_id]]></wp:meta_key>
		<wp:meta_value><![CDATA[925]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_object]]></wp:meta_key>
		<wp:meta_value><![CDATA[page]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_target]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_classes]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:1:{i:0;s:0:"";}]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_xfn]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_url]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title></title>
		<link>http://www.adellera.it/blog/2018/05/06/945/</link>
		<pubDate>Sun, 06 May 2018 16:01:55 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/?p=945</guid>
		<description></description>
		<content:encoded><![CDATA[ ]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>945</wp:post_id>
		<wp:post_date><![CDATA[2018-05-06 17:01:55]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2018-05-06 16:01:55]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[closed]]></wp:comment_status>
		<wp:ping_status><![CDATA[closed]]></wp:ping_status>
		<wp:post_name><![CDATA[945]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>1</wp:menu_order>
		<wp:post_type><![CDATA[nav_menu_item]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="nav_menu" nicename="primarymenu"><![CDATA[PrimaryMenu]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_type]]></wp:meta_key>
		<wp:meta_value><![CDATA[post_type]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_menu_item_parent]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_object_id]]></wp:meta_key>
		<wp:meta_value><![CDATA[851]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_object]]></wp:meta_key>
		<wp:meta_value><![CDATA[page]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_target]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_classes]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:1:{i:0;s:0:"";}]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_xfn]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_url]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title></title>
		<link>http://www.adellera.it/blog/2018/05/06/947/</link>
		<pubDate>Sun, 06 May 2018 16:01:55 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/?p=947</guid>
		<description></description>
		<content:encoded><![CDATA[ ]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>947</wp:post_id>
		<wp:post_date><![CDATA[2018-05-06 17:01:55]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2018-05-06 16:01:55]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[closed]]></wp:comment_status>
		<wp:ping_status><![CDATA[closed]]></wp:ping_status>
		<wp:post_name><![CDATA[947]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>6</wp:menu_order>
		<wp:post_type><![CDATA[nav_menu_item]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="nav_menu" nicename="primarymenu"><![CDATA[PrimaryMenu]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_type]]></wp:meta_key>
		<wp:meta_value><![CDATA[post_type]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_menu_item_parent]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_object_id]]></wp:meta_key>
		<wp:meta_value><![CDATA[112]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_object]]></wp:meta_key>
		<wp:meta_value><![CDATA[page]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_target]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_classes]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:1:{i:0;s:0:"";}]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_xfn]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_url]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>GitHub</title>
		<link>http://www.adellera.it/blog/2018/05/06/github2/</link>
		<pubDate>Sun, 06 May 2018 16:01:55 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/?p=949</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>949</wp:post_id>
		<wp:post_date><![CDATA[2018-05-06 17:01:55]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2018-05-06 16:01:55]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[closed]]></wp:comment_status>
		<wp:ping_status><![CDATA[closed]]></wp:ping_status>
		<wp:post_name><![CDATA[github2]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>7</wp:menu_order>
		<wp:post_type><![CDATA[nav_menu_item]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="nav_menu" nicename="primarymenu"><![CDATA[PrimaryMenu]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_type]]></wp:meta_key>
		<wp:meta_value><![CDATA[custom]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_menu_item_parent]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_object_id]]></wp:meta_key>
		<wp:meta_value><![CDATA[949]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_object]]></wp:meta_key>
		<wp:meta_value><![CDATA[custom]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_target]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_classes]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:1:{i:0;s:0:"";}]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_xfn]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_url]]></wp:meta_key>
		<wp:meta_value><![CDATA[https://github.com/alberto-dellera]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title></title>
		<link>http://www.adellera.it/blog/2018/05/26/962/</link>
		<pubDate>Sat, 26 May 2018 09:23:35 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/blog/2018/05/26/962/</guid>
		<description></description>
		<content:encoded><![CDATA[ ]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>962</wp:post_id>
		<wp:post_date><![CDATA[2018-05-26 10:23:35]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2018-05-26 09:23:35]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[closed]]></wp:comment_status>
		<wp:ping_status><![CDATA[closed]]></wp:ping_status>
		<wp:post_name><![CDATA[962]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>5</wp:menu_order>
		<wp:post_type><![CDATA[nav_menu_item]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="nav_menu" nicename="primarymenu"><![CDATA[PrimaryMenu]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_type]]></wp:meta_key>
		<wp:meta_value><![CDATA[post_type]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_menu_item_parent]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_object_id]]></wp:meta_key>
		<wp:meta_value><![CDATA[961]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_object]]></wp:meta_key>
		<wp:meta_value><![CDATA[page]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_target]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_classes]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:1:{i:0;s:0:"";}]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_xfn]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_menu_item_url]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>Expected cardinality (Formal Bricks)</title>
		<link>http://www.adellera.it/?p=8</link>
		<pubDate>Mon, 04 May 2009 19:41:19 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=8</guid>
		<description></description>
		<content:encoded><![CDATA[This is the first of a series of posts where I'm going to take a simple and sometimes trivial Oracle-related scenario and reason about it using formal tools (that usually translates to "math" and "statistics"). This is a way of learning that has always rewarded me with a lot of insight and intuitions; hopefully that will apply to you as well.

This post is going to formally discuss what "expected cardinality" means.

As it is well known, one of the main task of the CBO is to estimate the number of rows (the cardinality) produced by each plan row (aka "row source operation") of a candidate plan, before the plan itself is executed. 
The cardinality is usually a random variable - one of the reasons being that the SQL statement or fragment contains inputs (bind variables) whose actual value at execution time dictates the actual cardinality - and the inputs themselves are random variables, since they are decided by an external system (a "client") in a non-deterministic fashion. Given a random variable it is possible to calculate its "<a href="http://en.wikipedia.org/wiki/Expected_value">expected value</a>" (which is basically the same as the "average value"), which is what the CBO calculates (or tries to estimate).

So, let's consider the simplest possible scenario of a filter predicate:
[sql]
select ... 
  from t
 where x = :x;
[/sql]
and initially consider this table as an example:
[sql]
SQL> select * from t order by x;
         X
----------
         1
         4
         4
         4
         4
[/sql]
Let count(:x) be the number of rows fetched by this statement; obviously count(1)=1, count(4)=4, and count(:x) = 0 for all the other values of :x. Now, which is the average number of rows retrieved, that in statistics is usually called the <b>expected value</b> and denoted with E[count(:x)] ?

Letting w(:x) ("w" stands for "workload") the <a href="http://en.wikipedia.org/wiki/Probability_mass_function">probability mass function</a> (often named "distribution" with a slight misnomer) of the random variable :x (which is obviously dictated by the client), we have
[text]
E[count(:x)] = sum ( count(:x) * w(:x) )

over all possible values of :x
[/text]
For example, if the client always set :x = 1, then w(1)=1 and is zero for all other values, hence E[count(:x)] = 1 * 1 + 4 * 0 = 1. If the client sets :x to 1 and 4 with equal probability, E[count(:x)] = 1 * 0.5 + 4 * 0.5 = 2.5. 

It is interesting to consider the most important cases, and see how they apply to the CBO.
<h2>Uniform column distribution ( uniform count(:x) )</h2>
If count(:x) = constant = num_rows / num_distinct, we have
[text]
E[count(:x)] = num_rows / num_distinct * sum ( w (:x) ) 
[/text]
and, assuming that sum ( w (:x) ) = 1, that is, that <i>the client looks only for values contained in the table</i>, we have the well-known and intuitive formula that is used by the CBO in many scenarios (for example when the column has no histogram and :x is inside the min-max interval):
[text]
E[count(:x)] = num_rows / num_distinct 
[/text] 
Note in passing that assuming that sum ( w (:x) ) = 1 is the same of assuming that the statement always retrieves at least one row; the latter is an assumption frequently made by the CBO algorithms. Actually it is, in my opinion, the only reasonable assumption that the CBO can make, having no idea (currently?) of the actual distribution of values used by the client - and it is true, after all, that most of the time the client wants simply to <i>retrieve</i> rows  that it knows are already there.
But "most of the time" does not mean "always"; for example the client might want to simply <i>check</i> for the (non) existence of a BAD record (or, a NEW record in a "queue" table) which is (almost) never there, in which case the expected cardinality would be (almost) zero; in this case, the formula above obviously overestimates the cardinality.

<h2>Uniform workload distribution ( uniform w(:x) )</h2>
In this case, again assuming that sum ( w (:x) ) = 1, we have w(:x) = 1 / num_distinct and hence the previous formula again, since
[text]
E[count(:x)] = sum ( count(:x) ) / num_distinct = num_rows / num_distinct
[/text]
side note: it can be shown that the variance var[count(:x)] was zero for the previous case and can be far from zero in this case, hence in this second case the formula may not represent the population very well (quite obviously). Anyway, the expected value is exactly the same.

More interestingly, an uniform distribution of w(.) is what we would get if table t were a child table (say, the ORDERS table) and we were joining from the parent (the CUSTOMERS table) without any preference for one record or the other (uniform distribution for the workload on the parent) - regardless of the child table having or not a uniform count(:x). This is regardless of whether we are joining properly (by using a join statement) or fetching the child rows with another statement: the second statement would experience this distribution. In fact, this case is the basis for the so called "NewDensity" used for height-balanced histograms, part of a set of "density improvements" to the CBO introduced in 10.2.0.4 and 11g, as we will see in another post.

<h2>Matched count(:x) and w(:x)</h2>
Now assume that w(:x) = count(:x) / num_rows, that is, that if a value accounts for 42% of the rows of the table it gets issued by the client 42% times; this is the distribution you would see if you continuosly picked a row at random, and then retrieve all the rows with the same value of x. We have 
[text]
E[count(:x)] = sum ( count(:x) * count(:x) / num_rows ) =
 = sum ( count(:x) ^ 2) / num_rows
[/text]
Strange as it might seem, this formula is the core calculation of the value of the ("old") density that it is computed by dbms_stats - as we will discuss in another post.
]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>8</wp:post_id>
		<wp:post_date><![CDATA[2009-05-04 19:41:19]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-05-04 19:41:19]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[expected-cardinality-formal-bricks]]></wp:post_name>
		<wp:status><![CDATA[draft]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
						</item>
					<item>
		<title>the (old) density of Height-Balanced Histograms</title>
		<link>http://www.adellera.it/?p=111</link>
		<pubDate></pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=111</guid>
		<description></description>
		<content:encoded><![CDATA[In this and in the next post we are going to explore the formula used by dbms_stats to compute the "density" column statistic, and especially we are going to show and discuss the <b>rationale</b> for it. We will rehash also how density is used by the CBO to estimate the cardinality of a simple equality filter predicate. We will consider, for simplicity, only the (most complex) case of Height-Balanced histograms, filtered value inside the min-max interval of the filter column, and not-null values.

In this post we will discuss the pre-10.2.0.4 behaviour; in the next post we will discuss the 10.2.0.4 (and 11g) behaviour, that is, the new "NewDensity" computation that supersedes the previous one, relabeled as "OldDensity" (both the "NewDensity" and "OldDensity" names can be considered somewhat "official", sice they are used in 11g 10053 trace files).

So, we are going to consider a simple filter predicate on table t ("value" is the column name, "client_value" a client-provided literal):
[sql]
select ... 
  from t
 where value = <client_value>;
[/sql]
as a test case, we will consider the one contained in script TODO (a zip file that contains both the script and its log), run in 9.2.0.8. This test case builds the following distribution for value:
[sql]
SQL> select value, count(*)
  2    from t
  3   group by value
  4   order by value;

     VALUE   COUNT(*)
---------- ----------
         1          1
         2          2
         4          4
         8          8
        16         16
        64         64
[/sql]
And then computes a SIZE 5 Height-Balanced histogram. The resulting histogram from dba_histograms is as follows (note that I have added the column POPULARITY that marks popular values with "1"; EP is short for column ENDPOINT_NUMBER, VALUE is column ENDPOINT_VALUE):
[sql]
SQL> select ep, value, popularity from formatted_hist;

        EP      VALUE POPULARITY
---------- ---------- ----------
         0          1          0
         1         16          0
         5         64          1
[/sql]
As it is well known, when client_value is a popular value (i.e. 64 in this case), density is not used for the expected cardinality estimation. When client_value is not popular (that is, either equal to a nonpopular value - 1 and 16 in this case - or not contained in the histograms - 2.4 for example) but contained in the closed min-max interval (1-64 in this case), the formula used for the expected cardinality estimation is equal to (Note: I'm going to use the conventions defined in this previous TODO post, that I'm going to reference a lot in the following):
[text]
E[count(client_value)] = density * num_rows
[/text]
in our case, since from the script log we see that density = .115789474 and num_rows=95, we get density * num_rows=11 (note the perfectly integer value).

The formula used by dbms_stats was published in Jonathan Lewis' book <a href="http://www.jlcomp.demon.co.uk/cbo_book/ind_book.html">Cost Based Oracle</a> (page 172) and Wolfgang Breitling's presentation <a href="http://www.centrexcc.com/">Histograms - Myths and Facts</a>. The key fact is that the formula takes as input the rows of what I've nicknamed the not-popular subtable (NPS), that is, the original table without the rows whose values are  popular values (in this case, 64 is the only popular value). Letting num_rows_nps the number of rows of the NPS (for our example, num_rows_nps=1+2+4+8+16=31), we have:
[text]
   density = (1 / num_rows) *
   sum (count (value) ^ 2) / num_rows_nps 
   summed over all values of the NPS
[/text]
The script performs this calculation automatically; it is anyway instructive to perform the calculation manually at least one time:
density = (1/95) * (1*1+2*2+4*4+8*8+16*16) * (1/31)= .115789474
that matches perfectly the density we observed in the script log before.

But what is the statistical rationale for this seemingly strange computation ? Well, the resulting expected cardinality computation is 
[text]
E[count(client_value)] = sum (count (value) ^ 2) / num_rows_nps
for client_value not popular
[/text]
which is exactly the "Matched count(:x) and w(:x)" (the third) case considered in the previous post mentioned above, <i>applied to the NPS instead of the whole table</i>.

So, after having understood the previous post, explaining the rationale behind "density" is relatively simple. The CBO knows that client_value is not a popular values, hence it is contained in the NPS, and applies the usual reasoning and assumptions that it makes for tables without histograms to the NPS - but changing the assumption about the shape of w(client_value). It assumes that the more a certain client_value is represented in the table, the more it will be submitted by the client; more precisely, that if X% of rows has a certain common value, X% of user-submitted statements that "hit" the NPS will ask for that value. Density is pre-set by dbms_stats to produce the resulting value.

As we will see in the next post, the "NewDensity" changes in 10.2.0.4 consist mostly in replacing this assumption about w(client_value) with the standard assumptions made for columns without histograms - hence this assumption can be considered "deprecated".

In the next post, we will discuss the new, improved formulae.
]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>111</wp:post_id>
		<wp:post_date><![CDATA[2009-05-14 14:22:03]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[0000-00-00 00:00:00]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[]]></wp:post_name>
		<wp:status><![CDATA[draft]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
						</item>
					<item>
		<title>Why blogging ?</title>
		<link>http://www.adellera.it/blog/2009/05/24/why-blogging/</link>
		<pubDate>Sun, 24 May 2009 14:11:19 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=222</guid>
		<description></description>
		<content:encoded><![CDATA[Mainly because I like to write, and people usually like my writings. So, why not ?

Also - because it is a good way of learning. When I was a student, I remember that my favorite reharsal technique was to pretend I was explaining the topic to an imaginary person that knew nothing about it - and that technique worked very well, because when explaining, I very frequently discovered flaws in my knowledge that prompted me to improve even more. Blogging has the same advantage - with the additional bonus that the readers are real, hence they will discover (and hopefully tell me) much more flaws than my good old imaginary friend. A flaw discovered today is an error avoided in production tomorrow.

Then there's interaction with others, that will for sure provide me with interesting insights and other topics to investigate, or even a full-blown discussion extending across posts, blog pages and even ... restaurant tables.

So, here I am. Hope that you will find this Oracle blog useful ...]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>222</wp:post_id>
		<wp:post_date><![CDATA[2009-05-24 16:11:19]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-05-24 14:11:19]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[why-blogging]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
						<wp:comment>
			<wp:comment_id>2</wp:comment_id>
			<wp:comment_author><![CDATA[Amardeep Sidhu]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[amardeepsidhu@amardeepsidhu.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://amardeepsidhu.com/blog</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[122.163.204.218]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-05-25 18:40:40]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-05-25 16:40:40]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Alberto 

Welcome to the blogging world ! 

All the best :)]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>3</wp:comment_id>
			<wp:comment_author><![CDATA[Blogroll Additions: Alberto Dell&#8217;Era &amp; Christian Antognini | Structured Data]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://structureddata.org/2009/05/25/blogroll-additions-alberto-dellera-christian-antognini/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[208.97.183.4]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-05-25 19:41:53]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-05-25 17:41:53]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] OakTable Network member, Alberto Dell&#8217;Era, has starting blogging and I wanted mention it to my readers as well as add it to my blogroll. I&#8217;ve followed [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>Order of keys inside index blocks</title>
		<link>http://www.adellera.it/blog/2009/05/24/order-keys-inside-index-blocks/</link>
		<pubDate>Sun, 24 May 2009 16:11:56 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=233</guid>
		<description></description>
		<content:encoded><![CDATA[In this post we are going to illustrate how index keys are ordered inside a leaf block of an Oracle B+tree index.

It is well known that index blocks share most of their structure with "regular" (heap) table blocks; in particular, they share most of the way entries are stored inside the block. In tables, a row can be placed anywhere in the bottom part of the block (which is essentially managed like an "heap", in which the exact memory address that the row is stored at is not important); its row address is recorded into one of the slots of a vector named "row directory", located near the beginning of the block. 

The address of the row is not published externally: only its position inside the row directory is (as the last part of the rowid, usually named "row number"), in order to enable the kernel to move the row inside the "bottom heap" as it likes - all it has to do is to update the row directory with the new address after the move, and the change will be perfectly transparent to the outside world. This of course enables the optimal utilization of the limited space inside the block, since space inside it can be re-organized at will.

Index entries are stored in the index blocks in exactly the same fashion (and probably much of the code that manages them is the very same, since, for example, they are frequently named "rows" in block dumps and documentation, a convention we will keep in this post). The only difference is that the position inside the row directory is not published as well (there is not such thing as a "keyid" that needs to be known outside of the block); the kernel uses this additional degree of freedom to keep the row directory <b>ordered by key value</b> (in binary order). 

Let's check it by using this <a href="http://34.247.94.223/wp-content/uploads/2009/05/post_0005.zip">test case</a>. The script creates a table and defines a one-column index on it:
[sql]
create table t (x varchar2(10));
create index t_idx on t(x);
[/sql]
and then inserts eight rows in "random" order:
[sql]
insert into t values('000000');
insert into t values('777777');
insert into t values('111111');
insert into t values('666666');
insert into t values('222222');
insert into t values('555555');
insert into t values('333333');
insert into t values('444444');
[/sql]
The block dump (in 11.1.0.7) of the leaf (and root) block reveals the following index keys (my annotations are enclosed in curly braces):
[text]
...
kdxlebksz 8036
row#0[8020] flag: ------, lock: 2, len=16
col 0; len 6; (6):  30 30 30 30 30 30    { '000000' }
col 1; len 6; (6):  01 00 1c 74 00 00
row#1[7988] flag: ------, lock: 2, len=16
col 0; len 6; (6):  31 31 31 31 31 31    { '111111' }
col 1; len 6; (6):  01 00 1c 74 00 02
row#2[7956] flag: ------, lock: 2, len=16
col 0; len 6; (6):  32 32 32 32 32 32    { '222222' }
col 1; len 6; (6):  01 00 1c 74 00 04
row#3[7924] flag: ------, lock: 2, len=16
col 0; len 6; (6):  33 33 33 33 33 33    { '333333' }
col 1; len 6; (6):  01 00 1c 74 00 06
row#4[7908] flag: ------, lock: 2, len=16
col 0; len 6; (6):  34 34 34 34 34 34    { '444444' }
col 1; len 6; (6):  01 00 1c 74 00 07
row#5[7940] flag: ------, lock: 2, len=16
col 0; len 6; (6):  35 35 35 35 35 35    { '555555' }
col 1; len 6; (6):  01 00 1c 74 00 05
row#6[7972] flag: ------, lock: 2, len=16
col 0; len 6; (6):  36 36 36 36 36 36    { '666666' }
col 1; len 6; (6):  01 00 1c 74 00 03
row#7[8004] flag: ------, lock: 2, len=16
col 0; len 6; (6):  37 37 37 37 37 37    { '777777' }
col 1; len 6; (6):  01 00 1c 74 00 01
----- end of leaf block dump -----
...
[/text]
The address where the "row" (actually an index key) is stored is dumped between square brackets; for example, row#0 (which is the '000000' entry) is stored at address [8020], near the end of the block. You might note that the rows are placed bottom-up in insert order (the first row that was inserted was '000000' and was placed at [8020]; the second was '777777' and was placed at [8004], right above the first, etcetera); they are not ordered by binary value. 

The binary dump of the portion of the block containing the "row directory" is
[text]
C6E0280 00000000 00001F64 1F341F54 1EF41F14  [....d...T.4.....]
C6E0290 1F041EE4 1F441F24 10E81128 106810A8  [....$.D.(.....h.]
[/text]
removing auxiliary tracing info, grouping the bytes in two-byte chunks and converting them in decimal, we have
[text]
  1F64=8036 end of "bottom heap" (kdxlebksz), also 8020 + 16
  1F34=7988 address of '111111'   
  1F54=8020 address of '000000'
  1EF4=7924 address of '333333'
  1F14=7956 address of '222222'
  1F04=7940 address of '555555'
  1EE4=7908 address of '444444'
  1F44=8004 address of '777777'
  1F24=7972 address of '666666'
[/text]
that is, the addresses in the row directory are ordered by the (binary) value of the key they point to - remember that you must swap the high and low 2-byte quantities in each 32-bit word (the usual <a href="http://en.wikipedia.org/wiki/Endianness">little-endian</a> ordering; I haven't checked whether the results would be different on a machine that is not little-endian, as my one - an x86 - is).

So the number after the hash is, indeed, the position (aka index) in the row directory vector; so "row#0[8020]" means "row at position 0 in the row directory, the row being placed at address 8020", and the index positions are actually stored ordered.

The reason for this ordering is to improve the efficiency of typical visits to the index block. Consider a range scan, when the kernel has to find all the index keys contained in the search interval [min_extreme, max_extreme] (possibly min_extreme=max_extreme for equality predicates). As it is well known, the kernel first walks the branch blocks to identify the leaf block that contains min_extreme (or max_extreme, but that would be the same for our discussion); then, it has to identify all the keys that are >= min_extreme and <= max_extreme. Thanks to the ordering, it can simply perform a <a href="http://en.wikipedia.org/wiki/Binary_search">binary search</a> to locate the first key >= min_extreme, and then walk the next entries in the row directory until it gets to the last one that is <= max_extreme (possibly jumping on the next leaf block). Without this ordering, the kernel would be forced to visit all the keys contained in the block. 

The advantage is huge, since visiting all the keys is a O( N ) operation, while a <b>binary search has only O ( log(2,N) ) complexity</b>. 

To fully appreciate this on a concrete example, consider that each key of our example needs 16+2 bytes of storage, hence a perfectly packed 8K block might contain approximately 8000 / 18 = 444 keys. Thanks to the ordering, for the very frequent equality search (classic for Primary Key searches for example), the processing consists essentially of the binary search only - hence the number of keys to be considered are down to about ceil( log(2, 444) ) = 9, thus consuming only 9/444 = 2% (!!) of the resources. 

It is also worth remembering that this way, only a portion of the block is accessed, thus needing less accesses to central memory (it is unlikely in fact that the whole 8K can be found in the processor's caches), thus reducing the elapsed time considerably since stalling for central memory is a very common bottleneck in database systems - and thus improving scalability for the whole system thanks to the reduction of the traffic on the memory bus.

Of course there's a price to be paid for modifications, since each modification has to keep the row directory ordered, thus shifting the slots of the row directory, which is a relatively expensive operation. Oracle pays an higher bill at modification time to save (hugely) at read time.

As a final observation: note that the branch block visit can be considered a binary search as well, "pre-calculated" by the B+tree structure - the ordering inside a block is just the same divide-and-conquer algorithm applied in a different way.]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>233</wp:post_id>
		<wp:post_date><![CDATA[2009-05-24 18:11:56]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-05-24 16:11:56]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[order-keys-inside-index-blocks]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="indexes"><![CDATA[Indexes]]></category>
						<wp:comment>
			<wp:comment_id>4</wp:comment_id>
			<wp:comment_author><![CDATA[Two Excellent Index Related Blog Posts &laquo; Richard Foote&#8217;s Oracle Blog]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://richardfoote.wordpress.com/2009/05/25/two-excellent-index-related-blog-posts/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[72.233.96.150]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-05-25 13:15:13]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-05-25 11:15:13]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] second is by Alberto Dell&#8217;Era who discusses in a post called Order of keys inside index blocks exactly how Oracle orders and stores the index keys within an index block. I&#8217;ve exchanged a [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>5</wp:comment_id>
			<wp:comment_author><![CDATA[Cristian]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[cristian.cudizio@yahoo.it]]></wp:comment_author_email>
			<wp:comment_author_url>http://cristiancudizio.wordpress.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[88.42.187.162]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-05-29 17:48:28]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-05-29 15:48:28]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto,
congratulations, i will try to follow your example writing a question in English (correct me if i make some mistakes :) ). I've get in trouble with the point in wich you demonstrate that items in row directory are ordered by binary value of the key. Why are the byte grouped by groups of two? Another question is about storage needed by each key, you say that in your example is 16+2 bytes: what are the 4+2 bytes over keys used for?]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>6</wp:comment_id>
			<wp:comment_author><![CDATA[zfriese]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[zfriese@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[157.130.150.242]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-06-03 15:15:11]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-06-03 13:15:11]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Great article! However, your use of asymptotic notation is non-standard, and might be confusing. Consider simplifying to O(log n). Binary searches have logarithmic complexity. Thanks.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>7</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-06-04 16:45:08]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-06-04 14:45:08]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Sorry for answering late, since I've just got back from a internet-less vacation :)

@Cristian

the bytes are ordered in groups of two because in order to address a byte inside the block we need 16 bits (2^16 = 65535, which is enough for all configurable dimensions of the Oracle block). 

We need 16+2 bytes because 16 is the length of the entry itself (see len=16 in the block dump) and 2 is the size of the pointer in the row directory that points to the entry.

@zfriese

I will check whether I can find a standard notation to express the logarithm base as well; even if the base is not strictly necessary when performing big-O analysis, I think it adds value in this context. 
Thanks for your comment.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>8</wp:comment_id>
			<wp:comment_author><![CDATA[Dennis Sun]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[dennissunny@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[208.68.129.51]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-07-01 22:28:21]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-07-01 20:28:21]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Great job. I tested it on sun sparc server(big-endians). don't need to swap the high and low 2 bytes:
[text]
106751080 00000000 1F600000 1F501F30 1F101EF0  [.....`...P.0....]
106751090 1EE01F00 1F201F40 1D391D1D 1D011CE5  [..... .@.9......]


row#0[8016] flag: ------, lock: 2, len=16            
col 0; len 6; (6):  30 30 30 30 30 30
col 1; len 6; (6):  01 80 05 7f 00 00
row#1[7984] flag: ------, lock: 2, len=16            
col 0; len 6; (6):  31 31 31 31 31 31
col 1; len 6; (6):  01 80 05 7f 00 02
row#2[7952] flag: ------, lock: 2, len=16                
col 0; len 6; (6):  32 32 32 32 32 32
col 1; len 6; (6):  01 80 05 7f 00 04
row#3[7920] flag: ------, lock: 2, len=16            
col 0; len 6; (6):  33 33 33 33 33 33
col 1; len 6; (6):  01 80 05 7f 00 06
row#4[7904] flag: ------, lock: 2, len=16            
col 0; len 6; (6):  34 34 34 34 34 34
col 1; len 6; (6):  01 80 05 7f 00 07
row#5[7936] flag: ------, lock: 2, len=16
col 0; len 6; (6):  35 35 35 35 35 35
col 1; len 6; (6):  01 80 05 7f 00 05
row#6[7968] flag: ------, lock: 2, len=16
col 0; len 6; (6):  36 36 36 36 36 36
col 1; len 6; (6):  01 80 05 7f 00 03
row#7[8000] flag: ------, lock: 2, len=16
col 0; len 6; (6):  37 37 37 37 37 37
col 1; len 6; (6):  01 80 05 7f 00 01
[/text] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>9</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[217.201.193.75]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-07-02 00:00:36]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-07-01 22:00:36]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@Dennis

Thank you very much! Your observation makes this post complete ... 

For better readability, here's your observation "decoded" from hex to decimal, in the same format as above:
[text]
1F50=8016 address of '000000'
1F30=7984 address of '111111'
1F10=7952 address of '222222'
1EF0=7920 address of '333333'
1EE0=7904 address of '444444'
1F00=7936 address of '555555'
1F20=7968 address of '666666'
1F40=8000 address of '777777'
[/text] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>8</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>10</wp:comment_id>
			<wp:comment_author><![CDATA[Kostas Hairopoulos]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[khairop@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[115.95.47.252]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-08-31 18:10:27]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-08-31 16:10:27]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Alberto, thank you for sharing this article with us however can please give some lights in your phrase like "  ... that is, the addresses in the row directory are ordered by the (binary) value of the key they point to".
Its still not clear to me. 
As far as I understand from the leaf block dump, the row slot in row directory follows the key order  ( '0000000' is in slot 0, '11111111' is in slot 1 etc) and not the. What will be the order of a new row number 8 and value  '88888888' in position  7898? 

Best Regards,
Kostas Hairopoulos


Thank you in advance,
khair]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>11</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[93.33.134.204]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-09-01 10:29:08]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-09-01 08:29:08]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@Kostas

Yes, slot#0 "contains" '00000000', slot#1 "contains" '11111111', and hence a new row with the key value of '88888888' would be "in" slot#8, wherever it gets inserted in the block. 

Note that I have placed "contains" in double quotes because actually, each slot contains the <i>address</i> of the index key, not the index key itself. For example, in the example of the post above, slot#0 contains the number 8020 that is the address of first byte of its key '00000000'.

The block dump routine simply walks the row directory (an array of 16 bit elements) starting from the first slot and prints both the address and the key value.

Note: of course the index key order is as above because my database charset is AL32UTF8, and hence the binary representation of the pure-ASCII strings I have used is ordered as the language conventions dictate. Index keys are always stored in the block using the binary value.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>10</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>12</wp:comment_id>
			<wp:comment_author><![CDATA[DSLR-A900]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[abraham1@uymail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[176.195.165.59]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2011-11-13 01:13:06]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2011-11-12 23:13:06]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[è stato molto interessante da leggere. Voglio citare il tuo post nel mio blog . Si può ? E tu et un account su Twitter?]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>13</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2011-11-14 13:12:59]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2011-11-14 11:12:59]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Certo che puoi citarlo ... no, non ho account Twitter ;)]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>12</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>Optimizing SQL statements with xplan</title>
		<link>http://www.adellera.it/blog/2009/06/07/optimizing-sql-statements-with-xplan/</link>
		<pubDate>Sun, 07 Jun 2009 15:07:06 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=259</guid>
		<description></description>
		<content:encoded><![CDATA[<a href="http://www.adellera.it/scripts_etcetera/xplan/index.html">Xplan</a> is a utility to simplify and automate the first part of every SQL statement tuning effort, that is, collecting the real plan of the statement, its execution statistics (number of executions, number of buffer gets performed, etc), getting the definition of all the accessed tables (and their indexes), and, last but not least, the CBO-related statistics of the accessed tables (and their indexes and columns) stored in the data dictionary by dbms_stats or ANALYZE.

The utility doesn't need to install any object inside the database since it is a read-only sqlplus script, thus needing minimal support from the customers' DBA production team. It is also so simple to run that I am normally able to ask people with minimal Oracle skills to run xplan on my behalf and then to ship me the output report - with obvious benefits for all. 

The report is light and concise, designed with the needs of the SQL tuner in mind; to illustrate, the following small fragment of the report helps to get an immediate picture of the indexes layout:
[text]
-----------------------------------
|ColName     |1|2|3|4|5|P|U1|U2|R1|
--------------------U-U------------
|X           |1|1|2|1| |1|  |2 |  |
|PADDING     | | |1|2|1|2|R1|1 |  |
|RR          | | | | | | |  |  |1 |
|SYS_NC00004$|2| | | | | |  |  |  |
|SYS_NC00005$| |2| | | | |  |  |  |
-----------------------------------
[/text]

You can see at a glance that column X is indexed as the first column of indexes #1, #2 and #4 (#4 being a unique index) and as the second of index #3. Constraints are reported as well, for example the PK is (X, PADDING) and there are two unique constraints (U1, U2) and a FK (R1) constraint.

To see all the information that the report provides, you can check the showcase example in the xplan main page linked above, whose report is annotated to explain the various sections meaning. The most interesting ones are surely the plan section and the table/index/column/partition information.

Using xplan is very simple; just connect to the database with sqlplus (SELECT ANY DICTIONARY and SELECT ANY TABLE are the only necessary privileges) and run the xplan.sql script. There are various ways to tell xplan which statements to report about; probably the most useful one is to ask for statements whose text matches a SQL like expression, for example 

SQL>@xplan "select%from%customer%" ""

will dump all the SELECT statements that were run on the CUSTOMER table. 

It is also possible to dump a statement by hash value (or by sql_id, module, action, parsing user, and even child number):

SQL>@xplan "" "hash=3280933266"

Some further customizations are possible - for example, you can order the matching statements (technically, the matching child cursors in the shared sql area) by elapsed_time, buffer_gets, etc; you can get a different output file for each hash_value, instead of a single output file; you can suppress or enable certain sections of the report; and so on. For the full list and further details, please check the xplan.sql header.

Xplan is free to download and use. If you decide to try it - for any question, comment or feature request, feel free to drop a comment on this post.]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>259</wp:post_id>
		<wp:post_date><![CDATA[2009-06-07 17:07:06]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-06-07 15:07:06]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[optimizing-sql-statements-with-xplan]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="performance-tuning"><![CDATA[performance tuning]]></category>
		<category domain="category" nicename="tools"><![CDATA[tools]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[rashad.ahliman@gmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>14</wp:comment_id>
			<wp:comment_author><![CDATA[coskan]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[gundogar@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://coskan.wordpress.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[81.151.214.116]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-06-08 02:32:34]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-06-08 00:32:34]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto,

First of all thank you very much for sharing this tool with community. I am currently using Tanel Poders scripts + dbms_xplan utility for seeing the execution plans but I think this tool also rocks and lets us get rid of too many steps. 

IMHO The only addition can be added to choose what not to see in case if I need only the execution plan plus filters. you might add an option s/f/a (simple full advanced )]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>15</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-06-08 09:46:49]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-06-08 07:46:49]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@coskan

There's already something very similar to what you are asking for:

SQL&gt;@xplan "select%dual%" "tabinfos=N,plan_details=N"

that suppresses the table infos (usually the longest part of the report) and the plan details.

There's also an option, "dbms_xplan=Y", that adds the output of dbms_xplan.display_cursor() to the report (10g+ only of course).

If you use Tanel's scripts you will find the xplan interface similar - in fact, as credited in the xplan.sql header, I borrowed some ideas from one of the first scripts of Tanel's ...

Thanks for your kind comments :)]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>14</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>16</wp:comment_id>
			<wp:comment_author><![CDATA[Statistique]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[stats102@hotmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[142.213.85.254]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-06-08 16:03:14]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-06-08 14:03:14]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Great bunch of scripts well tied up together. I'm going to use this everyday. I was just too lazy to wrap all my scripts together !

Many Thanks.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>17</wp:comment_id>
			<wp:comment_author><![CDATA[sandro]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[sandro.osci@dedalus.eu]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[212.45.141.153]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-06-10 15:10:47]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-06-10 13:10:47]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto,
can you explain me why I have ColName that start from 0?

Thanks in advance.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>18</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-06-10 15:53:08]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-06-10 13:53:08]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@sandro

Might you please elaborate on your question ? ColName contains the column name as it is found in the data dictionary, if the column name starts with a number, it will be reproduced as is ... even if creating a table with a leading number requires to enclose the name in double-quotes, and it is very rarely done.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>17</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>19</wp:comment_id>
			<wp:comment_author><![CDATA[sandro]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[sandro.osci@dedalus.eu]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[212.45.141.153]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-06-10 16:08:26]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-06-10 14:08:26]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Sorry for my misunderstanding!
This is extract from my report.

-------------------------------------------------------------------------------------------
|Id|IId|ColName       |Type              |Null    |0|1|2|3|4|P |R0|R1|R2|R3|R4|R5|R6|R7|R8|
-----------------------------------------------------------U-------------------------------
| 1|  1|TEDO_TIPO     |VARCHAR2 (2 byte) |NOT NULL| | | | |1|R1|  |  |  |  |  |  |  |  |  |
| 2|  2|TEDO_PROG     |VARCHAR2 (10 byte)|NOT NULL| | | | |2|R2|  |  |  |  |  |  |  |  |  |
| 3|  3|TEDO_SERV_CODI|VARCHAR2 (8 byte) |NOT NULL| | | |1| 

My question is:
why I have 0,1,2,3,ecc...and it strats from "0"?]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>20</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-06-10 16:43:32]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-06-10 14:43:32]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@sandro

You should read the report row-wise, for example the first row details the first column of the table:

1) the column id ("Id") is 1
2) the column internal id ("IId") is 1
3) the column name ("ColName") is TEDO_TIPO 
4) the column type ("Type") is VARCHAR2 (2 byte)
5) the column nullability ("Null") is NOT NULL
6) indexes 0,1,2,3 do not reference this column
7) index 4 has this column as the first column 
...  etcetera.

If you look down on your report, you'll find the definition of the indexes, for example you'll find
### index #4
that you'll see is defined on (TEDO_TIPO, TEDO_PROG)

Further details on the main page of xplan - look at the commented example there :)]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>19</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>21</wp:comment_id>
			<wp:comment_author><![CDATA[Blogroll Report 06/06/09 &#8211; 12/06/09 &laquo; Coskan&#8217;s Approach to Oracle]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://coskan.wordpress.com/2009/06/12/blogroll-report-060609-120609/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[66.135.48.201]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-06-12 21:33:26]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-06-12 19:33:26]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] Alberto Dell&#8217;era &#8211; Optimizing SQL statements with xplan [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>22</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; Xplan 2.0]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2009/08/07/xplan-20/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-08-07 10:11:11]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-08-07 08:11:11]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] script I use to investigate about SQL statements performance (I spoke about version 1.0 in this post). Here's a brief [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>23</wp:comment_id>
			<wp:comment_author><![CDATA[optimizing oracle performance]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://starttags.com/tags/optimizing-oracle-performance</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[98.240.245.202]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-03-20 01:51:45]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-03-19 23:51:45]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] example, similar performance and energy cost savings can be obtained by tuning Oracle databases) ...Alberto Dell'Era's Oracle blog Optimizing SQL statements ...Xplan is a utility to simplify and automate the first part of every SQL statement tuning effort, [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>Tuning Oracle for Siebel - SQL template</title>
		<link>http://www.adellera.it/blog/2009/06/30/tuning-oracle-for-siebel-sql-template/</link>
		<pubDate>Mon, 29 Jun 2009 22:31:04 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=267</guid>
		<description></description>
		<content:encoded><![CDATA[The time has come to write down some of the most relevant discoveries I've made so far while being part of a team that is tuning a huge Siebel installation for a leading Italian company ("huge" especially because of the user base dimension and secondarily because of the hardware deployed, a three-node RAC on pretty powerful SMP machines).  

This blog entry is about the structure of the Siebel queries and the effect of the settings of some CBO-related parameters - settings made by the Siebel clients by altering the session at connect time, or required as mandatory in the Siebel installation notes. Other postings may follow in case I discover something worth writing about.

But first of all, let me thank for their support all the fellow members of the <a href=" http://www.oaktable.net">OakTable network</a> (especially <a href="http://www.evdbt.com/">Tim Gorman</a> that has exchanged long emails with me) and <a href="http://nbrightside.com/blog/">Andy Cowling</a> (introduced to me by <a href="http://www.oracledoug.com/serendipity">Doug Burns</a>) that kindly provided me with a lot of detailed information coming from their vast hands-on experience with Siebel on Oracle. 

For the record, the environment is Siebel 8.0, using a three-node 10.2.0.4 RAC cluster on identical SMP machines with 16 CPUs each. 

Most of the Siebel queries follow this template:
[sql]
select ...
  from base, inner1, ..., innerN
 where base.j1 = inner1.j1(+)
   and base.j2 = inner2.j2(+)
   ...
   and base.jN = innerN.jN(+)
   and "filter conditions on base"
  order by base.order1 [asc|desc], base.order2 [asc|desc], ..., base.orderK [asc|desc];
[/sql]
which must be discussed keeping in mind another critical and subtle information: the Siebel clients read only a subset of the returning rows (probably the ones that fit on the screen, sometimes only 2 or 3 on average) - an intention that the Siebel client wisely communicates to the CBO by altering the session and setting optimizer_mode = first_rows_10.

Side note: there are variants to this template; sometimes there are two or three base tables that are joined and filtered together, and more frequently, some of the outer join relations are based on one of the innerN tables, not on the base tables (eg. innerM.jN = innerN.jN), but that is inessential for what we are going to discuss here.

The Siebel client's intention is clear: get some rows from the base table, order them by the columns order1, order2, ..., orderK, get only the first rows, and then get additional information (columns) by following the outer join relations. Note the order of the operations.

Visiting the outer-joined tables almost always comes out as the most expensive part. The reason is two-fold; first, the sheer number of outer-joined tables (ten tables is the norm, up to about 50, since the Siebel relational model is highly normalized and hence the information is highly dispersed), and second and most importantly, because of the join method the CBO is forced to follow. 

In fact, Siebel blocks HASH JOINS (_hash_join_enabled=false) and SORT MERGE JOINS (_optimizer_sortmerge_join_enabled=false), which leaves NESTED LOOPS as the only surviving join method. When nested looping, Oracle must obviously start from the outer table listed in the SQL statement (base) and then visit the SQL inner tables (inner1 ... innerN) using the join conditions, something that can be efficiently done only by visiting an index that has innerN.jN as the leading column of its definition. Each of these visits requires blevel+1 consistent gets for the index and some additional consistent gets for every row that is found - usually one or two, sometimes zero, at least in the scenarios I've seen.

So it is clear that every row that is fetched from the base table may easily produce tens and tens of consistent gets coming from the outer joins - and that can easily lead to a disaster if the number of rows from the base table is not very very small. In one of our queries, for example, about one million rows came out from the base table, and since the CBO chose to outer join first and then order, each execution caused a whopping 15,000,000 consistent gets - only to have the Siebel client select the first 3 rows or so. Needless to say, such a huge number of gets is completely unacceptable; the impact on the response time and CPU consumption is obvious, but scalability suffers as well (gets cause latches or mutexes acquisitions that are the most frequent cause of contention) - that means that even a slight increase on the workload may cause severe degradation of response time (especially on RAC).

The solution is to have Oracle order first, and then join - to very quickly feed the first 3 or 4 rows to the client thus sparing the effort to outer join the remaing ones, that will never (or rarely) be fetched. That usually means that you must prepare an ad-hoc index for the query that has the order1,order2, orderK column as the last columns; the first_rows_10 setting will strongly encourage the CBO into choosing the index.  For example, say that the last "filter conditions on base" and the order clause are
[sql]
...
and base.col1 = :1 and upper(base.col2) = :2
order by base.order1 desc, base.order2 asc;
[/sql]
a suitable index might be (col1, upper(col2), order1 desc, order2 asc). 
Oracle will hopefully reach the start of the index range (or "slice") corresponding to the filter condition, a range that has the rows sorted exactly as Siebel wants them, and then scan the index range rows in succession; for each of them, it will outer join and then return the result to Siebel, and hence stop after a few rows read from the index and a few outer joins performed.

This is the main "tuning" technique in Siebel; of course there are others (using covering indexes for the outer join tables for example) that can provide some additional advantage to our beloved Oracle instances, that we are going to investigate and that I will blog about if they turn out as being useful. But I doubt that they can be as effective as this one.]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>267</wp:post_id>
		<wp:post_date><![CDATA[2009-06-30 00:31:04]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-06-29 22:31:04]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[tuning-oracle-for-siebel-sql-template]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="performance-tuning"><![CDATA[performance tuning]]></category>
		<category domain="category" nicename="siebel"><![CDATA[siebel]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[have@chief.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>24</wp:comment_id>
			<wp:comment_author><![CDATA[James]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[b2b@jhpwd.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[71.185.170.90]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-07-01 13:12:35]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-07-01 11:12:35]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Very illuminating, thank you. A question on the solution:

If the indexes are ad hoc, will they be created (and afterwards dropped) for each query? Is this manual or automated? If automated, how?

Or will you create a standard set for your most common queries?

Thanks]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>25</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.77.56.12]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-07-01 13:53:54]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-07-01 11:53:54]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@James

The indexes are created manually, following the usual procedures - they are "ad hoc" because they are usually useful for one query only, or a bunch of strongly related queries. But they are just regular indexes, and you must make good use of your indexing skills to define them - this post is just an head start,  as it summarizes the main information about the peculiarities of the Siebel environment.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>24</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>26</wp:comment_id>
			<wp:comment_author><![CDATA[Blogroll Report 26/06/2009 – 03/07/2006 &laquo; Coskan&#8217;s Approach to Oracle]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://coskan.wordpress.com/2009/07/03/blogroll-report-26062009-03072006/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[66.135.48.211]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-07-03 17:29:29]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-07-03 15:29:29]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] Alberto Dell’Era -Tuning Oracle for Siebel &#8211; SQL template [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>27</wp:comment_id>
			<wp:comment_author><![CDATA[@lex]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[steyr190@arcor.de]]></wp:comment_author_email>
			<wp:comment_author_url>http://siebel-essentials.blogspot.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[193.9.13.104]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-07-23 10:28:09]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-07-23 08:28:09]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto,

great post and very concise!

However, I just want to throw in that it is a very common practice of the DBA to create "ad hoc" indexes in the Siebel database.

When the Siebel schema is upgraded (say to version 8.1), the upgrade process drops all indexes and recreates only those which are registered in the Siebel Repository (using Siebel Tools).

I strongly encourage that the people creating ad-hoc indexes talk to the Siebel developers so that they can add the index definition to the Siebel Repository. Or even create the definition first and then use the Siebel ddlsync utility to "apply" the metadata-resident definitions to the physical schema.

For indexes where this is not possible, you should at least document the index definition (create statement) in a way that it is present during the upgrade process.

have a nice day

@lex]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>28</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-07-23 11:32:27]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-07-23 09:32:27]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@Alex

Thank you for your contribution - that is definitely something that must be always remembered when "tuning" Siebel.  Actually in our case, the database schema is so heavily customized (manually partitioned tables, a lot of indexes using options such as "compress" etc) that everything is pretty much done by hand ... Siebel is synchronized somehow, but I do not know exactly how since I'm not the one in charge of this :)]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>27</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>29</wp:comment_id>
			<wp:comment_author><![CDATA[Samir]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[skakli@adt.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[205.145.185.201]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-02-04 19:44:46]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-02-04 17:44:46]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hello, 

Nice post - i just saw this the first time. However i think there are issues in my environment which are related to your post somewhat, but different. The vanilla queries coming out of siebel are as you mentioned, from what i can see. However the customizations that are often done to them are causing issues, I believe. Many screens in our environment seem to have multiple base tables, not just one. For example, a query on accounts may select for the business unit from S_ORG_BU (of which there are only 1 or 2, so this will match alot of records), but then the developers cater this query for a team, to search by a national account number, using a custom column from the accounts table. But the ORDER BY stayed on the business unit, so oracle really loves that index on the S_ORG_BU table, so it can fetch the first 10 rows quickly as you said. But the problem is, as it is fetching the 10 rows they then are matched against the other predicate on the other ACCOUNTS table S_ORG_EXT. If the row doesn't satisfy that 2nd predicate, it must scan the next row on S_ORG_BU and try again. This can keep happening until it may end up scanning hundreds of thousands of rows until it finds 10 which match the 2nd predicate, and return them to the user. Response time can be horrible because of this. See below for an example. Even though an index exists on the X_NATIONAL_ACCOUNT_NUMBER table, the CBO doesn't pick it up as the column is not very selective. Each national account matches a few hundred rows in that table, but this is FAR better than using the S_ORG_BU index, which matches hundreds of thousands of rows. But the CBO likes the latter, because it is thinking FIRST_ROWS_10, that it only will fetch 10 rows from each step. Seems the CBO doesn't realize that it will scan many more rows than 10, to satisfy the 2nd predicate on S_ORG_EXT table...

SELECT ...
FROM SIEBEL.S_ORG_BU T1,
...
   SIEBEL.S_ORG_EXT T27
WHERE ....
AND T1.BU_ID = :1
AND T27.ROW_ID = T1.ORG_ID
AND T1.BU_ID = T8.ROW_ID
AND T1.BU_ID = T6.PAR_ROW_ID (+)
AND (T1.ORG_NAME &gt;= :2)
AND (T27.X_NATIONAL_ACCOUNT_NUMBER = :3)
ORDER BY T1.BU_ID,
   T1.ORG_NAME,
   T1.ORG_LOC]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>30</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[194.149.232.84]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-02-10 20:15:10]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-02-10 18:15:10]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@Samir

sorry, I have seen your comment only today, probably I have an issue with email notifications ...

The main issue with Siebel is that some "supported settings" are just there to kill the CBO. For example, setting OPTIMIZER_INDEX_COST_ADJ to 1 makes the cost of index access so tiny, that it really makes them so unrealistically cheap that the CBO basically miscalculates the cost completely ... if memory serves right you have, in recent version, the opportunity to set it to the default (100) hence allowing the CBO to make its work much better. You could try it and see whether that makes any difference.

The second is that very often, if the predicates on the N tables are not selective enough, there's no way that a nested loop could get them back efficiently - whatever table you choose as the driving table(s), it makes for a lot of index accesses on the inner tables(s). An hash join (or sort merge) would be optimal, but Siebel blocks them ...

Of course to remedy the situation, you might be forced to drop the index on the ordered-by columns ... possibly killing other queries. At the end, in Siebel, poor database performance has to be accepted as a fact of life almost always :(  

PS: FIRST_ROWS_10 means asking the CBO to get back the first 10 rows of the statement as fast as it can, not the first 10 rows of each step.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>29</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>31</wp:comment_id>
			<wp:comment_author><![CDATA[Samir]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[skakli@adt.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[205.145.185.201]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-02-10 20:59:12]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-02-10 18:59:12]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Alberto, 

Thanks - yes i agree with you about FIRST_ROWS_10, however, when the CBO calculates cost to get back the first 10 rows of the statement as fast as it can, it can grossly underestimate the # of rows for some key steps. Example, for the 1st predicate it uses an index range scan for that step, the CBO estimates only 10 records need to be scanned. But when running the query it goes through thousands of records as that is what it ends up taking get 10 rows which satisfy the 2nd predicate as well. I did find a potential solution for this though - even though i am mostly working at the query and database level, i discovered that in the siebel application, you can set something at the business-component level which will hint queries in that BC with an ALL_ROWS hint. That can fix some queries with this sort issue. I'm trying to get my siebel developers to look into this, as we are experiencing this issue all over the place.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>32</wp:comment_id>
			<wp:comment_author><![CDATA[Thomas]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[coolmadthomas@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.google.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[144.36.235.82]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2015-09-07 17:01:50]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2015-09-07 15:01:50]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[sql]
INSERT
    /*+ APPEND */
  INTO
    siebel.eim_account
    (
      row_id,
      if_row_stat,
      if_row_batch_num,
      party_uid,
      party_type_cd,
      pp_party_uid,
      pp_party_type_cd
    )
  SELECT
    rownum,
    if_row_stat,
    TRUNC(rownum / 5000) + 45000,
    party_uid,
    party_type_cd,
    pp_party_uid,
    pp_party_type_cd
  FROM
    (
      
      SELECT
        'TO_IMPORT' if_row_stat,
        sp.party_uid party_uid,
        sp.party_type_cd party_type_cd,
        sp1.party_uid pp_party_uid,
        sp1.party_type_cd pp_party_type_cd
      FROM
        siebel.id_f212_stg_custcor stg,
        siebel.s_party sp,
        siebel.s_org_ext soe,
        siebel.s_bu sbu,
        siebel.s_party sp1,
        siebel.s_contact sc,
        siebel.s_party_per spp
      WHERE
        stg.ef_status = 'I'
      AND stg.client_type = 'ID_ENT'
      AND stg.ident_cor = sc.x_eforce_id
      AND stg.id_client = soe.x_come_id_rce
      AND soe.x_come_sc_client = 'Enterprise'
      AND soe.row_id = spp.party_id
      AND sc.row_id = spp.person_id
      AND soe.bu_id = sbu.row_id
      AND soe.row_id = sp.row_id
      AND sp1.row_id = sc.row_id
      /*LOG errors INTO SIEBEL.ID_F212_tb_error('EIM_ACCOUNT') REJECT LIMIT UNLIMITED;
      COMMIT;
      -- To remove the link between Account and contact id EF_STATUS='I'
      INSERT  into SIEBEL.EIM_ACCOUNT
      (ROW_ID, IF_ROW_STAT, IF_ROW_BATCH_NUM, PARTY_UID, PARTY_TYPE_CD,
      PP_PARTY_UID, PP_PARTY_TYPE_CD)*/
      UNION ALL
      SELECT
        'TO_IMPORT' if_row_stat,
        sp.party_uid party_uid,
        sp.party_type_cd party_type_cd,
        sp1.party_uid pp_party_uid,
        sp1.party_type_cd pp_party_type_cd
      FROM
        siebel.id_f212_stg_custcor stg,
        siebel.s_party sp,
        siebel.s_org_ext soe,
        siebel.s_bu sbu,
        siebel.s_party sp1,
        siebel.s_contact sc,
        siebel.s_party_per spp
      WHERE
        stg.ef_status = 'I'
      AND stg.client_type = 'ID_ETA'
      AND stg.ident_cor = sc.x_eforce_id
      AND stg.id_client = soe.x_come_id_rce
      AND soe.x_come_sc_client = 'Establishment'
      AND soe.row_id = spp.party_id
      AND sc.row_id = spp.person_id
      AND soe.bu_id = sbu.row_id
      AND soe.row_id = sp.row_id
      AND sp1.row_id = sc.row_id
    )
    log errors
  INTO
    siebel.id_f212_tb_error('EIM_ACCOUNT_CUSTCOR') reject limit unlimited
[/sql] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>33</wp:comment_id>
			<wp:comment_author><![CDATA[Thomas]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[coolmadthomas@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.google.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[144.36.235.82]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2015-09-07 17:02:17]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2015-09-07 15:02:17]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Please help is tuning the above sql]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>Bind Variables Checker for Oracle - now install-free</title>
		<link>http://www.adellera.it/blog/2009/07/23/bind-variables-checker-for-oracle-now-install-free/</link>
		<pubDate>Thu, 23 Jul 2009 09:23:12 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=271</guid>
		<description></description>
		<content:encoded><![CDATA[I've finally managed to implement an install-free version of my utility to check for bind variables usage. The new script is named bvc_check.sql and when run, it examines the SQL statements stored in the library cache (through gv$sql) and dumps the ones that would be the same if the literals were replaced by bind variables. 

An example of the output:
[text]
------------------
statements count :  0000000003
bound    : select*from t where x=:n
example 1: select * from t where x = 2
example 2: select * from t where x = 3
------------------
[/text]
So we have 3 statements that are the same once literals are replaced with bind variables. Two examples are provided; the action of replacing the literals 2 and 3 with the bind variable :n makes the statements the same.

The script are available on <a href="http://www.adellera.it/scripts_etcetera/bvc/index.html">this page</a>, that also explains the script workings in more detail and describes other scripts that might be of interest.]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>271</wp:post_id>
		<wp:post_date><![CDATA[2009-07-23 11:23:12]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-07-23 09:23:12]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[bind-variables-checker-for-oracle-now-install-free]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="tools"><![CDATA[tools]]></category>
						<wp:comment>
			<wp:comment_id>34</wp:comment_id>
			<wp:comment_author><![CDATA[Coskan]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[gundogar@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://coskan.wordpress.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[145.62.32.129]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-07-23 13:53:33]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-07-23 11:53:33]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Did not dig into all sqls one by one but initial expression is that is is very cool. thank you very much for sharing Alberto.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>35</wp:comment_id>
			<wp:comment_author><![CDATA[Blogroll Report 17/07/2009 – 24/07/2009 &laquo; Coskan&#8217;s Approach to Oracle]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://coskan.wordpress.com/2009/07/24/blogroll-report-1707200924072009/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[74.200.245.226]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-07-27 16:29:43]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-07-27 14:29:43]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] Alberto Dell’Era &#8211; Bind Variables Checker for Oracle &#8211; now install-free [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>fast refresh of join-only materialized views - algorithm summary</title>
		<link>http://www.adellera.it/blog/2009/08/04/fast-refresh-of-join-only-materialized-views-algorithm-summary/</link>
		<pubDate>Tue, 04 Aug 2009 14:34:51 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=275</guid>
		<description></description>
		<content:encoded><![CDATA[This post investigates how Oracle fast refreshes materialized views containing only joins of master tables:
[sql]
create materialized view test_mv
build immediate
refresh fast on demand
as
select test_t1.*, test_t1.rowid as test_t1_rowid,
       test_t2.*, test_t2.rowid as test_t2_rowid,
       test_t3.*, test_t3.rowid as test_t3_rowid
  from test_t1, test_t2, test_t3
 where test_t1.j1_2 = test_t2.j2_1
   and test_t2.j2_3 = test_t3.j3_2
;
[/sql]
The fast refresh algorithm is simple and very easy to understand - so trivial in fact that once examined and understood, the possible tuning techniques follow naturally.  

The <a href="http://34.247.94.223/wp-content/uploads/2009/08/post_0030_join_mv.zip">test case</a> traces the fast refresh of the above materialized view (MV) using the 10046 event (aka "sql trace"). The test case has been run on 9.2.0.8, 10.2.0.4 and 11.1.0.7 (the latest versions of 9i, 10g and 11g available as of today), and on all of these versions the algorithm used by the refreshing engine (run by invoking dbms_mview.refresh) appears to be the same, with only a few implementation differences.

The test case explores the most general case: it performs inserts, updates and deletes on all the three master tables (the inserts being conventional; I will explore direct-path inserts another time). 

<b>Materialized view logs configuration</b>

In the test case, I have configured the materialized view logs to "log everything", in order to check whether more information in the logs could trigger some special kernel code designed to take advantage of it:
[sql]
create materialized view log on test_t1 
with sequence, rowid, primary key (j1_2, x1) 
including new values;
[/sql] 
but the engine uses only the rowid information even in 11.1.0.7, so you are better off logging only the rowid if the master table feeds join-only materialized views exclusively:
[sql]
create materialized view log on test_t1 with rowid;
[/sql] 
Minimal logging obviously improves the performance of DML against the master tables, but it also optimizes the fast refresh, since the latter, as we are going to see in a moment, reads each log twice, and of course the less you log, the more compact the logs will be.

<b>Log snapshots</b>

After some preliminary visits to the data dictionary, the first operation performed by the fast refresh engine is to "mark" the modifications (recorded in the materialized view logs) to be propagated to the MV. Only the marked log rows are then fed by the fast refresh engine as input to the next steps.

The "flag" used to mark the rows is the column snaptime$$. When the refresh starts, the engine performs a "snapshot" of the materialized view logs by setting the snaptime$$ of all the new rows (those with snaptime$$ = '01/01/4000') of each log in turn to the current time (SYSDATE).

In detail, the snapshot is performed by issuing this SQL statement (slightly edited for readability) in 9.2.0.8 and 10.2.0.4:
[sql]
update MLOG$_TEST_T1
   set snaptime$$ = :1  
 where snaptime$$ > to_date('2100-01-01:00:00:00','YYYY-MM-DD:HH24:MI:SS')
[/sql]
The bind variable :1 is a DATE whose value is equal to SYSDATE. 

Note: In 11.1.0.7, the statement is slightly different but makes the same thing, probably in a more scalable way concurrency-wise (check the script spools if you're interested).

You might have noticed the where condition on snaptime$$; that is necessary since the logs might be used by more than one materialized view. When a refresh ends, in fact, the engine checks whether other MVs might need each log row, and deletes only the log rows that have been processed by all dependant MVs; the other ones are left unchanged (and hence keep the snaptime$$ that was set when the fast refresh started). The where condition is needed to avoid overwriting the snaptime$$, and mark with the current time only the brand new rows (those with snaptime$$ = '01/01/4000').

So, at the end of the snapshot, the log rows that must be examined by the refresh engine will be the ones that are marked by having their snaptime$$ between the date of the last refresh (excluded) and :1 (included). All the other log rows must be ignored.

Side note: marking data at a certain point in time and then replicating the marked data is the only replication strategy that can work when you cannot "freeze" the master tables, as this is definitely our case. This is a general topic worth blogging about in the future.

The marked log rows are then inspected to count the number and type of the logged modifications. This is to check whether any of the replication steps (i.e. the DEL and INS steps that we are going to discuss in a moment) could be skipped. Also, the number of modifications is used (in some versions) to inject some hints in the SQL statements of the replication steps, a topic that falls out of the scope of this post.

<b>Core algorithm: the INS and DEL steps</b>

Then, the core replication starts. The replication considers each master table in turn, and for each table, propagates the modifications to the MV. So we have essentially one single algorithm that propagates from a single master table, just repeated once for each master table.

The propagation for each master table is made of two simple steps, steps that I'm going to name after the comments of the SQL as a DEL (DELETE) step followed by an INS (INSERT) step. 

The DEL step is (editing for readability: removing hints, unnecessary aliases, etc):
[sql]
/* MV_REFRESH (DEL) */ 
delete from test_mv 
 where test_t1_rowid in 
       (
select * from 
       (
select chartorowid (m_row$$)     
  from mlog$_test_t1   
 where snaptime$$ > :1 
       ) as of snapshot (:2) 
       )
[/sql]
The subquery simply fetches the rowid of all marked rows, since :1 is the date of the previous refresh of the materialized view, and :2 is the SCN (coded as a RAW variable) of the time when the snapshot was performed. So, this step deletes from the MV all the rows that record the result of the MV-defining join of any of the marked rows (of the current master table) with the other master tables.

This is the step that can benefit from the index on the column that stores the master table rowid (here, test_t1_rowid) that the <a href=" http://download.oracle.com/docs/cd/B28359_01/server.111/b28313/refresh.htm#sthref463">documentation suggests</a> to create. Note that in order to optimize this step, you need three separate single-column indexes (here, on test_t1_rowid, test_t2_rowid, test_t3_rowid), not a single composite index spanning the (here, three) columns, as it is sometimes wrongly stated.

The INS step is (again editing for readability):
[sql]
/* MV_REFRESH (INS) */ 
insert into test_mv 
select jv.j1_2, jv.x1, jv.pk1, jv.rid$,
       mas2.j2_1, mas2.j2_3, mas2.x2, mas2.pk2, mas2.rowid,
       mas3.j3_2, mas3.x3, mas3.pk3, mas3.rowid 
  from ( 
select log.rowid rid$, log.*  
  from test_t1 log 
 where rowid in 
       (
select chartorowid(log.m_row$$)     
  from mlog$_test_t1   
 where snaptime$$ > :1 
       )
       ) as of snapshot (:2) jv, 
       test_t2 as of snapshot (:2)  mas2,
       test_t3 as of snapshot (:2)  mas3 
 where   jv.j1_2 = mas2.j2_1 
   and mas2.j2_3 = mas3.j3_2 
[/sql]
The subquery is the same as the DEL step and serves the very same function. So, this statement replays the SQL statement of the MV definition, but limited to the marked rows only. Note that all tables are read at the same point in time in the past, the time when the snapshot of the log was performed, thanks to the argument of the "as of snapshot" clause being the same.

In order to speed up the INS step, indexes on the joined columns can be created on the master tables (not on the MV!). This is because, special cases aside, it is well known that the "fast refresh" (the name itself is quite horrible, many people prefer the adjective "incremental") can be actually "fast" only if a small fraction of the master tables is modified (otherwise, a complete refresh is better); in this scenario, almost certainly the optimal plan is a series of NESTED LOOPs that has the current table (test_t1 in this case) as the most outer table, series that can usually benefit a lot by an index on the inner tables join columns. Of course, you must remember that every table, in turn, acts as the most outer table, hence you should index every possible join permutation.

So here what the algorithm is all about: the DEL and INS steps, together, simply delete and recreate the "slice" of the MV that is referenced by the marked rows, whatever the modification type. The algorithm is as simple (and brutal) as it seems. 

<b>Algorithm optimizations</b>

The only optimizations performed are the skipping of some steps when they are obviously unnecessary. For every master table, the DEL step is skipped when only INSERTs are marked in the logs; the INS is skipped when only DELETEs are marked, and of course both are skipped if no row is marked. I have not been able to spot any other optimization.

Note that this means that UPDATEs always turn into a delete+insert of the entire "slice".  For example, consider the typical case of a parent table (say, CUSTOMER), with a child (say, ORDER) and a grandchild (say, ORDER_LINE); if you update a column of a row of the parent (say, ORDERS_TOTAL_AMOUNT), the parent row and its whole progeny (the "slice") will be deleted and then recreated. This was a quite surprising discovery for me - a fact that I have now committed to memory.]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>275</wp:post_id>
		<wp:post_date><![CDATA[2009-08-04 16:34:51]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-08-04 14:34:51]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[fast-refresh-of-join-only-materialized-views-algorithm-summary]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="materialized-views"><![CDATA[materialized views]]></category>
						<wp:comment>
			<wp:comment_id>36</wp:comment_id>
			<wp:comment_author><![CDATA[Cristian]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[cristian.cudizio@yahoo.it]]></wp:comment_author_email>
			<wp:comment_author_url>http://cristiancudizio.wordpress.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[88.42.187.162]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-08-07 14:08:39]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-08-07 12:08:39]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Very interesting post.  I've read it and re-read and i've made same tests by myself. I've a question: why in your opinion whith simple mv's (on a single table, without joins) Oracle does not use the same algorithm but makes updates as updates? (i've made a test on 10.2.0.4)]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>37</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-08-07 15:24:58]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-08-07 13:24:58]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@Cristian

what do you mean by "simple MV", with or without aggregates ?

You might want to post the defining SQL statement of the MV ...]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>36</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>38</wp:comment_id>
			<wp:comment_author><![CDATA[Cristian]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[cristian.cudizio@yahoo.it]]></wp:comment_author_email>
			<wp:comment_author_url>http://cristiancudizio.wordpress.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[88.42.187.162]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-08-07 16:12:26]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-08-07 14:12:26]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[I meant without aggregates:
[sql]
update testmv1 set fld1='a2' where pk1=1;
commit;
EXEC DBMS_MVIEW.REFRESH('TEST_MV1');
SELECT * FROM TESTMV1_LOG;
[/sql]
This because we sometimes use MV's as data replication tool.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>39</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-08-07 16:16:12]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-08-07 14:16:12]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Ok, but what is the defining SQL statement of the MV TEST_MV1 ?]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>38</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>40</wp:comment_id>
			<wp:comment_author><![CDATA[Cristian]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[cristian.cudizio@yahoo.it]]></wp:comment_author_email>
			<wp:comment_author_url>http://cristiancudizio.wordpress.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[88.42.187.162]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-08-07 16:30:00]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-08-07 14:30:00]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Sorry, the sun on my head :)
[sql]
create table testmv1 (pk1 number,fld1 varchar2(10));
create materialized view log on testmv1 with rowid;

create materialized view test_mv1 
build immediate 
refresh fast with rowid
on demand
as
 select 
  testmv1.*
 from testmv1;
[/sql]

I've not tried with primary key based refresh.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>41</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-08-07 19:07:45]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-08-07 17:07:45]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[I know a "rowid MV", as your one is, cannot contain neither joins neither aggregates and must be based on a single table, so they probably use a different algorithm than the one examined in this post (which is for join-only MVs). They are in fact MVs used for replication almost exclusively, usually from a remote database to a local one through a dblink - the old name was "snapshots", a technology "now merged" with the "materialized view" one. So it is outside the scope of this post, albeit I've added an investigation about this on my to-do list. It makes sense, anyway, that on a scenario as simple as this one, they have tried to optimize the propagation (hence using UPDATEs) as much as possible (especially to minimize the traffic over the dblink).]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>40</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>42</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; fast refresh of single-table materialized views - algorithm summary]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2009/08/11/fast-refresh-of-single-table-materialized-views-algorithm-summary/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-08-11 17:57:13]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-08-11 15:57:13]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] might be considered a degenerate case of a join-only MV, a topic that we investigated in an earlier post, and one could expect the same algorithm. But that is not the case: the test case shows that the [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>43</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[93.33.128.211]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-08-11 17:58:47]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-08-11 15:58:47]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@Cristian

I have posted an <a href="http://www.adellera.it/blog/2009/08/11/fast-refresh-of-single-table-materialized-views-algorithm-summary/" rel="nofollow">investigation</a> about your scenario.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>40</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>44</wp:comment_id>
			<wp:comment_author><![CDATA[Blogroll Report 31/07/2009 – 07/08/2009 &laquo; Coskan&#8217;s Approach to Oracle]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://coskan.wordpress.com/2009/08/12/521/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[74.200.244.14]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-08-12 16:32:37]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-08-12 14:32:37]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] Alberto Dell’Era- fast refresh of join-only materialized views -algorithm summary [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>45</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; 11gR2: materialized view logs changes]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2009/11/03/11gr2-materialized-view-logs-changes/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-11-03 19:20:55]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-11-03 17:20:55]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] the refresh is performed by using a "mark-and-propagate" algorithm, which is essentially (check this post for some additional details): 1) new log rows are inserted with snaptime$$=4000 A.D; 2) at refresh [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>46</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; fast refresh of join-only MVs: _mv_refresh_use_stats and locking log stats]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2010/03/11/fast-refresh-of-join-only-mvs-_mv_refresh_use_stats-and-locking-log-stats/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-03-11 22:46:21]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-03-11 20:46:21]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] understand the importance of points 5 and 6, please check this post of mine; note how those indexes are a necessary prerequisite for the sanity of the DEL and INS steps of the [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>47</wp:comment_id>
			<wp:comment_author><![CDATA[Shuai]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[mythcolor@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[220.166.204.130]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2011-11-01 17:19:24]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2011-11-01 15:19:24]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[I'm very glad to read your article about the algorithm of join-only MV fast refresh. It's very useful. I just want to know more about this: how about a joined MV with aggregation such as sum or count? I found it's very difficult to explain the aggregation MV's behavior while doing fast refresh because there is no rowid column. Do you have any idea? Many thanks!]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>48</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[151.64.131.223]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2011-11-01 20:57:46]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2011-11-01 18:57:46]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Shuai, 

I have never investigated that scenario - but you can do it yourself by modifying one of my test cases ... just try to see the SQL statements that the refresh produces, that's all it takes to get a rough model of the process ;)]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>47</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>49</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; fast refresh of outer-join-only materialized views &#8211; algorithm, part 1]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2013/04/22/fast-refresh-of-outer-join-only-materialized-views-algorithm-part-1/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-04-22 09:40:27]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-04-22 07:40:27]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] only 11.2.0.3. We will use the very same scenario (MV log configuration, DML type, etc) as in the inner join case, &quot;just&quot; turning the inner join into an outer [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>50</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; Fast refresh of aggregate-only materialized views &#8211; introduction]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2013/08/05/fast-refresh-of-aggregate-only-materialized-views-introduction/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-08-05 14:49:48]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-08-05 12:49:48]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] to the MV by setting snaptime$$ equal to the current time - check the description contained in this post for details (note also another possible variant with &quot;commit-scn mv logs&quot;). MV log purging (at the [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>51</wp:comment_id>
			<wp:comment_author><![CDATA[The mess that is fast-refresh join-only Materialized Views | OraStory]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://orastory.wordpress.com/2014/11/27/the-mess-that-is-fast-refresh-join-only-materialized-views/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[76.74.255.29]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-11-27 17:23:57]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-11-27 15:23:57]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] http://www.adellera.it/blog/2009/08/04/fast-refresh-of-join-only-materialized-views-algorithm-summar... [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>52</wp:comment_id>
			<wp:comment_author><![CDATA[MV Refresh | Oracle Scratchpad]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>https://jonathanlewis.wordpress.com/2013/04/29/mv-refresh/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[192.0.86.116]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2015-03-26 13:27:05]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2015-03-26 11:27:05]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] (Inner) Join View refresh (2009) [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>Xplan 2.0</title>
		<link>http://www.adellera.it/blog/2009/08/07/xplan-20/</link>
		<pubDate>Fri, 07 Aug 2009 08:11:08 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=285</guid>
		<description></description>
		<content:encoded><![CDATA[A lot of new features have been added in version 2.0 of <a href="http://www.adellera.it/scripts_etcetera/xplan/index.html">xplan</a>, the sqlplus script I use to investigate about SQL statements performance (I spoke about version 1.0 in this <a href="http://www.adellera.it/blog/2009/06/07/optimizing-sql-statements-with-xplan/">post</a>). Here's a brief description.

<b>wait profile (from ASH)</b>

For each statement, its wait profile is calculated fetching wait information from Active Session History:
[text]
-----------------------------------------
|ash event                    |cnt |%   |
-----------------------------------------
|enq: HW - contention         |2606|61.0|
|enq: TX - row lock contention| 875|20.5|
|db file sequential read      | 344| 8.0|
|enq: TX - index contention   | 158| 3.7|
|gc current grant busy        | 152| 3.6|
|cpu                          |  56| 1.3|
|gc current block 2-way       |  34| 0.8|
|gc current block busy        |  13| 0.3|
|gc buffer busy               |  10| 0.2|
|gc cr block 2-way            |   7| 0.2|
|gc current grant 2-way       |   5| 0.1|
|read by other session        |   5| 0.1|
|direct path write            |   3| 0.1|
|gc cr block busy             |   3| 0.1|
|gc cr grant 2-way            |   1| 0.0|
|SQL*Net more data from client|   1| 0.0|
|cr request retry             |   1| 0.0|
-----------------------------------------
[/text]

By default this feature is on in 10g+ and inspects a window of ash_profile_mins=15 minutes from v$active_session_history. 

Important note: you must have bought the appropriate Oracle licence (i.e. the Diagnostic Pack in 11.1) to read from that view and hence to use this feature (xplan will output a warning to remember you about that); you can disable this feature by setting ash_profile_mins=0.

<b>Dump of dependent object definitions</b>

If the statement references some database objects (e.g. a view, a pl/sql function) and hence depends on them, xplan will list them right below the statement text:
[text]
SELECT /*+ index(t,t_fbi) ordered use_nl(v) xplan_test_marker */ 
       T.RR, PLSQL_FUNC(MAX(T.X)) 
  FROM T, V 
 WHERE UPPER(T.X) >= '0' 
   AND T.X > :B1 
   AND V.RR ='x' 
 GROUP BY T.RR 
 ORDER BY T.RR

- depends on view DELLERA.V
- depends on function DELLERA.PLSQL_FUNC
[/text]
and the object definition will be reported at the bottom of the xplan output:
[text]
############################################# function DELLERA.PLSQL_FUNC ###
function plsql_func (p varchar2)
return varchar2
is
begin
  return p;
end plsql_func;
############################################# view DELLERA.V ###
view columns: #1 X(NUMBER),#2 PADDING(VARCHAR2),#3 RR(VARCHAR2)
select x, padding, rr
  from t
 where x > 0
[/text]

<b>Reading other RAC instance statements</b>

Now you can read from another instance by specifying the option inst_id (defaults to the instance you are connected). This is handy for inspecting other instances of the RAC cluster without reconnecting.

<b>Automatic dump of AWR most-expensive statements</b>

The experimental script xplan_awr.sql will inspect AWR (Active Workload Repository) and dump all the statements that are still in the library cache and that have exceeded some resource consumption thresholds in any of the periods marked by two consecutive AWR snapshots. Thresholds can be the percentage of total (e.g. dump if the CPU consumption is more that 10% of total CPU) or the ranking position (e.g. dump if the statement ranks more than 5th in the CPU chart - the typical "top-N" analysis). The thresholds are configurable in the topmost "params" WITH clause.

 Again, you must have bought the appropriate Oracle licence to use AWR, and hence to run xplan_awr.sql.]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>285</wp:post_id>
		<wp:post_date><![CDATA[2009-08-07 10:11:08]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-08-07 08:11:08]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[xplan-20]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="performance-tuning"><![CDATA[performance tuning]]></category>
		<category domain="category" nicename="tools"><![CDATA[tools]]></category>
		<category domain="category" nicename="xplan"><![CDATA[xplan]]></category>
						<wp:comment>
			<wp:comment_id>53</wp:comment_id>
			<wp:comment_author><![CDATA[Martin Berger]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[martin.a.berger@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://berxblog.blogspot.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[86.59.5.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-08-07 21:05:20]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-08-07 19:05:20]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Alberto, 
 What a nice improvemet for xplan! I used it quite regulary and I will use your new version with at least the same gratitude. 
 As you now also show related objects, you might want to include assicuated statistics, if they exist. I know, they are used rarely, but if they exist, they will sum up the informations xplan will deliver. 
 Martin]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>54</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[87.15.161.50]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-08-08 20:03:04]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-08-08 18:03:04]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@Martin

thanks, and I will add your request to my to-do list, absolutely.
Just to be sure - you mean the statistics added with the command ASSOCIATE STATISTICS, do you ?]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>53</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>55</wp:comment_id>
			<wp:comment_author><![CDATA[Martin Berger]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[martin.a.berger@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://berxblog.blogspot.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[86.59.5.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-08-08 20:12:55]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-08-08 18:12:55]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Alberto, 
yes, I mean the statiscits added with ASSOCIATE STATISTICS. To be honest, Adrian Billington brought me to them resently: http://www.oracle-developer.net/display.php?id=426#]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>56</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[87.15.209.87]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-08-09 19:46:54]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-08-09 17:46:54]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@Martin

I have added the associated statistics to the report output:
[text]
############################################# function DELLERA.PLSQL_FUNC ###
ASSOCIATED STATISTICS:  default selectivity (.001) default cost (cpu=100 io=10 net=1)
function plsql_func (p varchar2)
return varchar2
is
begin
  return p;
end plsql_func;
[/text]
I've not implemented anything for domain index and indextypes.
Hence now, the three types of associated statistics (selectivity/cost/stat type), associated to three types of objects (functions/packages/types) are reported by xplan.
I've also improved the report here and there (especially improved the way dependent materialized views are reported - now there's the defining statement and the CBO stats of the container table in a simpler output).]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>55</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>57</wp:comment_id>
			<wp:comment_author><![CDATA[Martin Berger]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[martin.a.berger@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://berxblog.blogspot.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[86.59.5.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-08-09 19:52:29]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-08-09 17:52:29]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Alberto,
you are just great!
( I will have to read your scripts in detail, I'm sure there are tons of gems hidden for simply minds like me ).
please keep improving the oracle-world with your knowledge!
 Martin]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>58</wp:comment_id>
			<wp:comment_author><![CDATA[rich]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[sachintugnayat@yahoo.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[87.238.84.64]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-06-18 10:07:28]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-06-18 08:07:28]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hello Sir,
this would be silly question but I am not able to get the output from your script, please help me to solve this.
I want to use this great script for my day to day issues of PT.

used all option but no luck ..

@xplan.sql "%select jp.cp_job_id%" ""

@xplan.sql "" "sql_id=ab4rjccnt8dvx"

@xplan.sql "" "sql_id=ab4rjccnt8dvx,hash=697579389"

getting following errors 

Usage: VAR[IABLE] [  [ NUMBER | CHAR | CHAR (n) | VARCHAR2 (n) |
                               NCHAR | NCHAR (n) | NVARCHAR2 (n) |
                               CLOB | NCLOB | REFCURSOR ] ]
Usage: VAR[IABLE] [  [ NUMBER | CHAR | CHAR (n) | VARCHAR2 (n) |
                               NCHAR | NCHAR (n) | NVARCHAR2 (n) |
                               CLOB | NCLOB | REFCURSOR ] ]
SP2-0552: Bind variable "CURRENT_ERROR" not declared.
Usage: VAR[IABLE] [  [ NUMBER | CHAR | CHAR (n) | VARCHAR2 (n) |
                               NCHAR | NCHAR (n) | NVARCHAR2 (n) |
                               CLOB | NCLOB | REFCURSOR ] ]
Usage: VAR[IABLE] [  [ NUMBER | CHAR | CHAR (n) | VARCHAR2 (n) |
                               NCHAR | NCHAR (n) | NVARCHAR2 (n) |
                               CLOB | NCLOB | REFCURSOR ] ]
Usage: VAR[IABLE] [  [ NUMBER | CHAR | CHAR (n) | VARCHAR2 (n) |
                               NCHAR | NCHAR (n) | NVARCHAR2 (n) |
                               CLOB | NCLOB | REFCURSOR ] ]
Usage: VAR[IABLE] [  [ NUMBER | CHAR | CHAR (n) | VARCHAR2 (n) |
                               NCHAR | NCHAR (n) | NVARCHAR2 (n) |
                               CLOB | NCLOB | REFCURSOR ] ]
SP2-0552: Bind variable "INSTANCE_NAME" not 
...
..
SP2-0552: Bind variable "OPT_PLAN_STATS" not declared.
SP2-0552: Bind variable "OPT_PLAN_STATS" not declared.
SP2-0552: Bind variable "OPT_PLAN_STATS" not declared.
...
..
Input truncated to 46 characters
Input truncated to 2 characters
Input truncated to 2 characters
Input truncated to 15 characters]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>59</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-06-18 11:49:45]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-06-18 09:49:45]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@rich

a) are you using a recent version of sqlplus (e.g. 10g, 11g) ?

b) have you extracted all the files contained in xplan.zip in the current directory ?

regards
Alberto]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>58</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>60</wp:comment_id>
			<wp:comment_author><![CDATA[Rich]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[sachintugnayat@yahoo.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[87.238.84.64]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-08-06 09:13:26]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-08-06 07:13:26]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[thanks Sir,
sorry for late reply, my problem got solved ..

Rich ..]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>61</wp:comment_id>
			<wp:comment_author><![CDATA[Rich]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[sachintugnayat@yahoo.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[87.238.84.64]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-08-06 09:41:13]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-08-06 07:41:13]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[hi Sir,
I am getting following error, while running the xplan.
I tried
SET SERVEROUTPUT ON size UNL

but no luck ..any suggestions ..

@xplan “” “sql_id=akwwmt0txutp3″

ERROR at line 1:
ORA-20000: ORU-10027: buffer overflow, limit of 1000000 bytes
ORA-06512: at “SYS.DBMS_OUTPUT”, line 32
ORA-06512: at “SYS.DBMS_OUTPUT”, line 97
ORA-06512: at “SYS.DBMS_OUTPUT”, line 112
ORA-06512: at line 174
ORA-06512: at line 238
ORA-06512: at line 252
ORA-06512: at line 1694
ORA-06512: at line 2702
ORA-06512: at line 2856]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>62</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[194.149.232.84]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-08-06 11:32:36]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-08-06 09:32:36]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Rich,

can you tell me :

- the version of the database you are connecting to
- the version of sqlplus you are using

The most recent the version of sqlplus, the better; I usually use 11.2 to connect even to older databases.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>61</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>63</wp:comment_id>
			<wp:comment_author><![CDATA[Rich]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[sachintugnayat@yahoo.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[87.238.84.64]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-08-11 16:30:50]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-08-11 14:30:50]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[hello Sir,
sorry for delayed reply, I am using 10202 sqlplus version ..
I will try with 11.2 version ..

thanks for writing a such a beautiful script, I can't say. how useful it was for me ..

Rich ..]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>64</wp:comment_id>
			<wp:comment_author><![CDATA[&raquo; Best Oracle Peformance Tools?]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://dboptimizer.com/?p=460</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[69.163.187.6]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2011-01-13 22:10:13]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2011-01-13 20:10:13]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] xplan  &#8211; extend explain plan info from Alberto Dell Era [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>65</wp:comment_id>
			<wp:comment_author><![CDATA[Lynn Sattler]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[sattlel@bgsu.edu]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[129.1.77.42]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2011-04-19 22:40:59]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2011-04-19 20:40:59]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Alberto,

I've chatted before with you about your xplan routine.

I've been using it some more and I read your documentation again.
I learned by trial and error that I could get it to sort the output by execution time per execution.
Here is what I used:
@xplan "%" "parsed_by=ONEADMIN,order_by=elapsed_time/executions desc"

If you are so inclined you may want to add this sort option to your samples.

Thanks for the xplan routines, I am finding them more useful.  We have the sql tune / addm  big dollar utilities.  I find good info in your output that does not show up with addm report.

Lynn Sattler
Toledo, Ohio  USA]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>66</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[151.59.183.137]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2011-05-01 18:19:16]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2011-05-01 16:19:16]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Lynn,

I'm happy to see that you find xplan useful and that you are so kind in letting me know :)

I have added your suggestion in the header of xplan.sql and I have also expanded the example description
a bit more - it is indeed possible to add full expressions in the order-by list, provided that you turn
commas into semicolons:

--          order_by:  (default: null)
--                    Order statements by the specified columns/expressions. Ties are ordered by sql_text and child_number.
--                    Use the semicolon instead of the comma in expressions.
--                    For example: "order_by=elapsed_time desc;buffer_gets"
--                                 "order_by=elapsed_time/decode(executions;0;null;executions) desc;buffer_gets"

This is useful also in your scenario, since it happens far too often that you get an executions=0 row, and
all it takes to spoil the fun is just one row ;)

ciao
Alberto]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>65</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>67</wp:comment_id>
			<wp:comment_author><![CDATA[Lynn Sattler]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[sattlel@bgsu.edu]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[129.1.77.42]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2011-05-02 22:18:13]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2011-05-02 20:18:13]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Alberto,

Have a new issue with xplan.

Running against v11.1 linux rh5 with multibyte characterset:
NLS_NCHAR_CHARACTERSET                                           AL16UTF16
NLS_LENGTH_SEMANTICS                                             CHAR

( I have a hunch the issue is related to the characterset because xplan works fine against another v 11.1 db)

Issued: @xplan "" ""       (have tried different options, same results)
get this:

new 147:      :OPT_ASH_PROFILE_MINS := 15;
old 148:   &amp;COMM_IF_LT_10G. end if;
new 148:    end if;
declare /* xplan_exec_marker */ -- process options
*
ERROR at line 1:
ORA-06502: PL/SQL: numeric or value error: character string buffer too small
ORA-06512: at line 28

SQL&gt;
SQL&gt; -- print current options values
SQL&gt; variable CURRENT_XPLAN_OPTIONS varchar2(500 char)
SQL&gt; begin
  2  select /*+ xplan_exec_marker */
  3         'inst_id=' || :OPT_INST_ID
  4      || ' plan_stats='||:OPT_PLAN_STATS


Any ideas?
Lynn Sattler]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>68</wp:comment_id>
			<wp:comment_author><![CDATA[Kyle Hailey &raquo; Best Oracle Performance Tools]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.kylehailey.com/best-oracle-performance-tools/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[69.163.187.6]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-09-13 16:07:53]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-09-13 14:07:53]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] xplan [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>69</wp:comment_id>
			<wp:comment_author><![CDATA[Daya]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[dayanand.nani@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[203.99.197.100]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-04-23 12:10:20]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-04-23 10:10:20]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@Martin, Rich, Alberto


Where is the link to download the zip files. I couldn't find the link to download the folder. can some body ping me the link to download the files. 


Thanks,
Daya]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>70</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[151.64.131.138]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-04-25 11:51:24]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-04-25 09:51:24]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Daya,

here it is:

http://www.adellera.it/scripts_etcetera/xplan/index.html

the zip can be found by following the first link on the page]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>fast refresh of single-table materialized views - algorithm summary</title>
		<link>http://www.adellera.it/blog/2009/08/11/fast-refresh-of-single-table-materialized-views-algorithm-summary/</link>
		<pubDate>Tue, 11 Aug 2009 15:57:10 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=297</guid>
		<description></description>
		<content:encoded><![CDATA[Today we are going to investigate how Oracle fast refreshes materialized views (MVs) of a single master table, containing no aggregate but, at most, filter predicates and additional column definitions:
[sql]
create materialized view test_mv
build immediate
refresh fast on demand
with rowid
-- with primary key
as
select test_t1.*, x1+x2 as x1x2
  from test_t1
 where x1 != 0.42;
[/sql]
This kind of MVs might be considered a degenerate case of a join-only MV, a topic that we investigated in an earlier <a href="http://www.adellera.it/blog/2009/08/04/fast-refresh-of-join-only-materialized-views-algorithm-summary/">post</a>, and one could expect the same algorithm. But that is not the case: the <a href="http://34.247.94.223/wp-content/uploads/2009/08/post_0050_single_table_mv.zip">test case</a> shows that the algorithm used is very different. 
The two main differences are (as we are going to illustrate in detail) that UPDATEs are actually used in this case (as <a href="http://www.adellera.it/blog/2009/08/04/fast-refresh-of-join-only-materialized-views-algorithm-summary/#comments">noted</a> by <a href="http://cristiancudizio.wordpress.com/ ">Cristian Cudizio</a>) instead of DELETE+INSERT only, and especially that row-by-row propagation is performed instead of using a couple of single SQL statements.

This kind of MV is frequently used for replication across a db-link (with a clause such as "from test_t1@db_link"); in this scenario, the MV used to be named SNAPSHOT in old releases. I have checked this scenario as well (not included in the test case) and the only difference is that, obviously, the master table test_t1 is referenced via a db-link and a few hints are injected by the refreshing engine. 

In the test case, I have checked both the WITH ROWID and WITH PRIMARY KEY options for the MV DDL; the algorithm turns out as being identical, besides (obviously) that in the former the rowid and in the latter the primary key is used to identify rows.

I am going to follow the path of the previous discussion about join-only MVs referenced above, as both the test case format and some of the actual refresh steps are very similar. I have tested on 9.2.0.8, 10.2.0.4 and 11.1.0.7 for the most common DML on the base table (conventional INSERTs, UPDATEs and DELETEs). I have seen no difference in the algorithm for the three kernel versions.

<b>Materialized view logs configuration</b>

Even for this test case, I have configured the materialized view logs to "log everything" to check whether Oracle is able to take advantage of more information in the log:
[sql]
create materialized view log on test_t1 
with sequence, rowid, primary key (x1, x2) 
including new values; 
[/sql] 
but even for single-table MVs the algorithm uses only the rowid or primary key information, hence the minimal (and hence optimal) log configuration is, for the WITH ROWID option:
[sql]
create materialized view log on test_t1 with rowid;
 [/sql] 
and for the WITH PRIMARY KEY option:
 [sql]
create materialized view log on test_t1 with primary key;
 [/sql] 

<b>Log snapshots</b>

The first step in the refresh algorithm is to take a log snapshot, exactly as in the join-only case, by setting snaptime$$ = current time. Hence the marked log rows (the ones and only ones to consider for propagation) will be characterized by snaptime$$ <= current time and > last snapshot refresh time. See the previous post about the join-only case for a more in-depth discussion. 

Note: actually, for the sake of precision, two (minor) differences with the join-only case are that the snapshot statement is exactly the same in all versions (there's no special version for 11.1.0.7) and that the log is not "inspected to count the number and type of the logged modifications".

<b>Core algorithm: the DELETE and UPSERT steps</b>

Then, the core replication starts. The propagation from the master table is composed of two simple steps, steps that I've named DELETE and UPSERT (UPDate + insERT).

The first <b>DELETE step</b> is a simple select-then-delete row-by-row processing, where each row returned by a select statement is passed to a single-row delete statement. 
For the WITH ROWID option, the select statement of the DELETE step is (editing for readability: removing hints, unnecessary aliases, etc):
[sql]
select distinct m_row$$ 
  from (
select m_row$$ 
  from mlog$_test_t1 
 where snaptime$$ > :1 
   and dmltype$$ != 'I'
       ) log 
 where m_row$$ not in 
       (
select rowid from test_t1 mas
 where (mas.x1 <> 0.42)
   and mas.rowid = log.m_row$$
       );
[/sql]
and the delete is a trivial
[sql]
delete from test_mv where m_row$$ = :1;
[/sql]
The select+delete purpose is to delete all marked rows that are not in the master table anymore, or that are still there but that do not satisfy the MV defining SQL (here, x1 != 0.42) anymore.

In fact, the first in-line view fetches from the log the rowid of a subset (those whose dmltype$$ != 'I') of the marked rows, since :1 is set to the date of the previous refresh of the materialized view. Well actually - the SQL, as it is, would also get the log rows inserted after the snapshot was taken, which is obviously not acceptable since the propagation must operate on a stable set of rows. I'm not sure how the non-marked rows are excluded, but probably the various "select for update" on the log data dictionary tables might play a role by locking the commits on the logs, or maybe the serialization level is set to read-only or serializable (I will investigate this in the future). For now, let's make the conjecture that only the marked rows are selected.

The last correlated subquery simply filters out the rowid of the rows that are still in the master table. The condition dmltype$$ != 'I' ('I' stands for INSERT) is only an optimization, since an inserted row would be filtered out by the subquery anyway - unless it has not been deleted after being inserted, but that would be recorded with another log row with dmltype$$ = 'D'. 

Why are updates (dmltype$$ = 'U') not optimized away as well? This is to delete rows from the MV that no longer belong to the current image of the MV defining SQL statement, since they used to satisfy the filter condition (here, x1 != 0.42) but no longer do after an update. Thanks to the filter condition (x1 != 0.42) being included in the subquery, any row that does not satisfy it anymore after an update will not be filtered out, and hence will be deleted. 

Note that column m_row$$ of the MV is a hidden (but not virtual) column that records, for each MV row, the rowid of the corresponding master table row. It is automatically created when you define the MV with the WITH ROWID option; an index is automatically created on m_row$$ as well (unless you specify USING NO INDEX, something that does not make sense if you want to fast refresh the MV). Hence you do not need to create any additional index, neither on the master table nor on the MV, to optimize this step of the fast refresh.

Switching to the WITH PRIMARY KEY option, the select statement of the DELETE step is
[sql]
select distinct pk1
  from (
select pk1 
  from mlog$_test_t1
 where snaptime$$ > :1 
   and dmltype$$ != 'I')
       ) log 
 where pk1 not in 
       (
select pk1
  from test_t1 mas 
 where (mas.x1 <> 0.42) 
   and log.pk1 = mas.pk1
       );
[/sql]
and the delete is simply
[sql]
delete from test_mv where pk1 = :1;
[/sql]
That is, the statements are the same as in the WITH ROWID case, with the primary key instead of the rowid in all statements. Since the master table must have a primary key for the MV create to succeed, and since an index on the MV that spans the primary key column(s) is automatically created (unless you specify USING NO INDEX of course), even in the WITH PRIMARY KEY case you do not need to create any additional index for performance. Actually, for best performance, an index on the master table that combines the PK and the column(s) referenced by the MV filter condition - here on (pk1, x1) - might help a bit, since probably the optimal plan is a nested loop having test_t1 as the inner table. This would avoid a block get on the master tables for marked rows not satisfying the MV filter condition; the effectiveness of this index depends on whether you have a lot of updates on the column referenced in the filter condition. 

The <b>UPSERT step</b> is a simple select-then-upsert row-by-row processing, where each row returned by a select statement (that calculates the current image of the row that needs to be propagated to the MV) is used to update the corresponding row in the MV; if the update finds no row, the row is inserted.

For the WITH ROWID option, the select statement of the UPSERT step is:
[sql]
select current.x1, current.x2, current.pk1, current.x1x2,
       rowidtochar (current.rowid) m_row$$ 
  from (
select x1, x2, pk1, x1+x2 as x1x2 
  from test_t1 
 where (x1 <> 0.42)
       ) current, 
       (
select distinct m_row$$ 
  from mlog$_test_t1
 where snaptime$$ > :1 
   and dmltype$$ != 'D'
       ) log
 where current.rowid = log.m_row$$;
[/sql]
and the update and insert statements are simply:
[sql]
update test_mv set x1=:1, x2=:2, pk1=:3, x1x2 = :4 where m_row$$ = :5;
insert into test_mv (x1,x2,pk1,x1x2,m_row$$) values (:1,:2,:3,:4,:5);
[/sql]
The select+upsert purpose is to calculate the new image of all marked rows that satisfy the MV defining SQL filter condition (here, x1 != 0.42) and then overwrite the old image in the MV with the new one. Note that an update on the master table might produce an insert if the old image did not satisfy the filter condition and the new one does. 

The structure of the select statement should be obvious after the previous illustration of the DELETE step. Note of course the different optimization in the second inline view (dmltype$$ != 'D'). Even in this case, the automatically created index on the m_row$$ MV column optimizes the update statement, and no other index is necessary for performance on neither the base table nor the MV.

Switching to the WITH PRIMARY KEY option, the select statement of the UPSERT step is
[sql]
select current.x1, current.x2, current.pk1, current.x1x2 
  from (
select x1, x2, pk1, x1+x2 x1x2 
  from test_t1
 where (x1 <> 0.42)
       ) current, 
       (
select distinct pk1 
  from mlog_test_t1
 where snaptime$$ > :1 
   and dmltype$$ != 'D'
       ) log 
 where current.pk1 = log.pk1; 
[/sql]
and the update and insert statements are:
[sql]
update test_mv set x1=:1, x2=:2, pk1=:3, x1x2=:4 where pk1=:3;
insert into test_mv  (x1, x2, pk1, x1x2) values (:1, :2, :3, :4); 
[/sql]


And the same considerations about the substitution of rowid with the primary key hold. The index on the master table on (pk1, x1) might be of help here as well.

So here it is what the algorithm, essentially, is all about: a row-by-row propagation of all the modified (marked) rows to the MV, with a few optimizations.

<b>Algorithm optimizations</b>

Whatever the type of modifications, the algorithm is always the same: both the DELETE and UPSERT step are performed in all cases. Of course, in both cases, the select statement might select no row.]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>297</wp:post_id>
		<wp:post_date><![CDATA[2009-08-11 17:57:10]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-08-11 15:57:10]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[fast-refresh-of-single-table-materialized-views-algorithm-summary]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="materialized-views"><![CDATA[materialized views]]></category>
						<wp:comment>
			<wp:comment_id>71</wp:comment_id>
			<wp:comment_author><![CDATA[Blogroll Report 07/08/2009 – 14/08/2009 &laquo; Coskan&#8217;s Approach to Oracle]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://coskan.wordpress.com/2009/08/14/blogroll-report-10/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[72.233.96.143]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-08-14 18:47:07]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-08-14 16:47:07]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] Alberto Dell’Era &#8211; Fast refresh of single-table materialized views &#8211; algorithm summary [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>72</wp:comment_id>
			<wp:comment_author><![CDATA[materialized views]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://starttags.com/tags/materialized-views</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[98.240.245.202]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-04-04 00:08:09]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-04-03 22:08:09]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] enterprise by Dan Chak on ... Sample Chapter: Materialized Views from Enterprise Rails (O'Reilly ...Alberto Dell'Era's Oracle blog fast refresh of single-table ...Today we are going to investigate how Oracle fast refreshes materialized views (MVs) of a single [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>73</wp:comment_id>
			<wp:comment_author><![CDATA[Reiner Kuehl]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[reiner.kuehl@genedata.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[91.195.142.1]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-03-28 09:02:06]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-03-28 07:02:06]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Thanks Alberto for this post.
We have recently started working with materialized views. Our scenario (using Oracle 11.2.0.3) is:
We have a master table with more than 200.000.000 rows. We have created two MVs based on this master table only, no aggregates. The only where-clause is 'column1 != 0' for the first MV and 'column2 in (9,11)' for the second.
The materialized view log does contain this two columns. Although recommended, I have made bad experience with commit-scn-based MV log, therefore using timestamp based MV log.
Both MVs are defined 'refresh fast on commit'.
Best
Reiner
Now my question:
When updating a row in the master table with 'column1=0' I wouldn't expect any refresh action on the first MV. Can you explain why Oracle performs deletes and upserts on the first MV although the master table record is not relevant for this MV (due to column1=0)?]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>74</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-03-28 13:11:04]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-03-28 11:11:04]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Reiner,
can you build a simple test case to reproduce ?]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>73</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>75</wp:comment_id>
			<wp:comment_author><![CDATA[Reiner Kuehl]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[reiner.kuehl@genedata.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[91.195.142.1]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-04-04 12:15:12]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-04-04 10:15:12]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Thanks Alberto for your quick response. 
No test case yet. I have recreated the MV log and MVs. Now performance is  very good. In addition, I have locked the statistics of the MV log (always empty - all MVs are refresh on commit) and set "_mv_refresh_use_stats" to TRUE.
I have two similar systems. One with these two fixes and the other without. Let's see whether the issue will occur again.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>76</wp:comment_id>
			<wp:comment_author><![CDATA[Reiner Kuehl]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[reiner.kuehl@genedata.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[88.67.137.30]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-07-03 12:58:38]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-07-03 10:58:38]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto, 
I have build a test case and reproduced the issue. To keep it simple you can just modify the update statements of your own test case:
[sql]
update test_t1 set pk1 = -pk1 where pk1 = 1 and x1 = 0.42;
update test_t1 set x1  = -x1  where pk1 = 2 and x1 = 0.42;
delete from test_t1           where pk1 = 3 and x1 = 0.42;
[/sql]
It is obvious that these statements should not lead to any modifications in the materialized views records (where x1 != 0.42).
Nevertheless, the algorithm does not change and performs the same delete and upsert statements. 
You have the x1-column in your materialized view log definition but it is not used. 

Our problem is: We have thousands of such updates in our application. Due to this algorithm our application is slowed down. I am always seeing the materialized view related 'Delete' and 'Upsert' in my top-sql list.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>77</wp:comment_id>
			<wp:comment_author><![CDATA[satish]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[pani123@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[12.207.193.66]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-12-07 01:45:32]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-12-06 23:45:32]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[How do I know how many changes are happening on an mview i.e. how many updates, how many deletes and how many inserts ?
Appreciate your response.

- Satish]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>78</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[151.64.130.30]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-01-25 16:33:58]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-01-25 14:33:58]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Satish,

sorry for the long delay, my notification module has gone berserk again ;(

There's nothing specific about MVs as far as I know. You can achieve what you want by inspecting all_tab_modifications, by taking the difference of the values before and after the MV refresh. Be sure to call dbms_stats.flush_database_monitoring_info before reading that view in order to have the most current values inside all_tab_modifications, since they are flushed from the SGA lazily, and not immediately after the modifications have been performed, for efficiency reasons.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>77</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>79</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[151.64.130.30]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-01-25 16:38:33]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-01-25 14:38:33]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Moreover: if the refresh is complete and non-atomic, you are not going to see any delete, simply because a truncate happens instead of regular deletes during the refresh. There's column "truncated" in all_tab_modifications in 11.2 that will tell you that a truncated happened (it will be increased by one).]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>78</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>80</wp:comment_id>
			<wp:comment_author><![CDATA[Iudith Mentzel]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[mentzel.iudith@il.zim.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[91.197.103.50]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-03-19 16:31:06]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-03-19 14:31:06]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hello Alberto,

My name in Iudith Mentzel and I am an Oracle developer at Zim Integrated Shipping Services in Haifa, Israel.

I am following for some longer time your very interesting posts regarding the Materialized views internals so, though this thread is an older one, I still would like to share with you my findings,
in the hope that they will highlight some points that you may find interesting.

In research of a specific case we have encountered, I performed a test using your test script single_table_mv.sql, running it in version 11.2.0.3.0.

What I have found is very interesting, namely:

For a local single table materialized view 
( that is, running your script exactly as is )
------------------------------------------------------------------------
Oracle performs indeed the 3 steps, but they look different than in the previous versions, as follows:

-- the log snapshot (which is the same - 6 rows updated in our test case)

[sql]
update &quot;TW&quot;.&quot;MLOG$_TEST_T1&quot; set snaptime$$ = :1  
where
 snaptime$$ &gt; to_date('2100-01-01:00:00:00','YYYY-MM-DD:HH24:MI:SS')
[/sql]

call     count       cpu    elapsed       disk      query    current        rows
------- ------  -------- ---------- ---------- ---------- ----------  ----------
Parse        1      0.00       0.00          0          0          0           0
Execute      1      0.00       0.00          0          6          1           6
Fetch        0      0.00       0.00          0          0          0           0
------- ------  -------- ---------- ---------- ---------- ----------  ----------
total        2      0.00       0.00          0          6          1           6


-- the delete 

[sql]
DELETE FROM &quot;TW&quot;.&quot;TEST_MV&quot; SNAP$ 
WHERE
 &quot;PK1&quot; IN (SELECT DISTINCT MLOG$.&quot;PK1&quot; FROM &quot;TW&quot;.&quot;MLOG$_TEST_T1&quot; MLOG$ WHERE 
  &quot;SNAPTIME$$&quot; &gt; :1 AND (&quot;DMLTYPE$$&quot; != 'I'))
[/sql]

call     count       cpu    elapsed       disk      query    current        rows
------- ------  -------- ---------- ---------- ---------- ----------  ----------
Parse        1      0.00       0.00          0          0          0           0
Execute      1      0.00       0.00          0          9          9           3
Fetch        0      0.00       0.00          0          0          0           0
------- ------  -------- ---------- ---------- ---------- ----------  ----------
total        2      0.00       0.00          0          9          9           3


Here we see the first changed behavior:

The DELETE is performed as a single SQL operation, but without the condition

WHERE (LOG$."PK1") NOT IN 
(SELECT MAS_TAB$."PK1" FROM "TEST_T1" "MAS_TAB$" WHERE ("MAS_TAB$"."X1"0.42) AND LOG$."PK1" = MAS_TAB$."PK1")

that appeared in the SELECT cursor for this step in the previous versions.

This means that ALL the MLOG$ rows corresponding to updates of non-PK columns in the base table ( those logged with DMLTYPE$$='U' ) are deleted from the materialized view !


This behavior is not a side-effect of the sample materialized view containing a filtering condition 
( in the sample case: "where x1 != 0.42" ).
Exactly the same happens without a filtering condition, as I checked on a real-life case.

In the previous versions the deletions were performed row-by-row, but this step DID NOT include
rows for DMLTYPE$$='U' whose PK-s are still present in the base table.


-- the upsert

This step is also performed in a single SQL MERGE statement, and not as row-by-row INSERT or UPDATE statements,
as it happened in previous versions:

[sql]
MERGE INTO &quot;TW&quot;.&quot;TEST_MV&quot; &quot;SNA$&quot; USING (SELECT CURRENT$.&quot;X1&quot;,CURRENT$.&quot;X2&quot;,
  CURRENT$.&quot;PK1&quot;,CURRENT$.&quot;X1X2&quot; FROM (SELECT &quot;TEST_T1&quot;.&quot;X1&quot; &quot;X1&quot;,
  &quot;TEST_T1&quot;.&quot;X2&quot; &quot;X2&quot;,&quot;TEST_T1&quot;.&quot;PK1&quot; &quot;PK1&quot;,&quot;TEST_T1&quot;.&quot;X1&quot;+&quot;TEST_T1&quot;.&quot;X2&quot; 
  &quot;X1X2&quot; FROM &quot;TEST_T1&quot; &quot;TEST_T1&quot; WHERE &quot;TEST_T1&quot;.&quot;X1&quot;&lt;&gt;0.42) CURRENT$, 
  (SELECT DISTINCT MLOG$.&quot;PK1&quot; FROM &quot;TW&quot;.&quot;MLOG$_TEST_T1&quot; MLOG$ WHERE 
  &quot;SNAPTIME$$&quot; &gt; :1 AND (&quot;DMLTYPE$$&quot; != 'D')) LOG$ WHERE CURRENT$.&quot;PK1&quot; = 
  LOG$.&quot;PK1&quot;)&quot;AV$&quot; ON (&quot;SNA$&quot;.&quot;PK1&quot; = &quot;AV$&quot;.&quot;PK1&quot;) WHEN MATCHED THEN UPDATE  
  SET &quot;SNA$&quot;.&quot;X1&quot; = &quot;AV$&quot;.&quot;X1&quot;,&quot;SNA$&quot;.&quot;X2&quot; = &quot;AV$&quot;.&quot;X2&quot;,&quot;SNA$&quot;.&quot;PK1&quot; = 
  &quot;AV$&quot;.&quot;PK1&quot;,&quot;SNA$&quot;.&quot;X1X2&quot; = &quot;AV$&quot;.&quot;X1X2&quot; WHEN NOT MATCHED THEN INSERT  
  (SNA$.&quot;X1&quot;,SNA$.&quot;X2&quot;,SNA$.&quot;PK1&quot;,SNA$.&quot;X1X2&quot;) VALUES (AV$.&quot;X1&quot;,AV$.&quot;X2&quot;,
  AV$.&quot;PK1&quot;,AV$.&quot;X1X2&quot;)
[/sql]

call     count       cpu    elapsed       disk      query    current        rows
------- ------  -------- ---------- ---------- ---------- ----------  ----------
Parse        1      0.01       0.00          0          0          0           0
Execute      1      0.00       0.01          4         19         35           3
Fetch        0      0.00       0.00          0          0          0           0
------- ------  -------- ---------- ---------- ---------- ----------  ----------
total        2      0.01       0.01          4         19         35           3


This MERGE will of course perform an INSERT for those updated rows that were additionally deleted in the "delete" step.

In summary, for ALL the UPDATE-s performed on the master table, the refresh does perform a DELETE + INSERT on the materailzied view, and not just for the updates that changed the PK columns, as it happened in previous versions.


I suppose that this may slow down the refresh performance, for cases where most of the DML activity consists in updating non-PK columns.

It is not clear to my why Oracle decided in 11.2.0.3.0 that performing a DELETE+INSERT is "cheaper" than performing an UPDATE, for local materialized views anyway.


For a remote single table materialized view
-------------------------------------------
I performed an identical test as the above one, but where the single table materialized view is located on a remote site  ( the usual replication materialized view ).

[sql]
create materialized view test_mv_r
build immediate
refresh fast on demand
with &amp;mv_with.
as
select test_t1.*, x1+x2 as x1x2
  from test_t1@dblink
 where x1 != 0.42
;
[/sql]

Here the DELETE and UPDATE steps were performed row-by-row, just like in the previous versions, and an UPDATE of a non-PK column is performed indeed as an UPDATE on the materialized view,
and not as a DELETE + INSERT.


Just for the sake of art, it would be interesting to compare the performance of a refresh of a local materialized view 
( doing single SQL statements ) to that of an identical materialized view, but defined using a loop-back database link, to make it appear as a remote materialized view, so expected to refresh row-by-row.

It would be very strange to find out that the remote materialized view refresh can be faster than that of a local one.


-------------------------------------------------------------------------
A second issue is related to the refresh having to use a "consistent data set" from the MLOG$ table, as you have mentioned in the post itself.

As per our conclusions, based on a specific case that lead to these investigations, this seems *NOT* to be the case, anyway not in 11.2.0.3.0.

That is, the log snapshot step is performed, but looks like this is done *ONLY* for making the SNAPTIME$$ usable for further PURGE-s of the MLOG$ table after each refresh.

Otherwise, for both the local materialized view and for the remote one, the access to the MLOG$ table only contains the 

"SNAPTIME$$ &gt; :last_refresh_time"  condition

but *NOT* the

"SNAPTIME$$ &lt;= :current_snapshot_time&quot;  condition !


This effectively means that, for tables with high DML activity, the new rows added to the MLOG$ *BETWEEN* the time of the &quot;delete&quot; step and the time of the &quot;upsert&quot; step ( and in fact also between the &quot;log snapshot&quot;
step and the &quot;delete&quot; step ) are used by the current refresh, so the refresh DOES NOT use a strictly consistent data set  !!!

We discovered this as a result of a very specific case we have:
A table has a PK composed of four significant columns, where at least two of them are subject to UPDATE-s, and also has a UK composed of a single surrogate column, which is never updated  
( a bad enough design, in my opinion ).

The table is very large and &quot;wide&quot;, with many columns.

So, we have a local materialized view on this table, whose only purpose is to contain ALL the rows, but only a low number of basic columns from the very many of the base table.

The materialized view has the same PK and UK columns as the base table.

The UK constraint is defined as DEFERRABLE, so it is enforced only at the last step of the refresh.

However, we do encounter sometimes refresh failures as a result of UK violations, and, in most cases, after such a failure, the next refresh is successful, because it &quot;corrects&quot; the &quot;mlog$ data set inconsistency&quot;
that I described above.

For a &quot;normal&quot; table design, where PK columns are not updated at all or anyway not frequently, this problem might not become visible, and each refresh practically uses &quot;more logged data&quot; from the MLOG$ table
than the data it marks in the log snapshot phase.

Occasionaly, though rarely, we do encounter also FK violations in refresh groups where all the materialized views involved in the constraint are in the same refresh group, the FK is DEFERRABLE, 
and these violations also do usually &quot;correct themselves&quot; on the next refresh.


It looks to me that for really using a &quot;strictly consistent MLOG$ data set&quot;, we should go for performing the refresh using SERIALIZABLE transactions only.

As far as I was aware, the UPDATE of the MLOG$ table performed in the &quot;log snapshot&quot; phase is committed immediately, to avoid blocking locks on refreshes of other materialized views that may use the same
MLOG$ table.
I don&#039;t see such a COMMIT statement in the trace file of the tests that I performed, though.

However, I think that using SERIALIZABLE transactions will make at least the &quot;delete&quot; and &quot;upsert&quot; steps see a consistent set of the MLOG$ data, though not necessarily consistent with the set seen by the &quot;log snapshot&quot; step, if that step is indeed committed as a separate transaction.

In your original post you mentioned that you would investigate this &quot;consistent data set&quot; issue further,
I would be very glad to read your conclusions.

Again, all your posts are GREAT, GREAT, GREAT  !

Thanks a lot, TANTE GRAZIE !

Iudith Mentzel
ZIM Integrated Shipping Services Ltd.
Haifa, Israel]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>81</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[151.64.143.121]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-03-22 12:55:15]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-03-22 10:55:15]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Iudith,

a) first of all, many thanks for your kind words - I really appreciate that you find my work interestingly and have spent your time to let me know :)

b) As an curious coincidence, I have actually noticed, a couple of weeks ago, that algorithm change in 11.2, and I'm very happy that you have described it here so that it can be shared, and I can further comment on it sharing my observations as well.

I totally agree that this change can make the refresh much more expensive, especially if you have some indexes on the MV - in this (very common) scenario, when the update on the master table is propagated as a delete+insert, the corresponding entry on the indexes must be first removed and then re-inserted, even if the indexed values have not changed(!); in the old version of the algorithm, an update to the same value would have not triggered any index modification (since the kernel always checks the before/after value before considering changing the index). 

Worst, the delete+insert happens even if you update a row that is not referenced by the MV definition(!). The information about what columns have been changed are in the log, in the column CHANGE_VECTOR$$, which gets completely ignored.

Getting two visits for each index, and for every updated rows, is going to be a bit expensive ... 

c) I would conjure that the old algorithm was simply the SNAPSHOT's one turned local, and that now development has "optimized" it to conform to the same strategy used by "join" and "group-by" MVs, that are mostly based on delete+insert. 

Your idea of using a loopback db-link looks promising - of course YMMV, but it is a nice idea to try.

d) your description of the refresh not using a "strictly consistent MLOG$ data set" looks like a very bad bug to me, of the "wrong result" kind (the most severe one), since it makes appear in the MV a dataset that has never existed. 
In my opinion, the developers simply forgot to add the "as of snapshot(:b_scn)" clause that is present on all other kind of (local) MVs refreshes.

e) about the commit not showing after the "log snapshot" - I notice that you use TKPROF to read the trace; have you tried inspecting it directly? Usually the kernel does not submit commit statements, but a "commit" api call instead, that TKPROF ignores since it is not associated to any statement. 
The XCTEND line traces the transaction end in both cases.
For further info, check this great post by Christian Antognini:
http://antognini.ch/2009/08/synthetic-commits-and-rollbacks/

f) it looks like that you are trying to implement what I call a "mirror MV", to just select only the column and rows you are interested into, without any data transformation. We are trying the same strategy, in our case using a custom trigger instead of the MV which is MUCH LESS costly - since a MV log implicitly installs a (kernel) trigger as well, and hence the very same optimizations that are disabled by the trigger are disabled by the MV log anyway.
We loose the query rewrite though ... 
I might blog about this "in the future" ;) but contact me at alberto.dellera@gmail.com if interested.

Ciao!
Alberto]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>80</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>82</wp:comment_id>
			<wp:comment_author><![CDATA[Iudith Mentzel]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[mentzel.iudith@il.zim.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[91.197.103.50]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-03-24 13:31:09]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-03-24 11:31:09]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hello Alberto,

Thanks a lot for your so detailed answer, you are so kind :)

Following Christian Antognini's post, I looked into the trace file itself, and found there sereval lines with "XCTEND rlbk=0".

Two of them appear after the "DBMS_MVIEW.REFRESH" cursor and after a recursive "UPDATE DBMS_LOCK_ALLOCATED" statement issued on behalf 
of the REFRESH call.
For each of these, an explicit cursor performing a COMMIT is added and there is also an explicit COMMIT appearing in the file after being processed by TKPROF.

Several other "XCTEND rlbk=0" rows appear in the trace file following recursive SELECT-s and UPDATE-s performed on internal mview maintenance tables like SYSTEM.DEF$_DESTINATION, SUMPARTLOG$, SUMDETAIL$, and these synthetic commits do not have explicit COMMIT-s included in the file processed by TKPROF.

I guess that one of these "synthetic commits" should be the one that also commits the UPDATE issued during the "log snapshot" phase.


Anyway, in the meantime I tried to perform the refresh using SERIALIZABLE transactions, by issuing the following:

[sql]
alter session set isolation_level = serializable;

exec dbms_mview.refresh ( list =&gt; 'test_mv', method =&gt; 'f', atomic_refresh =&gt; true); 
[/sql]

Unfortunately, however, it failed with the following error:

*
ERROR at line 1:
ORA-00604: error occurred at recursive SQL level 1 
ORA-08177: can't serialize access for this transaction 
ORA-06512: at "SYS.DBMS_SNAPSHOT", line 2563 
ORA-06512: at "SYS.DBMS_SNAPSHOT", line 2776 
ORA-06512: at "SYS.DBMS_SNAPSHOT", line 2745 
ORA-06512: at line 1 


For the test case (based on your original test script, with the above ALTER SESSION added), it looks from the trace file that id DID NOT perform any of the 3 refresh steps, but rather failed before that.

For my real case, though I got ultimately the same ORA-08177 error, the "log snaphshot" and "delete" phases statements still appear in the trace file, but the "upsert" step does not appear, so we can probably conclude that the error happened during the DELETE phase, though this is very unlikely logically, because the materialized view table is only updated by the refresh, and not by any other sessions or processes.

Also, my tests were all performed in an environment where no other refreshes of other materialized views were running in other sessions.

I was very confident that by using serializable transactions the refresh could work, except for possibly receiving an ORA-01555 error if the refresh takes too long and the MLOG$ table cannot be read consistently across the "delete" and "update" phases.

But, unluckily, this is NOT the case, it looks like there are many other "internal subtleties" that prevent a serializable transaction to be suitable for this scenario.

If the ORA-08177 did happen indeed as a result of one of the recursive operations performed during the refresh on one of the SYS tables, then this might be a problem when other materialized views are refreshing simultaneously, because all these refreshes do update the same SYS tables.

Using an explicit trigger could have been an option, of course, but since Oracle introduced the "kernelized" trigger that performs the changes to the MLOG$ tables, it always seemed (and Oracle also stated it explicitly) that this internal trigger is more efficcient than the previous "external" trigger used by older versions.

As you said, the MLOG$ data set inconsistency looks as a very severe problem.

It also exists for replication materialized views containing db-links, so it was probably "borrowed" from there, where I guess it always worked like this, in previous versions as well, because I can hardly believe that somebody just "volunteered" to remove the "as of snapshot(:b_scn)", if it was already there ...

I will try now to see how I can cope with the real-life problem by trying to disable and reenable the UK constraint that prevents the refresh from being successful.

Reenabling the constraint after the refresh may be time-consumig, but, instead, I would spare the time spent by having to repeat the refresh several times after UK violation failures, in an attempt to reach a consistent MLOG$ data set.

I am glad that you confirmed my supposition regarding the inefficiency of propagating UPDATE-s as "DELETE+INSERT", you are perfectly right, there are also many indexes on the table and probably many of the updates are for non-indexed columns ... the refresh does indeed take a long time.

Probably using a loop-back db-link would have been faster, though, the MLOG$ data inconsistency should still be handled using some trick in this particular case.


I am always glad to read your blogs on any of these and other topics :):)

Some years ago I also followed passionately after your blogs and papers related to histogram internals, and I was also amazed :):)

Yes, I definitely find your deep explorations as very valuable, and very clearly explained and I am delighted that you also took the time to blog about your findings in so much detail and with so many examples.

Keep up with the GREAT WORK !

Ciao e tante grazie ancora una volta !

Iudith Mentzel
Haifa, Israel]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>NoCOUG&#039;s &quot;First international SQL challenge&quot;</title>
		<link>http://www.adellera.it/blog/2009/08/24/nocougs-first-international-sql-challenge/</link>
		<pubDate>Mon, 24 Aug 2009 16:04:08 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=317</guid>
		<description></description>
		<content:encoded><![CDATA[Just a short note to tell my friends that I have been bestowed the <i>August Order of the Wooden Pretzel</i>, that is, that I won the NoCOUG's "First international SQL challenge" with <a href=" http://www.adellera.it/investigations/nocoug_challenge/index.html">this solution</a>. 

I'm especially happy to see that, after (way too) many years since graduation, I am still able to use my math skills to solve problems ... :). 

Many thanks to <a href="http://iggyfernandez.wordpress.com/ ">Iggy Fernandez</a> for setting up the contest (and running it with love and dedication), <a href="http://www.singingsql.com">Dan Tow</a> for judging the solution and of course <a href=" http://prodlife.wordpress.com/">Chen Shapira</a> for advertising and "supporting" it on her blog!]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>317</wp:post_id>
		<wp:post_date><![CDATA[2009-08-24 18:04:08]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-08-24 16:04:08]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[nocougs-first-international-sql-challenge]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[card@rural.com]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>CBO: the &quot;non-empty result set&quot; assumption</title>
		<link>http://www.adellera.it/blog/2009/09/03/cbo-the-non-empty-result-set-assumption/</link>
		<pubDate>Thu, 03 Sep 2009 13:14:58 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=322</guid>
		<description></description>
		<content:encoded><![CDATA[The CBO assumes that SELECT statements are always going to retrieve at least one row - even if this is not necessarily the case, of course. Understanding <i>why</i> this is done is both useful and fascinating.

We must start from the very beginning and remember that one of the most important tasks of the CBO is estimating the statement cardinality, that is, to make a guess about the number of rows that will be fetched. In statistics, that means that the CBO must calculate (estimate) the <a href=" http://en.wikipedia.org/wiki/Expected_value">expected value</a> of the cardinality <a href=" http://en.wikipedia.org/wiki/Random_variable">random variable</a>.

In order to calculate the expected value, in our case, we can consider the table <a href=" http://en.wikipedia.org/wiki/Statistical_population">potential population</a> (i.e. the set of all possible row values), execute (ideally!) the statement over each table in the population, and compute (again ideally) the average of the cardinality of each result set.

The population must be coherent with the set of observations stored in the data dictionary when the table and column statistics were collected; in other words, the population must satisfy a set of statistical constraints. For example the number of distinct values in each column must be equal (or statistically equal) to the num_distinct statistic; the range of values must be inside (or statistically inside) the min-max interval dictated by low_value-high_value, etc.

Now consider a simple statement with a filter predicate:
[sql]
select ... 
  from t
 where x = 1;
[/sql]
Assuming that column X contains numbers, there are an <i>infinite number</i> of values of X inside the min-max interval (assuming that min is not equal to max) that can satisfy the constraints. In the table population, how many tables have X=1, and how many rows will be retrieved by the statement?

If a frequency histogram has been collected on column X, the population is constrained to (statistically) satisfy it, and hence we have the answer: the expected cardinality is zero if value X is not contained in the histogram and strictly greater than zero (computed with the usual formula) otherwise.

But if no histogram is collected on the column, the number of tables with X=1 will be negligible, and hence the expected value will be zero. That is not very useful.

But if we assume that the <b>result set is never empty</b>, then we have another constraint to apply. That means that the value X is contained in all tables of the population, and (if we add the additional customary assumption of uniform distribution of values) we can easily derive the usual num_rows / num_distinct(X) formula.

Note that the "non-empty result set" assumption is very strong; it means that the statement and the table are not independent, but actually are highly correlated, since the assumption is equivalent to say that the client executes the statement in order to retrieve rows whose existence is certain before the statement execution. In other words, the CBO infers information about the data from the statement itself, not only from the data dictionary statistics, trusting that the user has some knowledge about the data stored in the table.

The assumption is of course more than reasonable for almost all statements and clients, but not always. For instance, X=1 might mean "new record" in a table-queue that contains the history of the last few years as well, and the table migth have no observable record with X=1 thanks to the consumer(s) being very quick or the producer(s) rarely enqueuing records. Or maybe, X=1 might mean "failed record" in a process that never fails, and the statement could be issued for checking the rows existence, not for retrieving them. In this kind of scenario, the CBO predictions can be affected by the "non-empty result set" assumption.]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>322</wp:post_id>
		<wp:post_date><![CDATA[2009-09-03 15:14:58]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-09-03 13:14:58]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[cbo-the-non-empty-result-set-assumption]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="cbo"><![CDATA[CBO]]></category>
		<category domain="category" nicename="performance-tuning"><![CDATA[performance tuning]]></category>
						<wp:comment>
			<wp:comment_id>83</wp:comment_id>
			<wp:comment_author><![CDATA[Entradas de Oracle semanas 35-37 &laquo; Gruñidos sobre Oracle y SAP]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://fidelinho.com/2009/09/13/entradas-de-oracle-semanas-35-3/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[74.200.244.84]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-09-13 13:42:49]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-09-13 11:42:49]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] en SAP debe ser configurado según sus recomendaciones. Alberto Dell&#8217;Era nos explica que el CBO asume siempre que una sentencia SELECT devuelve por lo menos una fila. Acabo con un articulo interesante de Porus Homi Havewala, &#8220;Patch a Thousand Databases, Using [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>84</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; CBO: about the statistical definition of &#8220;cardinality&#8221; (densities part I)]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2009/10/03/cbo-about-the-statistical-definition-of-cardinality-densities-part-i/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-10-03 12:32:28]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-10-03 10:32:28]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] all values of :x for which w(:x) is non zero. At the other end of the spectrum, that is, under the non empty result set assumption, we have E[card] = sum ( w(:x) ) * num_rows / num_distinct(X) = num_rows / num_distinct(X), the [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>85</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; CBO: NewDensity for Frequency Histograms,11g-10.2.0.4 (densities part IV)]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2009/10/23/cbo-newdensity-for-frequency-histograms11g-10204-densities-part-iv/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-10-23 18:07:18]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-10-23 16:07:18]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] statistics collection time, hence it returns the minimal cardinality estimate compatible with the non empty result set assumption (check this post for the importance of this assumption). If the statistics are reasonably fresh, [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>86</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; CBO: the formula for the &#8220;density&#8221; column statistic (densities part II)]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2009/10/10/cbo-the-formula-for-the-density-column-statistic-densities-part-ii/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-10-25 19:45:32]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-10-25 17:45:32]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] is known to be not popular, hence hitting the NPS - remember that the CBO operates under the "non-empty result set assumption", hence if the literal does not hit a popular value, it must hit a value of the [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>87</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; CBO: &#8220;NewDensity&#8221; replaces &#8220;density&#8221; in 11g, 10.2.0.4 (densities part III)]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2009/10/16/cbo-newdensity-replaces-density-in-11g-10204-densities-part-iii/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-10-25 19:46:07]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-10-25 17:46:07]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] (class) of all possible equality filter predicate statements that hit the NPS, under the usual "non-empty result set assumption" and the further (strange and strong) assumption that the more a value is represented in the NPS, [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>88</wp:comment_id>
			<wp:comment_author><![CDATA[non zero values]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://starttags.com/tags/non-zero-values</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[98.240.245.202]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-03-24 23:10:55]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-03-24 21:10:55]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] with a zero simulation however they can if required be executed in a non zero simulation time. ...Alberto Dell'Era's Oracle blog CBO: the non-empty result ...The CBO assumes that SELECT statements are always going to retrieve at least one row - even if this [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>An interview with Mark Townsend</title>
		<link>http://www.adellera.it/blog/2009/09/29/an-interview-with-mark-townsend/</link>
		<pubDate>Tue, 29 Sep 2009 11:51:38 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=328</guid>
		<description></description>
		<content:encoded><![CDATA[While attending the <a href=" http://www.oracle.com/webapps/events/EventsDetail.jsp?p_eventId=94800&src=6805597&src=6805597&Act=37 ">11gR2 launch event</a> in Milan last Thursday, I had the distinguished opportunity (invited, as a blogger, by the Oracle team that was organizing the event) to meet <a href="http://www.oracle.com/us/corporate/press/Spokespeople/016367">Mark Townsend</a> and exchange a few words about the new features of 11gR2 and the Oracle database in general as well. 

For those who don't know, Mark is (among other things) the Vice President in charge of coordinating the Product Managers and a technical expert at the same time, and this rare combination has the advantage that you can ask him about any feature you like at whatever granularity you like, from the strategic level down to the technical gory details. In fact Mark is frequently seen at public events (such as Oracle Open World), speaking to mixed audiences composed of both Engineers and Management. 

We spoke about many new features of 11gR2, so much in fact that in order to do justice to the information that Mark very kindly provided me, I will use them as the foundation of some future blog posts. In brief anyway, I noticed that this release has features that are targeted mostly to vastly improve the "grid", but with very interesting features for the "core" as well (my personal favourites being the <a href=" http://download.oracle.com/docs/cd/E11882_01/server.112/e10881/chapter1.htm#FEATURENO08862">in-memory parallel execution</a> and the new <a href=" http://download.oracle.com/docs/cd/E11882_01/server.112/e10810/refresh.htm#DWHSG0319 ">SCN-based MV log</a>, which I plan to blog about in the very near future).

But especially, I didn't miss the unique opportunity to discuss with one of the top players of Oracle Corporation about the amount of information that Oracle shares with its professionals, obviously trying to push for much more. I'm sure that everyone that works with any kind of software product agrees with me on the fact that knowing how the product works is key not only to troubleshooting (that being almost obvious) but to good design also, or perhaps especially; the more you know, the better designer you are going to be. 

We had a lot of back and forth on this topic, but to summarize, Mark agreed on detailed information being very useful for experts, but also pointed out that it takes years and years to become proficient enough to be able to digest very detailed documentation, and in the meanwhile, too much information is going to confuse, rather than clear things (especially for juniors coming from other database products). Just the current detail level is overwhelming, the current docs being composed of a staggering 21,000,000 words - and Oracle is in fact trying to organize the documentation in layers as much as possible, starting from high-level descriptions (the Two Day DBA course), than the Concept manual, and than the rest. The most details, however, will be still provided forever as Metalink (aka "My Oracle Support") notes, the only reason being to avoid confusing people, not to hide anything (besides strategic algorithms not covered by Patents of course). 

So in short, from this discussion I have understood that Oracle is willing to share information with its community; it only wants to find the right way to do so, since the community is huge (hundreds of thousands of people) and the product is very, very complex. Anyway, I have insisted for more information about the two topics that I'm sure that are not documented well enough, naming the "auto" features and  the CBO algorithms - and actually I feel like I have insisted perhaps too much on that with Mark ... but that's something I really care about, both for professional reasons and keen interest alone.

Well, I might add that information sharing, and community involvement as well, is in my opinion one of the main factors of Oracle's success; actually, being able to dig a lot into the inner workings of the product is the reason why I chose an Oracle career ten years ago.

PS I'm back from my vacation and I have a lot of interesting things to investigate at work that look like perfect candidates for being turned into posts, so I will be able to blog more frequently in the future. I also have a series of posts about the CBO that is "almost complete".]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>328</wp:post_id>
		<wp:post_date><![CDATA[2009-09-29 13:51:38]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-09-29 11:51:38]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[an-interview-with-mark-townsend]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[west@obviously.com]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>CBO: about the statistical definition of &quot;cardinality&quot; (densities part I)</title>
		<link>http://www.adellera.it/blog/2009/10/03/cbo-about-the-statistical-definition-of-cardinality-densities-part-i/</link>
		<pubDate>Sat, 03 Oct 2009 10:32:24 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=334</guid>
		<description></description>
		<content:encoded><![CDATA[Let's explore the concept of cardinality from the point of view of the statistician; this is both to get a clearer vision of the matter (i.e. for fun) and to path the way for understanding the rationale for the "density" statistics as calculated by dbms_stats (the topic of an upcoming post).

Let's consider a statement with input parameters (bind variables), and consider the most fundamental of them all, the one with a filter predicate:
[sql]
select ... 
  from t
 where x = :x;
[/sql]
the cardinality "card" of the set of rows retrieved depends on the table possible values and the actual inputs provided by the client as bind variable values. What about the <a href="http://en.wikipedia.org/wiki/Expected_value">expected value</a> E[card] ?
Let:
1) w(:x) ("w" stands for "workload") the <a href="http://en.wikipedia.org/wiki/Probability_mass_function">probability mass function</a> of the random variable :x (that completely characterizes the workload); 
2) E[count(:x)] the expected value of the cardinality of the rows retrieved for each value of :x.

We have, assuming that the two are independent:
[text]
E[card] = sum ( w(:x) * E[count(:x)] )
for all values of :x
[/text]

To solve the formula we have to know (or assume) the client-dictated w(:x). The same goes for the table <a href=" http://en.wikipedia.org/wiki/Statistical_population">potential population</a> (that -together with the statement of course- shapes E[count(:x)]); we must either have some statistical measurements about the table (for example, a frequency histogram on column X that we consider representative of the table population) or assume them (for example, assume a certain distribution for the column X values).

It is interesting to explore the most used scenario: a uniform (or assumed uniform) distribution for the column X values, of which we know the number of distinct values num_distinct(X) and the total number of values num_rows (let them be deterministically known for simplicity, and exclude null values). That means that E[count(:x)]) is equal to num_rows / num_distinct(X) <i>over a finite set that contains num_distinct(X) values</i> and is equal to zero over the remaining ones. 

It is relatively easy to see that E[card] depends on how w(:x) and E[count(:x)]) overlap. At one end of the spectrum, if the client always submits values for :x that are not contained in the table, E[card] is zero - since the client choice matematically translates into E[count(:x)]) being zero over all values of :x for which w(:x) is non zero. At the other end of the spectrum, that is, under the <a href="http://www.adellera.it/blog/2009/09/03/cbo-the-non-empty-result-set-assumption/">non empty result set assumption</a>, we have E[card] = sum ( w(:x) ) * num_rows / num_distinct(X) = num_rows / num_distinct(X), the usual formula used by the CBO in many (most) situations. 

The "density" column statistic formula can be derived in a similar way, but using a different assumption about w(:x) - as we will see in a dedicated post.

Other posts belonging to this series:
 <a href="http://www.adellera.it/blog/2009/10/10/cbo-the-formula-for-the-density-column-statistic-densities-part-ii/">densities part II</a>
 <a href="http://www.adellera.it/blog/2009/10/16/cbo-newdensity-replaces-density-in-11g-10204-densities-part-iii/">densities part III</a>
 <a href="http://www.adellera.it/blog/2009/10/23/cbo-newdensity-for-frequency-histograms11g-10204-densities-part-iv/">densities part IV</a>]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>334</wp:post_id>
		<wp:post_date><![CDATA[2009-10-03 12:32:24]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-10-03 10:32:24]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[cbo-about-the-statistical-definition-of-cardinality-densities-part-i]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="cbo"><![CDATA[CBO]]></category>
						<wp:comment>
			<wp:comment_id>89</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; CBO: the formula for the &#8220;density&#8221; column statistic (densities part II)]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2009/10/10/cbo-the-formula-for-the-density-column-statistic-densities-part-ii/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-10-10 15:56:07]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-10-10 13:56:07]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] we must reference the statistical concepts introduced in this post, and consider the family of all statements of our kind that can reference the [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>90</wp:comment_id>
			<wp:comment_author><![CDATA[Blogroll Report 09/10/2009-16/10/2009 &laquo; Coskan&#8217;s Approach to Oracle]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://coskan.wordpress.com/2009/10/21/blogroll-report-09102009-16102009/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[74.200.247.35]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-10-22 01:28:23]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-10-21 23:28:23]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] Alberto Dell&#8217;Era-CBO: about the statistical definition of “cardinality” (densities part I) [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>91</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; CBO: NewDensity for Frequency Histograms,11g-10.2.0.4 (densities part IV)]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2009/10/23/cbo-newdensity-for-frequency-histograms11g-10204-densities-part-iv/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-10-25 19:46:48]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-10-25 17:46:48]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] posts belonging to this series: densities part I densities part II densities part [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>70786</wp:comment_id>
			<wp:comment_author><![CDATA[Randell Strahan]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[strahan.randell@outlook.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[5.62.20.46]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2020-10-15 06:34:36]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2020-10-15 05:34:36]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Greetings, I was just visiting your site and submitted this message via your contact form. The feedback page on your site sends you messages like this via email which is the reason you are reading my message right now right? That's the most important achievement with any type of online ad, getting people to actually READ your advertisement and this is exactly what you're doing now! If you have an ad message you would like to promote to thousands of websites via their contact forms in the US or to any country worldwide let me know, I can even target specific niches and my charges are super reasonable. Write a reply here: lorenzodaniel9137@gmail.com]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1602740076.8909581;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>98451</wp:comment_id>
			<wp:comment_author><![CDATA[Elizbeth Walter]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[walter.elizbeth@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[184.75.209.43]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-01-25 05:50:43]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-01-25 04:50:43]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Did you know messages that come through on your website contact form are in fact a highly effective way to get more sales for your website? How can we do it? Easy, we put together an ad message like this one for your online business and we mass post it to thousands website contact pages on any website and in any business category or area you need. Do ads like these work well? Of course they do! You're reading this now aren't you? What's more, you can do this for less than $25 a week! Want to find out more? shoot us a quick email to: HansenAndyc65833@gmail.com]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1611550243.980387;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					</item>
					<item>
		<title>CBO: the formula for the &quot;density&quot; column statistic (densities part II)</title>
		<link>http://www.adellera.it/blog/2009/10/10/cbo-the-formula-for-the-density-column-statistic-densities-part-ii/</link>
		<pubDate>Sat, 10 Oct 2009 13:56:03 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=339</guid>
		<description></description>
		<content:encoded><![CDATA[In this post we are going to explore and explain the rationale for the formula used by dbms_stats to compute the "density" column statistic, used by the CBO in versions less than 10.2.0.4 to estimate the cardinality of a class of SQL statements. In the next post, we will speak about its replacement, named "NewDensity" in 10053 trace files.

We will consider only the non-trivial case of Height-Balanced histograms, since for Frequency Histograms density is a constant (0.5 / num_rows) and for columns without histogram, it is simply 1/num_distinct.

Let's illustrate the test case on which we will base our discussion, contained in <a href="http://34.247.94.223/wp-content/uploads/2009/10/density_post.zip">this zip</a> file. 

First, a table T is created with the following exponential value distribution:
[text]
SQL> select value, count(*)
  2    from t
  3   group by value
  4   order by value;

     VALUE   COUNT(*)
---------- ----------
         1          1
         2          2
         4          4
         8          8
        16         16
        64         64
[/text]
The test case then computes a SIZE 5 Height-Balanced histogram. The resulting histogram (from dba_histograms) is as follows (note that I have added the column POPULARITY that marks popular values with "1"; EP is shorthand for column ENDPOINT_NUMBER, VALUE for column ENDPOINT_VALUE):
[text]
SQL> select ep, value, popularity from formatted_hist;

        EP      VALUE POPULARITY
---------- ---------- ----------
         0          1          0
         1         16          0
         5         64          1
[/text]
The test case then issues this SQL statement that contains only an equality filter predicate on table T:
[sql]
select ... 
  from t
 where value = 2.4;
[/sql]
The literal value 2.4 is not contained in the table (and hence in the histogram), in order to make the CBO factor in "density" in its estimate of the expected cardinality - in fact, as it might be known, density is used when the literal is not popular (that is, not equal to 64 in our case), and it doesn't matter whether the literal is not contained in the histogram, or contained as an unpopular value (1 and 16 in our case), or even contained in the table or not. All it takes is its being not popular.
Side note: I'm assuming the literal is inside the closed min-max interval (1-64 in this case); when outside, it depends on the version.

When the literal is not popular, the formula used for the expected cardinality calculation is equal to 
[text]
E[card] = density * num_rows;
[/text]
That is easy to verify from the test case logs; in 9i we can see that density = 0.115789474 and num_rows=95, hence 0.115789474 * 95 = 11.000000000 which is exactly equal to the CBO estimate for our statement. 

The formula used by dbms_stats to compute "density" was published in Jonathan Lewis' book <a href="http://www.jlcomp.demon.co.uk/cbo_book/ind_book.html">Cost Based Oracle</a> (page 172) and Wolfgang Breitling's presentation <a href="http://www.centrexcc.com/">Histograms - Myths and Facts</a>. The key fact is that the formula takes as input the rows of what I've nicknamed the not-popular subtable (NPS), that is, the original table without the rows whose values are popular values (in this case, 64 is the only popular value). Letting num_rows_nps the number of rows of the NPS (for our example, num_rows_nps=1+2+4+8+16=31), we have:
[text]
   density = (1 / num_rows) *
   sum (count (value) ^ 2) / num_rows_nps 
   for  "value" belonging to the NPS
[/text]
The script performs this calculation automatically; it is anyway instructive to perform the calculation manually at least one time:
density = (1/95) * (1*1+2*2+4*4+8*8+16*16) / 31 = .115789474
that matches perfectly the density we observed in the script log before.

What is the statistical rationale for this seemingly strange computation? 

If we plug it inside the formula for E[card], we can see that num_rows is cancelled:
[text]
E[card] = sum (count (value) ^ 2) / num_rows_nps
summed over all "values" belonging to the NPS
[/text]

Now we must reference the statistical concepts introduced in <a href="http://www.adellera.it/blog/2009/10/03/cbo-about-the-statistical-definition-of-cardinality-densities-part-i/">this post</a>, and consider the family of all statements of our kind that can reference the NPS:
[sql]
select ... 
  from t
 where x = :x;
:x being a value belonging to the NPS
[/sql]
its E[card] is
[text]
E[card] = sum ( w(:x) * E[count(:x)] )
for all values of :x (belonging to the NPS)
[/text]
dbms_stats takes count(:x) as the best estimate for E[count(:x)] (for example, E[count(4)] = count(4) = 4 in our case). All we have to do in order to obtain the observed formula, is to assume w(:x) = count(:x) / num_rows_nps:
[text]
E[card] = sum ( (count(:x) / num_rows_nps) * count(:x) ) 
        = sum ( count(:x) ^ 2 ) / num_rows_nps
for all values of :x (belonging to the NPS)
[/text]

The meaning of the above particular shape of w(:x) is that the probability that the client submits a certain value for :x is proportional to the number of rows (in the NPS) that has that value; more precisely, that if X% of rows has a certain common value, X% of user-submitted statements that "hit" the NPS will ask for that value. Under this assumption, dbms_stats precomputes "density" to give back the above E[card] when the literal is known to be not popular, hence hitting the NPS - remember that the CBO operates under the "<a href="http://www.adellera.it/blog/2009/09/03/cbo-the-non-empty-result-set-assumption/">non-empty result set assumption</a>", hence if the literal does not hit a popular value, it must hit a value of the NPS.

The above assumption for w(:x) is quite a strange assumption - and in fact, we will see in the next post that in 11g (and 10.2.0.4), this assumption has been dropped and replaced with a more standard one. The "density" column statistics is in fact <i>ignored</i> in 10.2.0.4+ and a value computed at run-time, named "newDensity" in 10053 trace files, is used instead.

Other posts belonging to this series:
 <a href="http://www.adellera.it/blog/2009/10/03/cbo-about-the-statistical-definition-of-cardinality-densities-part-i/">densities part I</a>
 <a href="http://www.adellera.it/blog/2009/10/16/cbo-newdensity-replaces-density-in-11g-10204-densities-part-iii/">densities part III</a>
 <a href="http://www.adellera.it/blog/2009/10/23/cbo-newdensity-for-frequency-histograms11g-10204-densities-part-iv/">densities part IV</a>]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>339</wp:post_id>
		<wp:post_date><![CDATA[2009-10-10 15:56:03]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-10-10 13:56:03]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[cbo-the-formula-for-the-density-column-statistic-densities-part-ii]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="cbo"><![CDATA[CBO]]></category>
						<wp:comment>
			<wp:comment_id>92</wp:comment_id>
			<wp:comment_author><![CDATA[Rudy]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[hillrudy@email.it]]></wp:comment_author_email>
			<wp:comment_author_url>http://rdbland.blogspot.com/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.101.98.2]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-10-13 10:01:27]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-10-13 08:01:27]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[I checked Lewis' book, but he doesn't explain how he worked out the density formula - he will publish it in the upcoming book, so we have to wait (how long?!?).

Your explanation about w(:x) is very interesting, although the post is hard for me to read with your notation. I must say it's convincing, why is it strange for you?

No doubt it's an easy task for dbms_stats to compute the estimated value for count(:x), or E[count(:x)]... it's count(:x) indeed, no need to estimate :-)))]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>93</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-10-13 10:42:16]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-10-13 08:42:16]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@rudy

In Lewis' book the formula was introduced using words instead of math symbols but still understandable; Wolfgang uses a more formal mathematical definition. 

What I think is "strange" is the assumption about the shape of w(:x); why a customer that has ordered 100 books should ask about the order book list 100 times as frequently as another customer that has ordered only 1 book ? 11g (and 10.2.0.4) corrects this with "NewDensity", as we will see in the next post.

About E[count(:x)] = "observed count": that is not true in general, since one might use a statistical model that infer E[count(:x)] from the observed count, for example taking into account the way the table is modified over time (e.g: that an insert_date column is constantly increasing its max value). That would be, of course, very complicated in practice, but statistically sound and possible.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>92</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>94</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; CBO: &#8220;NewDensity&#8221; replaces &#8220;density&#8221; in 11g, 10.2.0.4 (densities part III)]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2009/10/16/cbo-newdensity-replaces-density-in-11g-10204-densities-part-iii/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-10-16 22:33:50]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-10-16 20:33:50]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] a previous post, we already discussed the pre-10.2.0.4 scenario: we saw how and when the "density" column statistic [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>95</wp:comment_id>
			<wp:comment_author><![CDATA[Blogroll Report 09/10/2009-16/10/2009 &laquo; Coskan&#8217;s Approach to Oracle]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://coskan.wordpress.com/2009/10/21/blogroll-report-18/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[76.74.254.71]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-10-22 01:29:00]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-10-21 23:29:00]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] Alberto Dell&#8217;Era-CBO: the formula for the “density” column statistic (densities part II) [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>96</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; CBO: about the statistical definition of &#8220;cardinality&#8221; (densities part I)]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2009/10/03/cbo-about-the-statistical-definition-of-cardinality-densities-part-i/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-10-25 19:44:32]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-10-25 17:44:32]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] posts belonging to this series: densities part II densities part III densities part [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>97</wp:comment_id>
			<wp:comment_author><![CDATA[density estimate]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://starttags.com/tags/density-estimate</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[98.240.245.202]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-04-02 21:07:40]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-04-02 19:07:40]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] bone reduces resulting in osteoporosis with porous bone fragility and high risk of bone fracture,Alberto Dell'Era's Oracle blog CBO: the formula for the ...In this post we are going to explore and explain the rationale for the formula used by dbms_stats to [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>CBO: &quot;NewDensity&quot; replaces &quot;density&quot; in 11g, 10.2.0.4 (densities part III)</title>
		<link>http://www.adellera.it/blog/2009/10/16/cbo-newdensity-replaces-density-in-11g-10204-densities-part-iii/</link>
		<pubDate>Fri, 16 Oct 2009 20:33:46 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=345</guid>
		<description></description>
		<content:encoded><![CDATA[In this post we are going to explore and explain the rationale for the formula used by the CBO to compute the "NewDensity" figure that replaces, from 10.2.0.4 onwards, the "density" column statistic in the cardinality estimation formulae for columns with height-balanced (HB) histograms defined.

In a <a href="http://www.adellera.it/blog/2009/10/10/cbo-the-formula-for-the-density-column-statistic-densities-part-ii/">previous post</a>, we already discussed the pre-10.2.0.4 scenario: we saw how and when the "density" column statistic is used in the cardinality formula for equality filter predicates, we explained its statistical rationale and defining formula, introduced the concept of the NPS (Not Popular Subtable), and built a test case. Now we are going to use the very same test case and explain the differences in the most recent versions (the previous post zip file contains logs for them also).

To summarize the test case - we have a table T with a single column VALUE, exponentially distributed, and with a SIZE 5 Height-Balanced histogram collected on. The histogram is:
[text]
SQL> select ep, value, popularity from formatted_hist;

        EP      VALUE POPULARITY
---------- ---------- ----------
         0          1          0
         1         16          0
         5         64          1
[/text]
Thus, we have a single popular value, 64; all the others are unpopular.

In this "densities" series of post, we focus on a SQL statement that contains only an equality filter predicate on table T:
 [sql]
select ... 
  from t
 where value = 2.4;
[/sql]
the literal value is not a popular value (but inside the 1-64 interval) and hence, in pre-10.2.0.4, the formula used for the expected cardinality calculation is equal to: 
[text]
E[card] = density * num_rows; 
[/text]
We discussed, in the previous post, how density is carefully calculated by dbms_stats to get back the expected cardinality of the family (class) of all possible equality filter predicate statements that hit the NPS, under the usual "<a href="http://www.adellera.it/blog/2009/09/03/cbo-the-non-empty-result-set-assumption/">non-empty result set assumption</a>" and the further (strange and strong) assumption that the more a value is represented in the NPS, the higher the probability that the value is used as the literal of the equality predicate (an assumption that mathematically translates into the formula "w(:x) = count(:x) / num_rows_nps"). 

Switching to 10.2.0.4 - the formula for E[card] is still the same, but with "density" replaced by "NewDensity" (as hinted by the fact that "density" is reported as "OldDensity" in the 10053 trace files, as we are going to see in a moment):
[text]
E[card] = NewDensity * num_rows; 
[/text]

NewDensity is not stored anywhere in the data dictionary, but it is computed at query optimization time by the CBO (note that density is still computed by dbms_stats using the old formula, but then it is ignored by the CBO). The NewDensity formula is based mainly on some histogram-derived figures; using the same names found in 10053 traces:
 
[text]
NewDensity = [(BktCnt - PopBktCnt) / BktCnt] / (NDV - PopValCnt)
[/text]
Where BktCnt ("Bucket Count") is the number of buckets (the "N" in the "SIZE N" clause);
PopBktCnt ("Popular Bucket Count") the number of buckets <i>covered</i> by the popular values;
PopValCnt ("Popular Value Count") is the number of popular values; NDV ("Number of Distinct Values") is the traditional name used by CBO developers for the num_distinct column statistic. With the exception of NDV, all these values are derived from the histogram.

Side note: if the numerator is equal to zero, NewDensity is set to 0.5 / num_rows, thus giving an E[card] = 0.5, as far as I have seen (not exaustively) in a few test cases; it looks like a lower-bound "sanity check". The denominator cannot be zero for HB histograms.

To illustrate the formula: the histogram of our test case has 5 buckets, hence BktCnt=5; 64 is the only popular value, hence PopValCnt =1; this popular value covers 4 buckets (since its EP is 5 and the previous EP is 1), hence PopBktCnt=4; we know that the column has num_distinct=6, hence NDV=6. This is in fact what we see in the 10053 trace file (in 11.1.0.7 and 11.2.0.1):

[text]
SINGLE TABLE ACCESS PATH 
  Single Table Cardinality Estimation for T[T] 
  Column (#1): 
    NewDensity:0.040000, OldDensity:0.115789 BktCnt:5, PopBktCnt:4, PopValCnt:1, NDV:6
  Using density: 0.040000 of col #1 as selectivity of unpopular value pred
  Table: T  Alias: T
    Card: Original: 95.000000  Rounded: 4  Computed: 3.80  Non Adjusted: 3.80
[/text]
So NewDensity = [(5-4)/5] / (6-1) = 1/25 = 0.04 and E[card]=0.04*95=3.8, which is exactly what we see in the above trace fragment.

The formula is statistically based on replacing the previous versions' assumption (that we labeled "strange and strong") about w(:x) with the standard assumption that the client will ask for the values in the NPS with the same probability; mathematically, that means replacing the formula "w(:x) = count(:x) / num_rows_nps" with the standard "w(:x) = 1 / num_distinct_nps" (where num_distinct_nps is of course the number of distinct values of the NPS). If you plug this shape of w(:x)  into the formula for E[card], you get
[text]
E[card] = sum ( w(:x) * E[count(:x)] ) =  
        = sum (E[count(:x)] ) / num_distinct_nps 
for all values of :x (belonging to the NPS)
[/text]
that is 
[text]
E[card] = num_rows_nps / num_distinct_nps
[/text]
which is, not surprising, the standard formula used for columns without histograms, but applied to the NPS, not the whole table. 

One possibility for producing the above E[card] value at run-time could have been to change dbms_stats to compute a value for "density" equal to (num_rows_nps / num_distinct_nps) / num_rows; but forcing users to recompute statistics for all their tables in their upgraded databases is not really a viable option. Hence, the CBO designers chose to simply ignore "density" and calculate the above formula at run-time, mining the histogram, at the cost of reduced precision. In fact, the easy part is num_distinct_nps, which is obviously exactly equal to num_distinct minus the number of popular values; but num_rows_nps can only calculated approximately, since the histogram is a (deterministic) sample of the column values obtained by first sorting the column values and then sampling on a uniform grid (for more information and illustration, see the first part of <a href="http://www.adellera.it/investigations/join_over_histograms/JoinCardinalityEstimationWithHistogramsExplained.pdf">this article of mine</a>). Using the histogram, the best approximation for num_rows_nps is num_rows times the fraction of buckets not covered by popular values. Hence, using the 10053 terminology
[text]
num_distinct_nps = NDV - PopValCnt (exactly)

num_rows_nps = [(BktCnt - PopBktCnt) / BktCnt] * num_rows (approximately)
[/text]
which gets back (again, approximately) the E[card] formula above, as can be trivially checked.

It might be desirable that one day, NewDensity gets calculated exactly by dbms_stats and stored in the data dictionary, at least for columns with new statistics, albeit the precision reduction is probably more than acceptable (that is, I have never seen a case where that has been an issue). The test case script, just for the sake of completeness, calculates the exact figure as well; it gets back an E[card] of 6.2 instead of 3.8. 

For a summary of the above discussion and some more discussion, check back <a href="http://www.adellera.it/investigations/11g_newdensity/index.html">this investigation</a> of mine. By the way, NewDensity replaces "density" also in join cardinality formulae, even if I have not run a complete investigation - but that is not surprising at all.

As a final nore - NewDensity is used also for Frequency Histograms, and in a very creative way; we will discuss this in part IV of this series.

Other posts belonging to this series:
 <a href="http://www.adellera.it/blog/2009/10/03/cbo-about-the-statistical-definition-of-cardinality-densities-part-i/">densities part I</a>
 <a href="http://www.adellera.it/blog/2009/10/10/cbo-the-formula-for-the-density-column-statistic-densities-part-ii/">densities part II</a>
 <a href="http://www.adellera.it/blog/2009/10/23/cbo-newdensity-for-frequency-histograms11g-10204-densities-part-iv/">densities part IV</a>]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>345</wp:post_id>
		<wp:post_date><![CDATA[2009-10-16 22:33:46]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-10-16 20:33:46]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[cbo-newdensity-replaces-density-in-11g-10204-densities-part-iii]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="cbo"><![CDATA[CBO]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[bus@myself.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[angele@live.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[robertoneill@hotmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>98</wp:comment_id>
			<wp:comment_author><![CDATA[Blogroll Report 09/10/2009-16/10/2009 &laquo; Coskan&#8217;s Approach to Oracle]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://coskan.wordpress.com/2009/10/21/blogroll-report-18/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[76.74.254.71]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-10-22 01:29:59]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-10-21 23:29:59]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] Alberto Dell&#8217;Era-CBO: “NewDensity” replaces “density” in 11g, 10.2.0.4 (densities part III) [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>99</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; CBO: the formula for the &#8220;density&#8221; column statistic (densities part II)]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2009/10/10/cbo-the-formula-for-the-density-column-statistic-densities-part-ii/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-11-22 17:57:50]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-11-22 15:57:50]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] posts belonging to this series: densities part I densities part III densities part [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>100</wp:comment_id>
			<wp:comment_author><![CDATA[Ung]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[ungkokaik@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[60.50.190.6]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-12-16 11:30:40]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-12-16 09:30:40]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Thanks for these excellent article. 

I've just tested out in 10.2.0.4 but couldn't find the NewDensity, just wondering if this is only happened to windows?

Rgds
Ung]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>101</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[93.33.129.215]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-12-16 13:05:50]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-12-16 11:05:50]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@Ung

it shouldn't be an operating-system dependent feature in theory ... may you run one of the script of my test case that generates the 10053 trace on your system and send the trace/log to alberto.dellera@gmail.com ? Thanks]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>100</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>102</wp:comment_id>
			<wp:comment_author><![CDATA[TomPier]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[asdfesaf@sadf.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[173.233.65.154]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-05-04 10:07:00]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-05-04 08:07:00]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[great post as usual!]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>103</wp:comment_id>
			<wp:comment_author><![CDATA[Elena]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[elena.luccone@web.de]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[139.2.4.131]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-08-08 08:32:38]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-08-08 06:32:38]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hello Alberto,

we are running Oracle RDBMS 11.2.0.4 on Solaris 64bit.
We have a very simple slow query in production, Oracle does not take the existing index because of wrong histograms. It looks like bug 18377553 or bug 10174050, because we have 500 million values in a column, frequency histograms, but just one bucket.
Anyway, investigating the issue I had to look at the 10053 trace and also found your article about NewDensity calculation.
It is an old post, but may be, you are still interested on this.
For me it looks like NewDensity is just set to 0.5 and not to NewDensity 0.5 / num_rows. My be it is a change in 11.2.0.4 or a part of the bug or… I am wrong ;-).
From the 10053 trace:
Single Table Cardinality Estimation for TBL_...
  Column (#2): 
    NewDensity:0.500000, OldDensity:0.000000 BktCnt:517289083, PopBktCnt:517289083, PopValCnt:1, NDV:507249889
  Column (#2): F…(
    AvgLen: 96 NDV: 507249889 Nulls: 0 Density: 0.500000
    Histogram: Freq  #Bkts: 1  UncompBkts: 517289083  EndPtVals: 1
  Using density: 0.500000 of col #2 as selectivity of unpopular value pred

(517289083 is number of rows in the table)

Best regards
Elena]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>104</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[93.33.129.250]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-08-24 11:51:12]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-08-24 09:51:12]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Elena,

how could it be a Frequency Histogram, since NDV is definitely much greater than the max value you can specify for SIZE (i.e. 254) ?
It looks like the CBO is wrongly classifying the histogram.

Check the "Card:" line just below in the 10053 trace, and check whether it is equal to either 0.5 or 0.5 * num_rows.

Anyway, as stated in the post, I observed that the rule "NewDensity = 0.5 / num_rows" is generally observed, but I cannot be sure that is observed "always" ;) - albeit this rule seems very sound from a statistical perspective.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>103</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>investigations</title>
		<link>http://www.adellera.it/archived/investigations/</link>
		<pubDate>Sun, 06 May 2018 15:25:47 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/?page_id=917</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>917</wp:post_id>
		<wp:post_date><![CDATA[2018-05-06 16:25:47]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2018-05-06 15:25:47]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[closed]]></wp:comment_status>
		<wp:ping_status><![CDATA[closed]]></wp:ping_status>
		<wp:post_name><![CDATA[investigations]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>914</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[page]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
														<wp:postmeta>
		<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
		<wp:meta_value><![CDATA[2]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_portfolio_layout]]></wp:meta_key>
		<wp:meta_value><![CDATA[2col]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_masonry]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_sidebar]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_text]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_portfolio_filter_status]]></wp:meta_key>
		<wp:meta_value><![CDATA[show]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_gap]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_blogpage_layout]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_pagesidebar_layout]]></wp:meta_key>
		<wp:meta_value><![CDATA[right]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_sidebar_one]]></wp:meta_key>
		<wp:meta_value><![CDATA[sidebar-1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_sidebar_two]]></wp:meta_key>
		<wp:meta_value><![CDATA[sidebar-1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_title_bar]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_title_text]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_breadcrumb]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_breadcrumb_char]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>personal</title>
		<link>http://www.adellera.it/archived/personal/</link>
		<pubDate>Sun, 06 May 2018 15:37:59 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/?page_id=925</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>925</wp:post_id>
		<wp:post_date><![CDATA[2018-05-06 16:37:59]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2018-05-06 15:37:59]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[closed]]></wp:comment_status>
		<wp:ping_status><![CDATA[closed]]></wp:ping_status>
		<wp:post_name><![CDATA[personal]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>914</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[page]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
														<wp:postmeta>
		<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
		<wp:meta_value><![CDATA[2]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_portfolio_layout]]></wp:meta_key>
		<wp:meta_value><![CDATA[2col]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_masonry]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_sidebar]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_text]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_portfolio_filter_status]]></wp:meta_key>
		<wp:meta_value><![CDATA[show]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_gap]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_blogpage_layout]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_pagesidebar_layout]]></wp:meta_key>
		<wp:meta_value><![CDATA[right]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_sidebar_one]]></wp:meta_key>
		<wp:meta_value><![CDATA[sidebar-1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_sidebar_two]]></wp:meta_key>
		<wp:meta_value><![CDATA[sidebar-1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_title_bar]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_title_text]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_breadcrumb]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_breadcrumb_char]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>scripts</title>
		<link>http://www.adellera.it/archived/scripts/</link>
		<pubDate>Sun, 06 May 2018 15:38:50 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/?page_id=927</guid>
		<description></description>
		<content:encoded><![CDATA[]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>927</wp:post_id>
		<wp:post_date><![CDATA[2018-05-06 16:38:50]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2018-05-06 15:38:50]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[closed]]></wp:comment_status>
		<wp:ping_status><![CDATA[closed]]></wp:ping_status>
		<wp:post_name><![CDATA[scripts]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>914</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[page]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
														<wp:postmeta>
		<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
		<wp:meta_value><![CDATA[2]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_portfolio_layout]]></wp:meta_key>
		<wp:meta_value><![CDATA[2col]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_masonry]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_sidebar]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_text]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_portfolio_filter_status]]></wp:meta_key>
		<wp:meta_value><![CDATA[show]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_gap]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_blogpage_layout]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_pagesidebar_layout]]></wp:meta_key>
		<wp:meta_value><![CDATA[right]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_sidebar_one]]></wp:meta_key>
		<wp:meta_value><![CDATA[sidebar-1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_sidebar_two]]></wp:meta_key>
		<wp:meta_value><![CDATA[sidebar-1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_title_bar]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_title_text]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_breadcrumb]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_breadcrumb_char]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>Cookie and Privacy (GDPR-like) Policy</title>
		<link>http://www.adellera.it/cookie-and-privacy-gdpr-policy/</link>
		<pubDate>Sat, 26 May 2018 09:23:35 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/?page_id=961</guid>
		<description></description>
		<content:encoded><![CDATA[<strong>Cookie and Privacy (GDPR-like) Policy</strong>

This site is strictly personal and not linked to any business organization, hence I'm not legally bounded to the GDPR regulation.

Anyway, I adhere to the spirit of GDPR, hence:
<ul>
 	<li>I do not sell or communicate any personal data to anyone, except Google Analytics (see below)</li>
 	<li>the only personal data I collect are the ones that the user may wish to communicate in comments (name, email, website), plus the IP address that is collected automatically</li>
 	<li>the software (Wordpress and its plugins) are always kept up-to-date to prevent data breaches as much as possible</li>
</ul>
If you want your data to be removed, or have any question, just drop me an email to alberto.dellera@gmail.com

<strong>Google Analytics:</strong>
<ul>
 	<li>Google Analytics gets only the IP, I do not send any additional "personal" infos about users</li>
 	<li>I do not even use the "Advertising" features - I actually use Analytics just out of curiosity sometimes, to see aggregated data (country, language) about my readers</li>
</ul>
<strong>Cookies Specific:</strong>

This site uses cookies - small text files that are placed on your machine to help the site provide a better user experience. In general, cookies are used to retain user preferences, store information for things like shopping carts, and provide anonymised tracking data to third party applications like Google Analytics. As a rule, cookies will make your browsing experience better. However, you may prefer to disable cookies on this site and on others. The most effective way to do this is to disable cookies in your browser. We suggest consulting the Help section of your browser or taking a look at <a href="http://www.aboutcookies.org">the About Cookies website</a> which offers guidance for all modern browsers]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>961</wp:post_id>
		<wp:post_date><![CDATA[2018-05-26 10:23:35]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2018-05-26 09:23:35]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[closed]]></wp:comment_status>
		<wp:ping_status><![CDATA[closed]]></wp:ping_status>
		<wp:post_name><![CDATA[cookie-and-privacy-gdpr-policy]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>80</wp:menu_order>
		<wp:post_type><![CDATA[page]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
														<wp:postmeta>
		<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
		<wp:meta_value><![CDATA[2]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_portfolio_layout]]></wp:meta_key>
		<wp:meta_value><![CDATA[2col]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_masonry]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_sidebar]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_text]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_portfolio_filter_status]]></wp:meta_key>
		<wp:meta_value><![CDATA[show]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_portfolio_gap]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_blogpage_layout]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_pagesidebar_layout]]></wp:meta_key>
		<wp:meta_value><![CDATA[right]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_sidebar_one]]></wp:meta_key>
		<wp:meta_value><![CDATA[sidebar-1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_sidebar_two]]></wp:meta_key>
		<wp:meta_value><![CDATA[sidebar-1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_title_bar]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_title_text]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_breadcrumb]]></wp:meta_key>
		<wp:meta_value><![CDATA[0]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_gx_page_breadcrumb_char]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>CBO: NewDensity for Frequency Histograms,11g-10.2.0.4 (densities part IV)</title>
		<link>http://www.adellera.it/blog/2009/10/23/cbo-newdensity-for-frequency-histograms11g-10204-densities-part-iv/</link>
		<pubDate>Fri, 23 Oct 2009 16:07:04 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=352</guid>
		<description></description>
		<content:encoded><![CDATA[As we have seen in the previous posts of this series, in 11g a new figure named "NewDensity" has been introduced as a replacement for the "density" column statistic for columns whose histogram has been collected; this change has been backported in 10.2.0.4 also. 

In the previous post we discussed how NewDensity influences the CBO cardinality estimate for Height-Balanced histograms; in this one we are going to investigate the same for Frequency Histograms. We will see that the most important change is the introduction of the “half the least popular" rule (see the "<a href="http://jonathanlewis.wordpress.com/2009/04/23/histogram-change">Histogram change</a>" post by Jonathan Lewis, which distills the findings of <a href="http://oracle-randolf.blogspot.com/2009/01/correlation-nocorrelation-and-extended.html">Randolf Geist</a> and <a href=" http://orainternals.wordpress.com/2008/12/19/correlation-nocorrelation-and-extended-stats/ "> Riyaj Shamsudeen</a>) - a surprising rule that might easily cause trouble (in fact as Jonathan reports in the comments - bug 6082745 was opened against this rule).

The <a href="http://34.247.94.223/wp-content/uploads/2009/10/density_post_freq.zip">test case</a> (script density_post_freq.sql) considers the same test statement we focused on in the previous post (a single equality filter predicate which asks for a value inside the min-max range of the column):
[sql]
select ... 
  from t
 where value = 64.5;
[/sql]

Of course we compute a Frequency instead of an Height-Balanced histogram, and use a slightly different value distribution in order to highlight the new rule:
[sql]
SQL> select value, count(*)
  2    from t
  3   group by value
  4   order by value;

     VALUE   COUNT(*)
---------- ----------
         8          8
        16         16
        64         64
       128        128
[/sql]

The histogram generated by the test case is (from DBA_HISTOGRAMS): 
[text]
     VALUE         EP        BKT
---------- ---------- ----------
         8          8          8
        16         24         16
        64         88         64
       128        216        128
[/text]
VALUE is an abbreviation for ENDPOINT_VALUE, EP for ENDPOINT_NUMBER. 
BKT is the number of buckets covered by the value (i.e.: EP minus the previous EP), that is, the number of rows whose column value was equal to VALUE at statistics collection time. 

When the filter predicate selects a value contained in the histogram, the new releases behave the same as the old ones (but check the "bottom note about singleton values" at the bottom for a a minor but interesting detail): neither density nor NewDensity is used, and the cardinality estimate is the usual intuitive one. In the complementary case of a value not contained in the histogram (but still inside the min-max interval), the cardinality used to be calculated as density*num_rows and it is now NewDensity*num_rows. Note the simmetry with the Height-Balanced case: the formula is the same, with NewDensity simply replacing density.

<b>NewDensity with the “half the least popular" rule active</b>

By default the rule is active, and in this case, NewDensity is set to 
[text]
NewDensity = 0.5 * bkt(least_popular_value) / num_rows
[/text]
and hence, for non-existent values:
[text]
E[card] = (0.5 * bkt(least_popular_value) / num_rows) * num_rows 
        =  0.5 * bkt(least_popular_value)
[/text]
For our test case, the least_popular_value is 8 and bkt(8) = 8, hence E[card] = 0.5 * 8 = 4 thanks to  NewDensity being equal to 0.5 * 8 / 216 = 0.018518519. In fact, we can verify in the 10053 traces (in 10.2.0.4, 11.1.0.7, 11.2.0.1) for our statement, that asks for a not-existent value (64.5), that E[card] and NewDensity are set as above:
[text]
    NewDensity:0.018519, OldDensity:0.002315 BktCnt:216, PopBktCnt:216, PopValCnt:4, NDV:4
  Using density: 0.018519 of col #1 as selectivity of unpopular value pred
  Table: T  Alias: NOT_EXISTENT
    Card: Original: 216.000000  Rounded: 4  Computed: 4.00  Non Adjusted: 4.00
[/text]

As another check, let's see what happens if bkt(least_popular_value) = 1, that is, if there is (at least) one value that occurred exactly one time (a singleton value) at statistics collection time. Adding such a row to our test case is trivial (just uncomment the first insert row in the script); in this scenario, our formula above predicts E[card] = 0.5 with NewDensity = 0.5 / 217 = .002304147, and in fact (check the *_least_is_one.trc traces):

[text]
    NewDensity:0.002304, OldDensity:0.002304 BktCnt:217, PopBktCnt:216, PopValCnt:4, NDV:5
  Using density: 0.002304 of col #1 as selectivity of unpopular value pred
  Table: T  Alias: NOT_EXISTENT
    Card: Original: 217.000000  Rounded: 1  Computed: 0.50  Non Adjusted: 0.50
[/text]
note that E[card] gets rounded up from 0.5 to 1 (as usual).

What is the rationale behind this rule? Thanks to Randolf Geist (see the comment in Jonathan's blog entry above), we know that it was introduced as a patch to solve one particular scenario (see bug 5483301) and then included in the main release, for some reason. Luckily, the rule can be disabled and the old sane behaviour can be restored.

<b>NewDensity with the “half the least popular" rule disabled</b>

To disable the new rule, just switch off the patch 5483301:
alter session set "_fix_control"='5483301:off';
(or alter system if you want to make it permanent)

with this setting, NewDensity becomes simply
[text]
NewDensity = 0.5 / num_rows
[/text]
and hence, again for non-existent values:
[text]
E[card] = 0.5
[/text]
which is exactly what we got in pre-10.2.0.4, where density was used (and density was, and is still, set to 0.5 / num_rows by dbms_stats).  So the cardinality estimate is 0.5 (rounded up to 1).

For our test case, we predict NewDensity = 0.5 / 216 = 0.002314815. In fact our 10053 traces tell us:
[text]
  NewDensity:0.002315, OldDensity:0.002315 BktCnt:216, PopBktCnt:216, PopValCnt:4, NDV:4
  Table: T  Alias: NOT_EXISTENT_OFF
    Card: Original: 216.000000  Rounded: 1  Computed: 0.50  Non Adjusted: 0.50
[/text]

The rationale for this behaviour is sound; the CBO knows that no row with the requested value existed at statistics collection time, hence it returns the minimal cardinality estimate compatible with the <a href="http://www.adellera.it/blog/2009/09/03/cbo-the-non-empty-result-set-assumption/">non empty result set assumption</a> (check this post for the importance of this assumption). If the statistics are reasonably fresh, this is the only sane estimate that can be made.

<b>Playing with density - a warning</b>

If you set your own column stats using dbms_stats.set_column_stats, the behaviour is different; I haven't made any extensive investigations but as far as I can tell, the value you provide for density is used instead of NewDensity. User-provided column statistics are flagged with dba_tab_cols.user_stats = 'YES'. You can disguise your user statistics as non-user by setting the flags parameter of dbms_stats.set_column_stats to 2 - but since the latter parameter is labeled as "for Oracle internal use only", I would do it only for investigations purposes - that is, never in production.

---
<i>Bottom note about singleton values</i>: actually in pre-10.2.0.4 versions, if the value was present in the Frequency histogram but covering a single bucket (hence it was present in the table exactly one time at statistic collection time), it used to be classified as "unpopular" and hence used to get the same treatment as a value not in the histogram - the end result being that the cardinality was estimated as 0.5 rounded up to 1; now it is 1 before rounding as one would intuitively expects. I hope to be able to investigate whether this change fixes the issues about join cardinality estimation I investigated - see "the mystery of halving" in <a href="http://www.adellera.it/investigations/join_over_histograms/JoinOverHistograms.pdf">this investigation</a> of mine if interested.

Other posts belonging to this series:
 <a href="http://www.adellera.it/blog/2009/10/03/cbo-about-the-statistical-definition-of-cardinality-densities-part-i/">densities part I</a>
 <a href="http://www.adellera.it/blog/2009/10/10/cbo-the-formula-for-the-density-column-statistic-densities-part-ii/">densities part II</a>
 <a href="http://www.adellera.it/blog/2009/10/16/cbo-newdensity-replaces-density-in-11g-10204-densities-part-iii/">densities part III</a>]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>352</wp:post_id>
		<wp:post_date><![CDATA[2009-10-23 18:07:04]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-10-23 16:07:04]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[cbo-newdensity-for-frequency-histograms11g-10204-densities-part-iv]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="cbo"><![CDATA[CBO]]></category>
						<wp:comment>
			<wp:comment_id>105</wp:comment_id>
			<wp:comment_author><![CDATA[Blogroll Report 16/10/2009-23/10/2009 &laquo; Coskan&#8217;s Approach to Oracle]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://coskan.wordpress.com/2009/10/26/blogroll-report-19/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[74.200.245.190]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-11-03 14:48:46]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-11-03 12:48:46]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] Alberto Dell&#8217;Era-CBO: NewDensity for Frequency Histograms,11g-10.2.0.4 (densities part IV) [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>106</wp:comment_id>
			<wp:comment_author><![CDATA[Randolf Geist]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[info@sqltools-plusplus.org]]></wp:comment_author_email>
			<wp:comment_author_url>http://oracle-randolf.blogspot.com/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[87.178.69.207]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-12-03 16:38:58]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-12-03 14:38:58]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Alberto,

regarding your comment "Playing with density": I've suggested in a recent discussion to refer to your excellent blog series on Oracle-l (and try to set the density manually to get the "old" density behaviour back) - yesterday Wolfgang Breitling mentioned when we met at the UKOUG that manually setting the density actually removes the histogram, and generating a histogram manually will still use the NewDensity but not the density provided as part of the user-generated statistics.

I haven't had time yet to test this personally, but now that Wolfgang has mentioned it I'm quite sure I remember that he's right regarding setting the density manually - it removes the complete histogram immediately.

Can you comment on what you meant by above: "If you set your own column stats using dbms_stats.set_column_stats..."?

Have you tried to modify the density only or generating your own histogram?

Randolf]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>107</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-12-03 17:59:32]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-12-03 15:59:32]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Randolf,

thank you very much for your positive feedback, I really appreciate it - as you "may" know, it takes a lot of time to write about this kind of things trying to be clear and exhaustive ...

I use the following tiny SP to set the density while preserving the histogram:
[sql]
-- a utility procedure to change density, preserving the histogram
create or replace procedure set_density (
  p_table_name  varchar2,
  p_column_name varchar2,
  p_new_density number,
  p_flags       number default null
)
is
  l_distcnt     number;
  l_old_density number;
  l_nullcnt     number;
  l_srec        dbms_stats.statrec;
  l_avgclen     number;
  l_new_density number;
begin
  -- get the current column statistics
  dbms_stats.get_column_stats (
    ownname => user,
    tabname => p_table_name,
    colname => p_column_name,
    distcnt => l_distcnt,
    density => l_old_density,
    nullcnt => l_nullcnt,
    srec    => l_srec,
    avgclen => l_avgclen
  );

  -- reset them, overwriting "density"
  if p_new_density is not null then
    l_new_density := p_new_density;
  else
    l_new_density := l_old_density;
  end if;
  
  dbms_stats.set_column_stats (
    ownname => user,
    tabname => p_table_name,
    colname => p_column_name,
    distcnt => l_distcnt,
    density => l_new_density,
    nullcnt => l_nullcnt,
    srec    => l_srec,
    avgclen => l_avgclen,
    no_invalidate => false,
    flags         => p_flags
  );
  
  dbms_output.put_line ('density of '||p_table_name||'.'||p_column_name||' changed from '||l_old_density||' to '|| l_new_density);

end set_density;
/
show errors;
[/sql]
I've tested it right now again, albeit on 11.1.0.7 only, and it actually preserves the histogram. It is a script I've used for some years now.

Notice how it works : it fetches the histogram from the data dictionary, and rewrites it back verbatim with a new density, possibly changing the "flags" as well ...]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>106</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>108</wp:comment_id>
			<wp:comment_author><![CDATA[Randolf Geist]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[info@sqltools-plusplus.org]]></wp:comment_author_email>
			<wp:comment_author_url>http://oracle-randolf.blogspot.com/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[87.178.69.207]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-12-03 18:44:05]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-12-03 16:44:05]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Alberto,

thanks for the clarification.

So you mean to say: Using your SP you've manually modified the density while preserving the histogram - and the CBO uses then the manually modified density from the dictionary for calculation but not the NewDensity any longer?

I thought that Wolfgang meant to say that he has generated a histogram manually along with a density, but the CBO sill applied the NewDensity algorithm to his made-up histogram.

At least two things come into my mind that might matter:
- I don't know the version he has used to test
- He seems to have setup a made-up histogram rather than preserving an existing one, however I don't see where this exactly should make any difference

Anyway, thanks for the feedback. If I find some time I'll test it myself resp. ask Wolfgang for clarification what he did and what version he used to test.

Randolf]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>109</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-12-03 20:18:06]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-12-03 18:18:06]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Randolf,

&gt;So you mean to say: Using your SP you've manually modified the density 
&gt;while preserving the histogram - and the CBO uses then the manually 
&gt;modified density from the dictionary for calculation but not the NewDensity any longer?

Yes if you use the default and only supported value (null) for the "flags" parameter of dbms_stats.set_column_stats - as far as I understand, in this case the statistics get labeled as "user generated stats" (dba_tab_cols.user_stats = 'YES'). If you set "flags" to 2, you are pretending to be dbms_stats or a system routine (dba_tab_cols.user_stats = 'NO') and hence NewDensity gets used.

It makes sense - if the user has provided her own value for "density", use it instead of NewDensity. 

NB: I have exchanged in the past many, many emails with Wolfgang and I've noticed that He commonly uses flags=2 in his scripts ... that should explain everything nicely :)]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>108</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>110</wp:comment_id>
			<wp:comment_author><![CDATA[Xiang Rao]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[xiang_rao@hotmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[69.246.175.240]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-08-22 20:59:57]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-08-22 18:59:57]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto,
I am wondering if the num_rows inside the "half the least popular" formula NewDensity = 0.5 * bkt(least_popular_value)/num_rows should be the last endponiter_number? In your case, both of your row count and the buckets are the same: 216.

I have a table with 99,826,738 rows, the concerned column has 60 distinct values ranged between 3 and 451, with frequncy histogram of 17 buckets, and density 5.17e-9. The last endponiter_number is 5,327 and the least popular value 303 has only 1 bucket. For value 4 (not any of the endpoint_value, but beteween first 2 values), Oracle gives cardinality estimate as 9,370 and newDensity as 0.000094, which is 0.5*bkt(303)/last_endpoint_number = 0.5*1/5,327. I was looking for the theory behind the newDensity value 0.000094, and google brought me to your article again.

Thanks,

Xiang]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>111</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[151.64.131.0]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-08-25 18:56:46]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-08-25 16:56:46]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Xiang,

yes, you're right - in all my examples I have always used no sampling when gathering statistics  (to keep the discussion simple and the examples deterministic), and when no sampling, the last endpoint_number is always exactly the same as num_rows. But it is the last endpoint_number that is to be used in the formula, as you kindly point out - which makes a difference to you since you are sampling for sure.


Just to be complete, here's a demo that shows the effect of sampling on endpoint_number for a table with num_rows=100000:
[sql]
SQL&gt; create table tt as select 0 as x  from dual connect by level &lt;= 100000;
SQL&gt; exec dbms_stats.gather_table_stats(user,'tt',method_opt=&gt;'for all columns size 254', estimate_percent=&gt;0.000001);
SQL&gt; select max(endpoint_number) from user_histograms where table_name='TT' and column_name='X';

MAX(ENDPOINT_NUMBER)
--------------------
                2710
SQL&gt; exec dbms_stats.gather_table_stats(user,'tt',method_opt=&gt;'for all columns size 254', estimate_percent=&gt;null);
SQL&gt; select max(endpoint_number) from user_histograms where table_name='TT' and column_name='X';

MAX(ENDPOINT_NUMBER)
--------------------
              100000
[/sql]
Thanks for commenting!]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>110</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>112</wp:comment_id>
			<wp:comment_author><![CDATA[Rickey]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[rickeyfrancisco@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.linkvis.com/profile/AprilDuck</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[194.71.225.89]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-01-14 05:34:27]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-01-14 03:34:27]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Definitely believe that that you stated. Your 
favorite reason seemed to be on the net the easiest thing to 
take into accout of. I say to you, I definitely get annoyed even as folks think 
about concerns that they just do not know about.

You managed to hit the nail upon the top as well as defined out 
the whole thing with no need side-effects , other people could take a signal.

Will likely be again to get more. Thanks]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>113</wp:comment_id>
			<wp:comment_author><![CDATA[Sayan Malakshinov]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[xt.and.r@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://orasql.org</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[95.31.24.2]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-12-03 21:43:41]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-12-03 19:43:41]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Alberto, 

could you tell me please: is this my view dba_newdensity written correctly?
[sql]
create or replace view dba_newdensity as
with
 histgrm1 as (
   select--+ inline merge
      owner                 as owner
     ,table_name            as table_name
     ,column_name           as column_name
     ,endpoint_number       as ep_num
     ,endpoint_value        as ep_val
     ,endpoint_actual_value as ep_act_val
     ,lag(endpoint_number) over(partition by owner,table_name,column_name order by endpoint_number) as ep_num_prev
   from
      dba_histograms h1
)
,histgrm2 as (
   select--+ inline
      owner                       as owner
     ,table_name                  as table_name
     ,column_name                 as column_name
     ,ep_num                      as ep_num
     ,ep_val                      as ep_val
     ,ep_act_val                  as ep_act_val
     ,ep_num - nvl(ep_num_prev,0) as bkt
     ,decode (ep_num - nvl(ep_num_prev,0)
               , 0, 0
               , 1, 0
               , 1
             ) as popularity
   from
      histgrm1 h
)
,hist_agg as (
   select--+ inline
       owner
      ,table_name
      ,column_name
      ,max(ep_num) as BktCnt -- should be equal to sum(bkt)
      ,sum(decode(popularity, 1, bkt,0))  as PopBktCnt
      ,sum(decode(popularity, 1, 1  ,0))  as PopValCnt
--      ,min(bkt) keep(dense_rank first order by decode(popularity,1,ep_num)) as bkt_least_popular_value
--      ,min(decode(popularity,1,bkt)) keep(dense_rank first order by decode(popularity,1,bkt) nulls last) as bkt_least_popular_value
      ,min(decode(popularity,1,bkt)) as bkt_least_popular_value
   from histgrm2
   group by owner,table_name,column_name
)
select
    st.owner
   ,st.table_name
   ,st.column_name
   ,st.histogram
   ,h.BktCnt
   ,h.PopBktCnt
   ,h.PopValCnt
   ,st.num_distinct as NDV
   ,h.bkt_least_popular_value
   ,st.density      as old_Density
   ,case st.histogram
      when 'FREQUENCY'
           then  -- 0.5 * bkt_least_popular_value / t.num_rows
                 0.5 * bkt_least_popular_value / BktCnt
      when 'HEIGHT BALANCED'
           then   ( 1 - PopBktCnt / BktCnt ) / (st.num_distinct - PopValCnt)
    end as newdensity
from
     dba_tab_col_statistics st
    ,hist_agg   h
    ,dba_tables t
where
      st.owner       = h.owner
  and st.table_name  = h.table_name
  and st.column_name = h.column_name
  and st.owner       = t.owner
  and st.table_name  = t.table_name;[/sql] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>114</wp:comment_id>
			<wp:comment_author><![CDATA[Sayan Malakshinov]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[xt.and.r@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://orasql.org</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[95.31.24.2]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-12-03 21:49:14]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-12-03 19:49:14]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[without unnecessary:
[sql]
create or replace view dba_newdensity as
with
 histgrm1 as (
   select--+ inline merge
      owner                 as owner
     ,table_name            as table_name
     ,column_name           as column_name
     ,endpoint_number       as ep_num
     ,endpoint_value        as ep_val
     ,endpoint_actual_value as ep_act_val
     ,lag(endpoint_number) over(partition by owner,table_name,column_name order by endpoint_number) as ep_num_prev
   from
      dba_histograms h1
)
,histgrm2 as (
   select--+ inline
      owner                       as owner
     ,table_name                  as table_name
     ,column_name                 as column_name
     ,ep_num                      as ep_num
     ,ep_val                      as ep_val
     ,ep_act_val                  as ep_act_val
     ,ep_num - nvl(ep_num_prev,0) as bkt
     ,decode (ep_num - nvl(ep_num_prev,0)
               , 0, 0
               , 1, 0
               , 1
             ) as popularity
   from
      histgrm1 h
)
,hist_agg as (
   select--+ inline
       owner
      ,table_name
      ,column_name
      ,max(ep_num) as BktCnt -- should be equal to sum(bkt)
      ,sum(decode(popularity, 1, bkt,0))  as PopBktCnt
      ,sum(decode(popularity, 1, 1  ,0))  as PopValCnt
      ,min(decode(popularity,1,bkt)) as bkt_least_popular_value
   from histgrm2
   group by owner,table_name,column_name
)
select
    st.owner
   ,st.table_name
   ,st.column_name
   ,st.histogram
   ,h.BktCnt
   ,h.PopBktCnt
   ,h.PopValCnt
   ,st.num_distinct as NDV
   ,h.bkt_least_popular_value
   ,st.density      as old_Density
   ,case st.histogram
      when 'FREQUENCY'
           then  0.5 * bkt_least_popular_value / BktCnt
      when 'HEIGHT BALANCED'
           then   ( 1 - PopBktCnt / BktCnt ) / (st.num_distinct - PopValCnt)
    end as newdensity
from
     dba_tab_col_statistics st
    ,hist_agg   h
where
      st.owner       = h.owner
  and st.table_name  = h.table_name
  and st.column_name = h.column_name;
create public synonym dba_newdensity for dba_newdensity;
grant select on dba_newdensity to public;[/sql] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>115</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[151.64.130.30]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-01-25 16:26:08]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-01-25 14:26:08]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Sayan,

sorry for the long delay, my notification module has gone berserk again ;(

There was a NewDensity calculation function inside the test case, have you checked that ? As far as I know my function is correct;  if that's not the case, I would like to know the reason]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>114</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>117</wp:comment_id>
			<wp:comment_author><![CDATA[DiF]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[asdaroth@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[144.24.20.227]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2015-10-09 22:20:14]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2015-10-09 20:20:14]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto,

I tried to influence the optimizer to use Old Density value when calculating the join cardinality/selectivity for a statement, but without any success. Is it possible to do such a thing ?

--10053 before
Table Stats::
  Table: TAB_1  Alias: TAB_1  (Using composite stats)
    #Rows: 3913250500  #Blks:  34223419  AvgRowLen:  408.00  ChainCnt:  0.00
Index Stats::
  Index: IDX_1  Col#: 16
    USING COMPOSITE STATS
    LVLS: 2  #LB: 897500  #DK: 231507  LB/K: 3.00  DB/K: 19.00  CLUF: 4469600.00
    ALL PARTITIONS USABLE
    
 Column (#16): 
    NewDensity:0.000004, OldDensity:0.000072 BktCnt:254, PopBktCnt:28, PopValCnt:1, NDV:231507
  Column (#16): COL_1(
    AvgLen: 5 NDV: 231507 Nulls: 0 Density: 0.000004 Min: -1 Max: 836355
    Histogram: HtBal  #Bkts: 254  UncompBkts: 254  EndPtVals: 227
    
Access Path: index (AllEqJoinGuess)
    Index: IDX_1
    resc_io: 214.00  resc_cpu: 2089826
    ix_sel: 0.000004  ix_sel_with_filters: 0.000004 
    NL Join : Cost: 1077.02  Resp: 63.62  Degree: 20
      Cost_io: 1074.00  Cost_cpu: 10495264
      Resp_io: 63.44  Resp_cpu: 626640

Height histogram on column COL_1 has a single popular value ('-1', about 10% of the rows, 430M). Unfortunately this popular value is the one that is being retrieved from TAB_1. Instead of E-Rows of 17K (3,913,250,500 / 231,507 = 16903.37873152864) we get 431,381,945 rows (cardinality of popular value). COL_1 is a join column (no predicates are applied to it) for TAB_1, which is an inner table in a NESTED LOOP.

The following piece of code was executed:
exec dbms_stats.set_column_stats(OWNNAME =&gt;null, TABNAME =&gt;'TAB_1', colname =&gt;'COL_1',density =&gt; 0.00007169487, flags   =&gt; null);       

--0.00007169487 is the Old Density
--Histogram on COL_1 disappeared after command was executed
--dba_tab_cols.user_stats = ‘YES’ for COL_1
--10053 after:        

Table Stats::
  Table: TAB_1  Alias: TAB_1  (Using composite stats)
    #Rows: 3912654200  #Blks:  34224610  AvgRowLen:  408.00  ChainCnt:  0.00
Index Stats::
Index: IDX_1  Col#: 16
    USING COMPOSITE STATS
    LVLS: 2  #LB: 897500  #DK: 231507  LB/K: 3.00  DB/K: 19.00  CLUF: 4469600.00
    ALL PARTITIONS USABLE      
Column (#16): COL_1(
    AvgLen: 5 NDV: 237644 Nulls: 0 Density: 0.000072 Min: -1 Max: 841836
       
Access Path: index (AllEqJoinGuess)
    Index: IDX_1
    resc_io: 214.00  resc_cpu: 2089626
    ix_sel: 0.000004  ix_sel_with_filters: 0.000004 
    NL Join : Cost: 1077.02  Resp: 63.62  Degree: 20
      Cost_io: 1074.00  Cost_cpu: 10494264
      Resp_io: 63.44  Resp_cpu: 626584
 

Even if Density: 0.000072 for COL_1, index selectivity is still calculated using 1/NDV (1/231507 =  0.00000431952381569). Is this happening because the histogram is missing and density is not taken into account when selectivity is calculated ?

Is there any method to change ix_sel ?

Regards,
Dif]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>118</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[93.33.115.111]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2015-11-25 21:10:51]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2015-11-25 19:10:51]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[DiF,

sorry for the delay ... have you tried changing the index stats to check whether the CBO is using them while ignoring the column ones? 

You can set  _optimizer_enable_density_improvements=false to get back the old density, as stated in 
http://www.adellera.it/investigations/11g_newdensity/11gNewDensity.pdf

HTH - Al]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>117</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>119</wp:comment_id>
			<wp:comment_author><![CDATA[12c Hybrid histogram &#8211; All Things Oracle]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://allthingsoracle.com/12c-hybrid-histogram/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[52.16.220.145]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2016-01-26 17:19:51]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2016-01-26 15:19:51]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] buckets, the number of popular values, etc. Nevertheless, using the following select (inspired by Alberto Dell&#8217; Era) we can get a reliable value for the [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>11gR2: materialized view logs changes</title>
		<link>http://www.adellera.it/blog/2009/11/03/11gr2-materialized-view-logs-changes/</link>
		<pubDate>Tue, 03 Nov 2009 17:20:51 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=376</guid>
		<description></description>
		<content:encoded><![CDATA[In this post we are going to discuss some 11gR2 changes to materialized view logs that are aimed at increasing the performance of the fast-refresh engine of materialized views (MVs), especially the on-commit variant. 

The MV logs, in 10gr2, now comes in <a href="http://download.oracle.com/docs/cd/E11882_01/server.112/e10592/statements_6003.htm#i2064649">two flavours</a>: the traditional (and still the default) <b>timestamp</b>-based one and the brand new <b>commit SCN</b>-based one; you choose the latter type by specifing the "WITH COMMIT SCN" clause at MV log creation time. Interestingly, the "old" timestamp-based implementation has been changed as well. Let's examine both with the help, as usual, of a <a href="http://34.247.94.223/wp-content/uploads/2009/11/11gr2_mv_logs.zip">test case</a>.

<b>Timestamp-based MV logs (the "old" type)</b>

The test case configures an MV log as "log everything", that is, it activates all the logging options:
[text]
create materialized view log on test_t1 
with sequence, rowid, primary key (x1) 
including new values;
[/text]

In pre-11gR2 (e.g. in 11.1.0.7, 10.2.0.4), the MV log columns were:
[text]
pk1             number(22)
x1              number(22)
m_row$$         varchar2(255)
sequence$$      number(22)
snaptime$$      date(7)
dmltype$$       varchar2(1)
old_new$$       varchar2(1)
change_vector$$ raw(255) 
[/text]
now in 11gR2 (11.2.0.1):
[text]
pk1             number(22)
x1              number(22)
m_row$$         varchar2(255)
sequence$$      number(22)
snaptime$$      date(7)
dmltype$$       varchar2(1)
old_new$$       varchar2(1)
change_vector$$ raw(255)
xid$$           number(22) 
[/text]
the only difference is the new column xid$$ (transaction id) that uniquely identifies the transaction that made the changes to the row. For the curious, the number is a combination of the elements of the triplet (undo segment number, undo slot, undo sequence); it is simply the binary concatenation of the three numbers shifted by (48, 32, 0) bits respectively (as checked in the script).

The xid$$ column is used by the 11gR2 on-commit fast refresh engine, which can now easily retrieve the changes made by the just-committed transaction by its xid; at the opposite, the on-demand fast refresh one keeps using snaptime$$ as it did in previous versions. I will speak about this in more detail in an upcoming post.

<b>Commit SCN-based MV logs (the "new" type in 11gR2)</b>

Let's recreate the same MV log, this time adding the commit SCN clause (new in 11GR2):
[text]
create materialized view log on test_t1 
with sequence, rowid, primary key (x1), COMMIT SCN 
including new values;
[/text]
The columns of the MV log are:
[text]
pk1             number(22)
x1              number(22)
m_row$$         varchar2(255)
sequence$$      number(22)
dmltype$$       varchar2(1)
old_new$$       varchar2(1)
change_vector$$ raw(255)
xid$$           number(22) 
[/text]
so, the only difference from the 11gR2 timestamp-based case is that  snaptime$$ is no longer a column of the MV log; the only difference from the pre-11gR2 is that snaptime$$ has been replaced with xid$$.

For this log flavour only, the mapping between the xid that modified the table and its commit-time SCN is now tracked in a new view, all_summap (probably named after "SUMmary MAP", "summary" being yet another synonym for "MV"), which is (as of 11.2.0.1) a straight "select *" of  the dictionary table sys.snap_xcmt$. To illustrate, the script makes one insert, one update and one delete on the base table, which translates into 4 rows inside the MV log with the same xid:
[sql]
SQL&gt; select distinct xid$$ from mlog$_test_t1;

                XID$$
---------------------
     1126024460895690
[/sql]
after the commit, we get 
[sql]
SQL&gt; select * from all_summap where xid in (select xid$$ from mlog$_test_t1);

                  XID COMMIT_SCN
--------------------- ----------
     1126024460895690    2885433
[/sql]
hence, it is now possible to know the infinite-precision time (the SCN) when every modification became visible to an external observer (the commit SCN) by simply joining the MV log and all_summap (or sys.snap_xcmt$). Note that the commit SCN is not propagated to the MV log at all.


<b>commit SCN-based MV logs for on-demand fast refresh</b>

This new xid$$ column and commit-SCN mapping table are leveraged by the fast refresh of on-demand MVs as follows (on-commit ones do not need the SCN as they know exactly the xid of the committed transaction; again we will see that in an upcoming post).

With "old style" timestamp-based MV logs, the refresh is performed by using a "mark-and-propagate" algorithm, which is essentially (check <a href="http://www.adellera.it/blog/2009/08/04/fast-refresh-of-join-only-materialized-views-algorithm-summary/">this post</a> for some additional details):
1) new log rows are inserted with snaptime$$=4000 A.D;
2) at refresh time, a snapshot of the new rows is taken, that is, all new rows are marked with snaptime$$=sysdate;
3) all modifications whose snaptime$$ is between the date of the last refresh (excluded) and sysdate(included) are propagated to the MV;
4) all obsolete log rows are deleted, that is, all rows whose snaptime$$ is less than or equal the lowest of all refresh times are removed from the log.

With "new style" SCN-based MV logs, the algorithm is, instead:
1) new log rows are inserted with xid$$=transaction id of modifing transaction;
2) at refresh time, the current SCN is retrieved (no snapshot is performed);
3) all modifications whose xid maps to a row in all_summap whose commit_scn is between the SCN of the last refresh (excluded) and the retrieved current SCN(included) are propagated to the MV;
4) obsolete rows are removed from the log as before, this time using the SCN instead of snaptime$$.

The main advantage is that the snapshot is not performed, thus removing the redo and undo generated by the update, and obviously the log visit (usually a full table scan) as well - at the cost of an additional join with all_summap (or sys.snap_xcmt$) later; if the join is calculated efficiently, that is very likely advantageous "in general" (but as always, it depends on your scenario).

It might be (rarely) beneficial to index xid$$, as it is (rarely) beneficial to index snaptime$$. In that case, having no snapshot performed reduces both the undo and redo generated for the index maintenance.

As a side and "philosophical" note, it is also worth noting that the new logging mechanism records more information - now we know which transactions modified the table and the infinite-precision time (the SCN) of modifications, and this is much more informative about the history of the logged table than the mostly meaningless refresh time contained in snaptime$$. This is definitely a better utilization of storage.

I plan to blog about how the new MV log impact fast refreshes in 11gR2 in the near future, focusing on join-only MVs; so stay tuned if you're interested.]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>376</wp:post_id>
		<wp:post_date><![CDATA[2009-11-03 19:20:51]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-11-03 17:20:51]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[11gr2-materialized-view-logs-changes]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="materialized-views"><![CDATA[materialized views]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_syntaxhighlighter_encoded]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>120</wp:comment_id>
			<wp:comment_author><![CDATA[Rob van Wijk]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[rwijk72@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://rwijk.blogspot.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[82.171.93.154]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-11-03 22:20:39]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-11-03 20:20:39]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Great post.
Looking forward to the next one!]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>121</wp:comment_id>
			<wp:comment_author><![CDATA[Blogroll Report 30/10/2009-06/11/2009 &laquo; Coskan&#8217;s Approach to Oracle]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://coskan.wordpress.com/2009/11/10/blogroll-report-21/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[74.200.245.251]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-11-10 20:16:47]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-11-10 18:16:47]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] Alberto Dell&#8217;era-11gR2: materialized view logs changes [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>122</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; 11gR2: new algorithm for fast refresh of on-commit materialized views]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2009/11/22/11gr2-new-algorithm-for-fast-refresh-of-on-commit-materialized-views/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-11-22 17:56:31]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-11-22 15:56:31]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] noted in the post of mine "11gR2: materialized view logs changes", in 11gR2 a new column, xid$$, is now part of materialized view logs; this column records the id [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>123</wp:comment_id>
			<wp:comment_author><![CDATA[suman]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[sumanamara@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[122.181.128.170]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-09-17 11:07:18]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-09-17 09:07:18]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[very nice top.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>124</wp:comment_id>
			<wp:comment_author><![CDATA[sam]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[sachintugnayat@yahoo.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[54.240.196.186]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-10-04 19:54:10]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-10-04 17:54:10]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[hi,
I am on 11.2.0.2
I have requirement to snap two tables, both the table are dealing with almost 40 million  DML ( mostly inserts and deletes ).
my snaps is not able to catch up with this many changes and always lag, once its start lagging, its not able to catch up.

what you think how to deal with this ? you advice will be greatly appreciated .

thanks]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>125</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[151.64.142.136]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-10-04 21:20:13]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-10-04 19:20:13]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Sam,
How many rows are in your master tables, and how many in their mv logs?
Are your master tables local, or across a db-link?]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>124</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>126</wp:comment_id>
			<wp:comment_author><![CDATA[sam]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[sachintugnayat@yahoo.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[54.240.196.185]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-10-04 22:56:29]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-10-04 20:56:29]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[thanks for reply,

master table is weekly partitioned, retention is 6 weeks, per partition is having almost 70 million rows, its on remote DB.

as an avg, in 10 min I can see. around 200K insert/update and 30K delete in mview log.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>127</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[151.64.142.136]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-10-04 23:32:23]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-10-04 21:32:23]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[So when you refresh, you get 40M rows in the mv log, and 6x70M rows in the master ?
Have you tried refreshing more often, or even switching to complete refresh (that can be much quicker then "fast" when you have to propagate many rows) and maybe (if you can live with it) trying with atomic => false ?]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>128</wp:comment_id>
			<wp:comment_author><![CDATA[sam]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[sachintugnayat@yahoo.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[54.240.196.185]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-10-05 00:08:59]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-10-04 22:08:59]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[hi,
let me elaborate.
I am trying to build the snap for migration of very big table with heavy DML activity. my refresh interval is 5 min. 

1. master side table size is 200G.
2. 5 min DML activities are around 100K insert, 100K update and 30K delete on master.
3. complete refresh is not an option here, it will take forever to finish it.
do you have any other faster technique to do complete refresh ? 
because, suppose if first complete refresh takes 5 hours to finish then next fast refresh will have millions of rows and it will never finish.

so what I am doing here.
1.I am creating one empty table structure
2. creating mlog on master
3. then using  dbms_mview.set_i_am_a_refresh(true); to insert into mview.
4. loading 200G of data taking at least 4 hours.
5. then using fast refresh to catch changes happened in 4 hours.
5. but in those 4 hours mlog grows too big that its not catching up.

my question is
how to make fast refresh more faster on heavy DML activity table which generates almost 300K DML per 5 min.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>129</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-10-05 10:24:40]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-10-05 08:24:40]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[If you are using dbms_mview.set_i_am_a_refresh(true) because this is an updatable MV, I must confess I have no experience with that kind of MV, sorry.

Anyway, to speed up the refresh, I would try to investigate (by tracing) the statements submitted to refresh - for example, I have done that (for read only snapshots) here:
http://www.adellera.it/blog/2009/08/11/fast-refresh-of-single-table-materialized-views-algorithm-summary/
for example, one could find that the plan is wrong due to missing statistics on the master or the master MV, or maybe find that some indexes might help, etc

I would check whether LOCKING the stats on the MV logs makes any difference, as it does for join MVs:
http://www.adellera.it/blog/2010/03/11/fast-refresh-of-join-only-mvs-_mv_refresh_use_stats-and-locking-log-stats/

Maybe using rowid-based MV logs instead of primary key might save index visits during the refresh.

If supported over a db-link, I would also investigate using SCN-based MV logs - it would save the "mark the rows in the log" phase:
http://www.adellera.it/blog/2009/11/03/11gr2-materialized-view-logs-changes/

I would stress that these are only *speculations*; as said above, the best way is to trace, and better yet, profile the refresh and try to investigate and optimize the slower components. At the end, it's not much different than standard performance tuning, with the complication that you can't control the SQL statements submitted.

HTH ;)]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>128</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>130</wp:comment_id>
			<wp:comment_author><![CDATA[sachin]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[sachintugnayat@yahoo.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[54.240.196.185]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-10-05 20:25:35]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-10-05 18:25:35]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[thanks Alberto,
above replay shows that you really care about your blog, I have seen many oracle blogger posts something and if someone ask anything about it, NO REPLY.

Yeh, 
I have created the index mlog but still i wasn't able to catch up. session on master side hovering around seq. read and after few hours it terminated with snapshot too old, I will get the trace data also. 

I will also check on commit based mlog and update my findings. 

thanks again.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>131</wp:comment_id>
			<wp:comment_author><![CDATA[antony]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[ca_raj@yahoo.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[74.90.71.107]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-09-03 06:09:23]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-09-03 04:09:23]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto,

COMMIT-SCN based logging can only be used with locally managed MVs.As per Oracle11gR2 SQL reference doc,You cannot create remote materialized views on base tables with commit SCN-based materialized view logs.

Thanks
Antony]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>132</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[151.64.142.167]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-09-07 17:14:01]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-09-07 15:14:01]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Anthony,

thanks for your observation - I had indeed tested only "locally managed" mviews, not "remote" ones (that used to be named "snapshot" in the good old days) ...]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>131</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>133</wp:comment_id>
			<wp:comment_author><![CDATA[oraclenewbie]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[cfancy23@yahoo.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[216.113.168.130]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-07-30 01:31:34]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-07-29 23:31:34]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[The commit SCN can be obtained from the MV log's ORA_ROWSCN pseudocolumn, it should be the same as those obtained from the sys.snap_xcmt$, right? 

Does anyone know how the commit timestamp is inserted into the sys.snap_xcmt$? Through a internal trigger fired after commit? At least there is no commit trigger that the users can define.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>134</wp:comment_id>
			<wp:comment_author><![CDATA[Trevor]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[shalomav@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[129.253.54.30]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2015-01-22 02:34:39]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2015-01-22 00:34:39]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA["now in 11gR2 (10.2.0.1)", you mean "now in 11gR2 (11.2.0.1):"]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>135</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.51]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2015-01-22 11:46:20]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2015-01-22 09:46:20]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Trevor,

many thanks - fixed :)]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>134</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>11gR2: new algorithm for fast refresh of on-commit materialized views</title>
		<link>http://www.adellera.it/blog/2009/11/22/11gr2-new-algorithm-for-fast-refresh-of-on-commit-materialized-views/</link>
		<pubDate>Sun, 22 Nov 2009 15:56:28 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=385</guid>
		<description></description>
		<content:encoded><![CDATA[This post investigates the improvements that have been made in 11gR2 to the fast refresh engine of materialized views (MVs) that are set to be automatically refreshed at commit time. We speak about join-only materialized views only in this post, as always with the help of a test case.

As noted in the post of mine "<a href="http://www.adellera.it/blog/2009/11/03/11gr2-materialized-view-logs-changes/">11gR2: materialized view logs changes</a>", in 11gR2 a new column, xid$$, is now part of materialized view logs; this column records the id of the transaction that logged the changes of the base table which the log is defined on. It is important to stress that this column is added regardless of the type of the MV log, that is, to <b>both</b> the brand-new "commit SCN-based" logs <b>and</b> the old fashioned "timestamp-based" ones. That means that both types of MV logs can take advantage of the new improvements - albeit I haven't tested whether MVs (logs) migrated from a previous version are automatically upgraded by the migration scripts and get the new xid$$ column added.

<b>algorithm before 11gR2</b>

In versions before 11gR2, the refresh algorithm for on-commit MVs was the same as the one for on-demand ones, with only minor variants. That is, the algorithm was almost completely the same, just triggered by the commit event instead of by the user.

For an in-depth analysis of the algorithm, I will refer the reader to the discussion about the on-demand algorithm in the post "<a href="http://www.adellera.it/blog/2009/08/04/fast-refresh-of-join-only-materialized-views-algorithm-summary/">fast refresh of join-only materialized views - algorithm summary</a>"; in passing, the <a href="http://34.247.94.223/wp-content/uploads/2009/11/11gr2_join_mv_on_commit.zip">test case</a> for this post is in fact the very same three-table join MV, just redefined as "on commit" instead of "on demand". To recap, the "old" algorithm (until 11.1.0.7) was:

1) new log rows are inserted with snaptime$$=4000 A.D;
2) at refresh time (commit time), a snapshot of the new rows is taken, that is, all new rows are marked with snaptime$$= "commit time", using the statement
[sql]
update MLOG$_TEST_T1
   set snaptime$$ = :1  
 where snaptime$$ > to_date('2100-01-01:00:00:00','YYYY-MM-DD:HH24:MI:SS')
[/sql]
3) all modifications whose snaptime$$ is between the date of the last refresh (excluded) and the commit date(included) are propagated to the MV. The propagation consists of two steps.
First a DEL step:
[sql]
/* MV_REFRESH (DEL) */ 
delete from test_mv 
 where test_t1_rowid in 
       (
select * from 
       (
select chartorowid (m_row$$)     
  from mlog$_test_t1   
 where snaptime$$ > :1 
       ) -- no "as of snapshot (:2)" clause
       )
[/sql]
Then an INS one:
[sql]
/* MV_REFRESH (INS) */ 
insert into test_mv 
select jv.j1_2, jv.x1, jv.pk1, jv.rid$,
       mas2.j2_1, mas2.j2_3, mas2.x2, mas2.pk2, mas2.rowid,
       mas3.j3_2, mas3.x3, mas3.pk3, mas3.rowid 
  from ( 
select log.rowid rid$, log.*  
  from test_t1 log 
 where rowid in 
       (
select chartorowid(log.m_row$$)     
  from mlog$_test_t1   
 where snaptime$$ > :1 
       )
       ) jv, -- no "as of snapshot (:2) jv" clause
       test_t2 as of snapshot (:2)  mas2,
       test_t3 as of snapshot (:2)  mas3 
 where   jv.j1_2 = mas2.j2_1 
   and mas2.j2_3 = mas3.j3_2 
[/sql]
Note that the only small difference from the on-demand case is the absence of the "as of snapshot" clause, but the statements are otherwise identical. Note also that the rows in the MV log are identified in both statements by snaptime, using the subquery  
[sql]
select chartorowid(log.m_row$$)     
  from mlog$_test_t1   
 where snaptime$$ > :1 
[/sql]
4) all obsolete log rows are deleted, that is, all rows whose snaptime$$ is less than or equal the lowest of all refresh times are removed from the log, using the the statement
[sql]
delete from mlog$_test_t1
 where snaptime$$ <= :1
[/sql]

<b>algorithm starting from 11gR2</b>

In 11gR2, the on-commit algorithm is still almost the same as the on-demand one; the "only" change is how modified rows to be propagated are identified, and in general, how logs are managed. Not surprisingly, log rows are now directly identified by the transaction id, which is logged in xid$$. In detail:

1) new log rows are inserted with xid$$ = transaction id;
2) at refresh time (commit time), <b>no snapshot is taken</b>, that is, the MV log is not updated at all;
3) all modifications made by the committing transaction are propagated to the MV, still using the same two steps.
The DEL step is now:
[sql]
/* MV_REFRESH (DEL) */ 
delete from test_mv 
 where test_t1_rowid in 
       (
select * from 
       (
select chartorowid (m_row$$)     
  from mlog$_test_t1   
 where xid$$ = :1
       ) 
       )
[/sql]

The INS one is:
[sql]
/* MV_REFRESH (INS) */ 
insert into test_mv 
select jv.j1_2, jv.x1, jv.pk1, jv.rid$,
       mas2.j2_1, mas2.j2_3, mas2.x2, mas2.pk2, mas2.rowid,
       mas3.j3_2, mas3.x3, mas3.pk3, mas3.rowid 
  from ( 
select log.rowid rid$, log.*  
  from test_t1 log 
 where rowid in 
       (
select chartorowid(log.m_row$$)     
  from mlog$_test_t1   
 where xid$$ = :1
       )
       ) jv, -- no "as of snapshot (:2) jv" clause
       test_t2 as of snapshot (:2)  mas2,
       test_t3 as of snapshot (:2)  mas3 
 where   jv.j1_2 = mas2.j2_1 
   and mas2.j2_3 = mas3.j3_2 
[/sql]

Hence, the big difference from the previous versions case is that rows in the MV log are identified very simply by the transaction that logged them (the committing transaction, of course), by the subquery  
[sql]
select chartorowid(log.m_row$$)     
  from mlog$_test_t1   
 where xid$$ = :1
[/sql]
4) all obsolete log rows are deleted, that is, the rows logged by the committing transaction are removed, using the the statement
[sql]
delete from mlog$_test_t1
 where where xid$$ = :1 
[/sql]

The new algorithm is for sure much simpler and more elegant. Performance is improved since the snapshot step has been removed, and the other steps are more or less as expensive as before. 

<b>practical implications: an example</b>

I strongly believe that studying the internals is the best way to learn how to make the best use of any feature. Let's see an example of how the few bits of "internal knowledge" I shared here can be used in practice - that is, how a little investment in investigation makes for huge savings in effort afterwards, and huge gains in effectiveness of your work as well.

It is well-known that it can be sometimes beneficial, in pre-11gR2, to place an index on the log (indexing the log is even suggested by support note 258252 "MATERIALIZED VIEW REFRESH: Locking, Performance, Monitoring"). The scenario that benefits the most from such an index is when the log is composed of mostly-empty blocks, and hence an index access is preferable over a full table(log) scan; you get mostly-empty blocks, for example, when there are peeks in activity on the master tables that keep the log  High Water Mark very high.

From the above discussion, it is obvious that in pre-11gR2, the best index for join-only MVs was on (snaptime$$, m_row$$) - not on snaptime$$ alone as it is sometimes suggested - to make the refresh operation an index-only one. 

Starting from 11gR2, the best index is now on (xid$$, m_row$$). Not only that, but having no snapshot step, and hence no update on the index, makes the indexing option even more attractive.

Could you see these implications so easily, without knowing the internals? I don't.


]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>385</wp:post_id>
		<wp:post_date><![CDATA[2009-11-22 17:56:28]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2009-11-22 15:56:28]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[11gr2-new-algorithm-for-fast-refresh-of-on-commit-materialized-views]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="materialized-views"><![CDATA[materialized views]]></category>
		<category domain="category" nicename="performance-tuning"><![CDATA[performance tuning]]></category>
						<wp:comment>
			<wp:comment_id>136</wp:comment_id>
			<wp:comment_author><![CDATA[Igor]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[igor.racic@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[194.98.239.11]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-12-04 16:44:27]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-12-04 14:44:27]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto, 

I agree with your point of view. (just don't tell to tkyte about it. Just kidding... :-)

Thank you for these insights.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>137</wp:comment_id>
			<wp:comment_author><![CDATA[Blogroll Report 20/11/2009-27/11/2009 &laquo; Coskan&#8217;s Approach to Oracle]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://coskan.wordpress.com/2009/12/12/blogroll-report-24/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[74.200.245.179]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-12-12 21:04:56]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-12-12 19:04:56]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] 4-How does fast refresh of on-commit materialized views works on 11GR2? Alberto Dell&#8217;era-11gR2: new algorithm for fast refresh of on-commit materialized views  [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>138</wp:comment_id>
			<wp:comment_author><![CDATA[Joaquin]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[jogoca@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[195.235.8.54]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-12-17 19:03:24]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-12-17 17:03:24]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto,

It seems that materialized views are refreshed using only deletes and inserts, am I right? If that's true, then there's no reason for the pctfree of the materialized view to be not equal to zero, right?

Thank you!

Joaquin Gonzalez]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>139</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2009-12-17 20:27:24]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2009-12-17 18:27:24]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@Joaquin

for join-only MVs, that is, the kind of MV investigated in this post, sure. 

Anyway, I always check the actual algorithm using the actual SQL statement and the exact database version I am using for important MVs; better safe than sorry... you can easily adapt my test case for that purpose. 

I don't think that setting pctfree to zero is going to improve the performance too much - at most it might reduce the resource consumption of full table scans by 10%, which is not that much.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>138</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>140</wp:comment_id>
			<wp:comment_author><![CDATA[Taral Desai]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[taral.desai@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[173.18.210.145]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-01-06 07:14:45]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-01-06 05:14:45]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hello Alberto,

I have some problem with mv where i am using 10.2.0.4. I saw your trace file and in that it uses 

[sql]
Rows     Row Source Operation
-------  ---------------------------------------------------
      2  TABLE ACCESS BY INDEX ROWID TEST_T1 (cr=21 pr=0 pw=0 time=4362 us)
      5   NESTED LOOPS  (cr=20 pr=0 pw=0 time=4307 us)
      2    NESTED LOOPS  (cr=18 pr=0 pw=0 time=4217 us)
      3     VIEW  (cr=14 pr=0 pw=0 time=3887 us)
      3      HASH JOIN SEMI (cr=14 pr=0 pw=0 time=3865 us)
    100       TABLE ACCESS FULL TEST_T3 (cr=7 pr=0 pw=0 time=308 us)
      6       TABLE ACCESS FULL MLOG$_TEST_T3 (cr=7 pr=0 pw=0 time=105 us)
      2     TABLE ACCESS BY INDEX ROWID TEST_T2 (cr=4 pr=0 pw=0 time=120 us)
      2      INDEX RANGE SCAN TEST_T2_J2_3_IDX (cr=2 pr=0 pw=0 time=67 us)(object id 60236)
      2    INDEX RANGE SCAN TEST_T1_J1_2_IDX (cr=2 pr=0 pw=0 time=43 us)(object id 60230)


[/sql]

Hash join semi. Where i have problem uses hash  join right semi. What is different between them ? This i think is causing performace issue in my case

[sql]
Rows     Row Source Operation
-------  ---------------------------------------------------
      1  NESTED LOOPS  (cr=55325 pr=53317 pw=0 time=22980681 us)
      1   NESTED LOOPS  (cr=55324 pr=53317 pw=0 time=22980657 us)
      1    VIEW  (cr=55321 pr=53317 pw=0 time=22980562 us)
      1     HASH JOIN RIGHT SEMI (cr=55321 pr=53317 pw=0 time=22980548 us)
      2      TABLE ACCESS FULL MLOG$_S_R (cr=3 pr=0 pw=0 time=135 us)
8264128      TABLE ACCESS FULL S_R (cr=55318 pr=53317 pw=0 time=8272772 us)
      1    TABLE ACCESS BY INDEX ROWID SERVICE_REQUESTS (cr=3 pr=0 pw=0 time=86 us)
      1     INDEX UNIQUE SCAN xxxx_PK (cr=2 pr=0 pw=0 time=40 us)(object id 52121)
      1   INDEX UNIQUE SCAN PK_Sxxxxx (cr=1 pr=0 pw=0 time=12 us)(object id 87853)

call     count       cpu    elapsed       disk      query    current        rows
------- ------  -------- ---------- ---------- ---------- ----------  ----------
Parse        5      0.01       0.01          0          0          0           0
Execute      5     50.73      61.04     266390     276650         80           5
Fetch        0      0.00       0.00          0          0          0           0
------- ------  -------- ---------- ---------- ---------- ----------  ----------
total       10     50.74      61.06     266390     276650         80           5

[/sql]

Table and index name are changed due to policy. So, i think most time is spent on hash join right semi. Can you please guide me how to improve this]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>141</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[87.15.167.252]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-01-06 23:16:43]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-01-06 21:16:43]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@Taral

I concurr on the performance problem being the Hash Join; there your statement spends the vast majority of time (22980548 microseconds), that is almost completely CPU or unaccounted-for time (since the two child FTS accounts for only 135+8272772 microseconds). 

About the question about the semi-join, you have a SQL semi-join since a fragment of the statement used for the INS phase of the fast refresh is

select .. from test_t1 where rowid in ( select ... from mlog$_test_t1 )

There are (conceptually) two ways to calculate this fragment using an hash table:

a) load test_t1 as an hash table "in memory", then read mlog$_test_t1, and mark the rows in the hash table that match; then, return the marked rows

b) load mlog$_test_t1 as an hash table "in memory", then read test_t1; whenever a match occurs, return the row, and mark the hash table row as "already returned", and never return it again even if another match occurs [or, simply remove the row from the hash table].

I'm almost sure that (a) is how an "HASH JOIN SEMI" works, and (b) is how an "HASH JOIN RIGHT SEMI" works, even if I am only 95% sure right now. If that's true, in the common scenario where the log contains only a few rows and  the table a lot of rows (as it seems to be your case), (b) would seem to be the more efficient way (small hash table).

It would be interesting to compare two tkprofs of the fragment, one using (a) and another (b) (you can use the swap_join_inputs and no_swap_join_inputs to force one or another), and see whether it makes any difference.

Of course one would argue that the most efficient way to compute that fragment would be to get the table rows "pointed to" by the log rowids, thus avoiding a very expensive FTS, not by an expensive hash join. The hash join was chosen in my tests because the tables were tiny; in general, I do not expect that path to be chosen very often.

Might you check that the CBO was working with up-to-date information, by checking that
a) table S_R had up-to-date statistics collected
and
b) the log MLOG$_S_R had either up-to-date statistics or no statistics (both scenarios are possible).]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>140</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>142</wp:comment_id>
			<wp:comment_author><![CDATA[Taral Desai]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[taral.desai@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[173.18.210.145]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-01-07 08:03:38]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-01-07 06:03:38]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Thanks Sir for update and also explaining both things. As usual i learned many things from you today thank you for that. Now, coming to the issue this is actually a bug and i tested using the method provide in document 578720.1 and now it's using path

[sql]
call     count       cpu    elapsed       disk      query    current        rows
------- ------  -------- ---------- ---------- ---------- ----------  ----------
Parse        1      0.01       0.00          0          0          0           0
Execute      1      0.01       0.00          0          8          0           0
Fetch        0      0.00       0.00          0          0          0           0
------- ------  -------- ---------- ---------- ---------- ----------  ----------
total        2      0.02       0.01          0          8          0           0


Rows     Row Source Operation
-------  ---------------------------------------------------
      0  NESTED LOOPS  (cr=8 pr=0 pw=0 time=432 us)
      1   NESTED LOOPS  (cr=7 pr=0 pw=0 time=402 us)
      1    VIEW  (cr=4 pr=0 pw=0 time=269 us)
      1     NESTED LOOPS  (cr=4 pr=0 pw=0 time=265 us)
      1      SORT UNIQUE (cr=3 pr=0 pw=0 time=235 us)
      2       TABLE ACCESS FULL MLOG$_xxxx (cr=3 pr=0 pw=0 time=143 us)
      1      TABLE ACCESS BY USER ROWID S_XXXX (cr=1 pr=0 pw=0 time=23 us)
      1    TABLE ACCESS BY INDEX ROWID S_XXXX (cr=3 pr=0 pw=0 time=127 us)
      1     INDEX UNIQUE SCAN SXXXXX_PK (cr=2 pr=0 pw=0 time=55 us)(object id 52121)
      0   INDEX UNIQUE SCAN PK_S_XXXXX (cr=1 pr=0 pw=0 time=25 us)(object id 87853)
[/sql] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>143</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-01-07 11:25:26]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-01-07 09:25:26]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@Taral

thanks for coming back and letting me know about your solution.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>142</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>144</wp:comment_id>
			<wp:comment_author><![CDATA[The mess that is fast-refresh join-only Materialized Views | OraStory]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://orastory.wordpress.com/2014/11/27/the-mess-that-is-fast-refresh-join-only-materialized-views/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[76.74.255.29]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-11-27 17:24:13]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-11-27 15:24:13]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] http://www.adellera.it/blog/2009/11/22/11gr2-new-algorithm-for-fast-refresh-of-on-commit-materialize... [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>tweet ...</title>
		<link>http://www.adellera.it/blog/2010/01/06/tweet/</link>
		<pubDate>Wed, 06 Jan 2010 21:57:31 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=399</guid>
		<description></description>
		<content:encoded><![CDATA[For people that have asked - I'm not blogging simply because I'm feverishly working on a tool of mine that I'm very fond of :)

Guess what it does from the following next two screenshots ...

<img src="http://34.247.94.223/wp-content/uploads/2010/01/tool_lines2.bmp" alt="tool_lines2" title="tool_lines2" class="alignleft size-full wp-image-412" />

<img src="http://34.247.94.223/wp-content/uploads/2010/01/tool_prof1.bmp" alt="tool_prof1" title="tool_prof1" class="alignleft size-full wp-image-413" />]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>399</wp:post_id>
		<wp:post_date><![CDATA[2010-01-06 23:57:31]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2010-01-06 21:57:31]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[tweet]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[gundogar@gmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[absolutely@silence.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>145</wp:comment_id>
			<wp:comment_author><![CDATA[Taral Desai]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[taral.desai@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[207.108.42.8]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-01-07 18:20:17]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-01-07 16:20:17]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Waiting for tool]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>146</wp:comment_id>
			<wp:comment_author><![CDATA[taral]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://starttags.com/tags/taral</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[98.240.245.202]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-03-31 03:34:28]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-03-31 01:34:28]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...]     Alberto Dell'Era's Oracle blog tweet ...For people that have asked - I'm not blogging simply because I'm feverishly working on a tool of [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>xplan: dbms_metadata.get_ddl for tables referenced by the plan</title>
		<link>http://www.adellera.it/blog/2010/02/09/xplan-dbms_metadataget_ddl-for-tables-referenced-by-the-plan/</link>
		<pubDate>Tue, 09 Feb 2010 15:59:40 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=417</guid>
		<description></description>
		<content:encoded><![CDATA[As a minor but useful new feature, <a href="http://www.adellera.it/scripts_etcetera/xplan/index.html">xplan</a> is now able to integrate into its report the DDL of tables (and indexes) referenced by the plan, calling dbms_metadata.get_ddl transparently. 

This is mostly useful to get more details about referenced tables' constraints and partitions definition - to complement their CBO-related statistics that xplan reports about.

This feature can be activated by specifing dbms_metadata=y or dbms_metadata=all (check xplan.sql header of xplan.sql for more informations).

We spoke about xplan in general <a href="http://www.adellera.it/blog/2009/08/07/xplan-/">here</a>.]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>417</wp:post_id>
		<wp:post_date><![CDATA[2010-02-09 17:59:40]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2010-02-09 15:59:40]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[xplan-dbms_metadataget_ddl-for-tables-referenced-by-the-plan]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="performance-tuning"><![CDATA[performance tuning]]></category>
		<category domain="category" nicename="tools"><![CDATA[tools]]></category>
		<category domain="category" nicename="xplan"><![CDATA[xplan]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[development@husband.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>147</wp:comment_id>
			<wp:comment_author><![CDATA[oracle tables]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://starttags.com/tags/oracle-tables</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[66.77.232.66]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-03-05 06:32:42]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-03-05 04:32:42]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] ... the Configure Oracle 10g XE blog page and do so now, or use the Oracle APEX instructions ...Alberto Dell'Era's Oracle blog xplan: dbms_metadata.get_ddl ...As a minor but useful new feature, xplan is now able to integrate into its report the DDL of tables [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>fast refresh of join-only MVs: _mv_refresh_use_stats and locking log stats</title>
		<link>http://www.adellera.it/blog/2010/03/11/fast-refresh-of-join-only-mvs-_mv_refresh_use_stats-and-locking-log-stats/</link>
		<pubDate>Thu, 11 Mar 2010 20:46:16 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=426</guid>
		<description></description>
		<content:encoded><![CDATA[A devastating performance degradation of materialized view fast refreshes can happen in versions after 9i - and can be healed rather easily by simply setting the hidden parameter _mv_refresh_use_stats or, a bit surprisingly, by locking statistics on the logs. The problem can manifest at least in the currently-latest patchsets of 10g, 11gR1 and 11gR2 (10.2.0.4, 11.1.0.7 and 11.2.0.1), seems to hit a lot of people, and its root cause are the utilization of wrong hints by the Oracle refresh engine. 

We will investigate the join-only MV case only, since this is the case I have investigated after a question by <a href="http://www.pythian.com/news/author/kutrovsky/">Christo Kutrovsky</a>, factoring in some observations by Taral Desai and some Support notes; I have some clues that something similar may happen for other types of MVs.

The <a href="http://34.247.94.223/wp-content/uploads/2010/03/join_mv_use_stats_lock.zip">test case</a> sets up this very common scenario for fast refreshes:

1 - two big base tables joined together by the MV;
2 - only a small fraction of rows modified (actually one deleted, two updated, one inserted);
3 - all tables and indexes with fresh statistics collected;
4 - MV logs with no statistic collected AND with not-locked statistics;
5 - indexes present on the joined columns;
6 - indexes present on the rowid columns of the MV.

Points 1 and 2 make for the ideal scenario for incremental ("fast") refreshes to be effective; 3 is very common as well, since you normally have many other statements issued on the tables; the relevance of 4 will be clear later, but it happens very often in real life, since people might perhaps consider collecting stats on the log, but locking their statistics is usually not made, at least in my experience.

To understand the importance of points 5 and 6, please check <a href="http://www.adellera.it/blog/2009/08/04/fast-refresh-of-join-only-materialized-views-algorithm-summary/">this post of mine</a>; note how those indexes are a necessary prerequisite for the sanity of the DEL and INS steps of the MV process. Without them, the refresh cannot be incremental since it has no physical way to read and propagate only the modified rows and those related to them, but it must scan (uselessly) most of the base tables and MV. But in other for the refresh to be incremental ("fast"), those indexes have to be actually used...

<b>the issue</b>

Let's illustrate the issue focusing on the DEL step (the easier to discuss about). In the above mentioned post, we have seen that the DEL step uses a single SQL statement whose text, leaving out minor technical details <i>and hints</i>, is:
[sql]
/* MV_REFRESH (DEL) */ 
delete from test_mv 
 where test_t1_rowid in 
       (
select * from 
       (
select chartorowid (m_row$$)     
  from mlog$_test_t1   
 where snaptime$$ > :1 
       ) as of snapshot (:2) 
       )
[/sql]
In 9.2.0.8, we get this very healthy plan:
[text]
-------------------------------------------------
|Id|Operation             |Name                 |
-------------------------------------------------
| 0|DELETE STATEMENT      |                     |
| 1| DELETE               |                     |
| 2|  NESTED LOOPS        |                     |
| 3|   VIEW               |                     |
| 4|    SORT UNIQUE       |                     |
| 5|     TABLE ACCESS FULL|MLOG$_TEST_T1        |
| 6|   INDEX RANGE SCAN   |TEST_MV_TEST_T1_ROWID|
-------------------------------------------------
[/text]
That is: get the rowid of all modified rows from the log, and use the rowid-based index to delete the "old image" of them from the MV (inserting their "new image" is the job of the INS step). This is truly incremental, since the resource usage and elapsed time are proportional to the number of rows logged in the MV log, not to the dimension of the tables.

In 10.2.0.4, 11.1.0.7 and 11.2.0.1 the plan becomes:
[text]
------------------------------------------
|Id|Operation              |Name         |
------------------------------------------
| 0|DELETE STATEMENT       |             |
| 1| DELETE                |TEST_MV      |
| 2|  HASH JOIN RIGHT SEMI |             |
| 3|   TABLE ACCESS FULL   |MLOG$_TEST_T1|
| 4|   MAT_VIEW ACCESS FULL|TEST_MV      |
------------------------------------------
[/text]
Oops, the indexes are not used ... hence the DEL step overhead is proportional to the size of the MV, and that can be definitely unacceptable.

That is due to the engine injecting an HASH_SJ hint in the outermost nested subquery:
[text]
... WHERE "TEST_T1_ROWID" IN (SELECT /*+ NO_MERGE  HASH_SJ  */ ...
[/text]
This is recognized as a bug in many scenarios (start from Oracle Support note 578720.1 and follow the references to explore some of them) even if I have not found a clear and exhaustive note that documents the behaviour.

<b>remedy one: set "_mv_refresh_use_stats"</b>

To get back to the healthy plan, simply set "_mv_refresh_use_stats" to "true" (ask Oracle Support first of course for permission); this makes for a set of hint much more adequate for a fast refresh:
[text]
... WHERE "TEST_T1_ROWID" IN (SELECT /*+ NO_MERGE  NO_SEMIJOIN  */ ...
[/text]

Note: The root cause for this bug is probably due to a change hinted in note 875532.1 - in 10.2.0.3 the meaning of _mv_refresh_use_stats was reversed, but not the default, hence (by mistake?) activating a different piece of the engine code.

The very same problem happens for the INS step; I won't go into much details here (please check the test case spools provided above if interested), but in 9.2.0.8 the base table modified rows are directly fetched using the rowid contained in the log:
[text]
-----------------------------------------------------
|Id|Operation                      |Name            |
-----------------------------------------------------
| 0|INSERT STATEMENT               |                |
| 1| TABLE ACCESS BY INDEX ROWID   |TEST_T2         |
| 2|  NESTED LOOPS                 |                |
| 3|   VIEW                        |                |
| 4|    NESTED LOOPS               |                |
| 5|     VIEW                      |                |
| 6|      SORT UNIQUE              |                |
| 7|       TABLE ACCESS FULL       |MLOG$_TEST_T1   |
| 8|     TABLE ACCESS BY USER ROWID|TEST_T1         |
| 9|   INDEX RANGE SCAN            |TEST_T2_J2_1_IDX|
-----------------------------------------------------
[/text]
Instead, in 10.2.0.4, 11.1.0.7 and 11.2.0.1 we get the following plan:
[text]
--------------------------------------------------
|Id|Operation                   |Name            |
--------------------------------------------------
| 0|INSERT STATEMENT            |                |
| 1| TABLE ACCESS BY INDEX ROWID|TEST_T2         |
| 2|  NESTED LOOPS              |                |
| 3|   VIEW                     |                |
| 4|    HASH JOIN RIGHT SEMI    |                |
| 5|     TABLE ACCESS FULL      |MLOG$_TEST_T1   |
| 6|     TABLE ACCESS FULL      |TEST_T1         |
| 7|   INDEX RANGE SCAN         |TEST_T2_J2_1_IDX|
--------------------------------------------------
[/text]
Whose resource consumption is, of course, proportional to the size of the base table.

Even in this case, this is due to the nasty HASH_SJ hint:
[text]
... FROM "TEST_T1" "MAS$" WHERE ROWID IN (SELECT  /*+ HASH_SJ */  ...
[/text]

If you set _mv_refresh_use_stats, you get back the 9.2.0.8 plan - and thus you are back to incremental for both the DEL and INS steps. As a side note, a cardinality hint is used, where the cardinality is set to the correct value (6 in my test case):
[text]
... FROM "TEST_T1" "MAS$" WHERE ROWID IN (SELECT  /*+ CARDINALITY(MAS$ 6) NO_SEMIJOIN ...
[/text]
&nbsp;
<b>remedy two: collect and lock statistics on the logs</b>

Very interestingly, instead of setting the hidden parameter, you have another way to get back to the healthy plan: gather statistics on the MV logs when they are empty AND lock them (as suggested in note 578720.1, albeit not in this scenario and even if setting the parameter is not necessary; thanks to Taral Desai for pointing me to the note). In this case, no hint at all is injected beside a NO_MERGE for the DEL step:

[text]
... WHERE "TEST_T1_ROWID" IN (SELECT /*+ NO_MERGE  */ ...
... FROM "TEST_T1" "MAS$" WHERE ROWID IN (SELECT  ...
[/text]

So, the engine is confident that the CBO will come out with a good plan, and it does not inject any "intelligent" hint. Possibly, and intriguing, this is because by locking the statistics, I am assuring the engine that these statistics are representative of the data anytime. So, locking the statistics is not meant only as a way to prevent dbms_stats from changing them ... it is deeper than that. At least in this case, you are taking responsibility for them, and Oracle will take that in consideration. ]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>426</wp:post_id>
		<wp:post_date><![CDATA[2010-03-11 22:46:16]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2010-03-11 20:46:16]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[fast-refresh-of-join-only-mvs-_mv_refresh_use_stats-and-locking-log-stats]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="materialized-views"><![CDATA[materialized views]]></category>
		<category domain="category" nicename="performance-tuning"><![CDATA[performance tuning]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[who@low.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[circle@board.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>148</wp:comment_id>
			<wp:comment_author><![CDATA[Blogroll Report 05/02/2010 – 12/03/2010 &laquo; Coskan&#8217;s Approach to Oracle]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://coskan.wordpress.com/2010/04/23/blogroll-report-39/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[76.74.255.38]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-04-23 03:08:18]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-04-23 01:08:18]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] 19-How to sort performance degradation of materialized view fast refreshes on versions after 9i?  Alberto D&#8217;ellera-fast refresh of join-only MVs: _mv_refresh_use_stats and locking log stats [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>149</wp:comment_id>
			<wp:comment_author><![CDATA[Nathan Marston]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[marston.nathan@etsa.com.au]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[159.13.16.138]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2011-01-05 09:06:24]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2011-01-05 07:06:24]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[I ran a few followup tests to your article, as I was seeing similar issues with join-only fast refresh MVs containing outer joins.

(FYI, my tests were run on a Linux 2-node RAC running Oracle 11g).

It turns out that once you start using outer joins, only one of the two solutions provided in your article will remove the dreaded HASH_SJ hints from all queries generated by Oracle to perform the MV refresh.

The reason outer joins complicates things is the DML issued by Oracle to do the refresh changes when there's an outer join in the picture - in my tests, after some base table changes it actually issued an UPDATE against the MV which set the fields from the "outer" table to NULL. I couldn't tell from tkprof's output, but I'd guess that query would be issued in response to deleting a row from the table on the outer table.

Even with locked stats on the MV logs (which is the solution I wish worked all the time), that query still contained a HASH_SJ hint.

When I switched to setting "_mv_refresh_use_stats" instead, I found performance improved and the HASH_SJ hint no longer appeared in the refresh queries.

I can't see a good reason for *any* of the hints in those generated queries. Adding join and table access hints are almost always a bad idea - you're essentially saying you know something about the data that the CBO doesn't. 

In the case of MV logs that might be true - the number of rows in the MV log from refresh to refresh could vary a lot. If stats say MV log is small but it's actually big, the CBO won't generate the execution plan we want.

I can think of two responses to that argument:
1. Is a fast refresh MV really the appropriate tool if you have that much base table data changing? Why not refresh more frequently (to reduce the number of changes per refresh), or use full refreshes, or use something other than a MV?
2. If you really want to cater for both small and large MV logs, why not perform dynamic sampling on the MV logs and let the CBO do its job?]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>150</wp:comment_id>
			<wp:comment_author><![CDATA[FAST REFRESH w widokach zmaterializowanych &#8211; nie taki szybki ?! &laquo; Okiem bazodanowca]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://gdrzymala.wordpress.com/2011/05/07/fast-refresh-w-widokach-zmaterializowanych-nie-taki-szybki/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[66.135.48.233]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2011-05-07 15:36:31]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2011-05-07 13:36:31]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] Rozwiązanie problemu jest bardzo ładnie przedstawione na blogu Alberto Dell&#8217;Ery :  problem wolnego FAST REFRESH rozwiązany przez Alberto Pierwsza rzecz, która rzuca się w oczy &#8211; problem dotyczy tylko niektórych wersji Oracla. [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>151</wp:comment_id>
			<wp:comment_author><![CDATA[Don Seiler]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[don@seiler.us]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.seiler.us</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[174.53.161.160]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-08-14 15:02:43]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-08-14 13:02:43]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto,

What about gathering real stats on the mview log immediately before the fast refresh?

I have an interesting case from this weekend with an mv using a join. MV log for 1 table always has 0 rows. When the 2nd table had over 229K rows, fast refresh finished in less than 9 minutes. The next fast refresh saw the 2nd table with only 5K rows, but it took over an hour to complete. Looking for a definite root cause and workaround so it doesn't happen again :p]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>152</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-08-21 13:53:40]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-08-21 11:53:40]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Don,

sorry that I haven't answered sooner, but I was on vacation ...

Possibly the performance degraded because it had to propagate the deletion of 224K(=229K-5K) rows to the MV in the DEL step - in which case a complete refresh would have been better ...

Yes in general, gathering stats on the MV log (and master tables and their indexes) - should make the CBO happier - as well as locking the stats on the MV log if you see the problem described in this post. 

After analyzing the MV logs, you could check the stats to decide whether to refresh using the FAST or COMPLETE option - it is something I'm actually considering for one project of mine :)]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>151</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>153</wp:comment_id>
			<wp:comment_author><![CDATA[daniesh shaikh]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[daniesh.shaikh@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[175.100.162.155]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-01-08 13:06:56]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-01-08 11:06:56]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto,

Thanks for this post. this is very helpful for me as i am working on MV performance since 1 month. I created a MV by joining 4 tables out of which one table(gl_balances) size is more than 20GB.GL_balances and GL_code_combinations tables are partition by range. I ran the fast refresh which takes more than 1 hr. I can see that the del query is hash join semi. In my case the parameter _mv_refresh_use_stats is set to true.

SQL&gt; show parameter _mv_refresh_use_stats

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
_mv_refresh_use_stats                boolean     TRUE


Plan Hash: 4021631375
DELETE FROM "APPS"."GLBAL_MV1" SNA$ 
WHERE
 "C2" IN (SELECT /*+ NO_MERGE  */ * FROM (SELECT  
  CHARTOROWID("MAS$"."M_ROW$$") RID$     FROM "GL"."MLOG$_GL_BALANCES" "MAS$" 
    WHERE "MAS$".SNAPTIME$$ &gt; :B_ST2 ) AS OF SNAPSHOT(:B_SCN) MAS$) 


call     count       cpu    elapsed       disk      query    current        rows
------- ------  -------- ---------- ---------- ---------- ----------  ----------
Parse        1      0.00       0.01          0          0          0           0
Execute      1    420.66    1428.79   10564633   10634970     758532      635919
Fetch        0      0.00       0.00          0          0          0           0
------- ------  -------- ---------- ---------- ---------- ----------  ----------
total        2    420.66    1428.80   10564633   10634970     758532      635919

Misses in library cache during parse: 1
Misses in library cache during execute: 1
Optimizer mode: ALL_ROWS
Parsing user id: 175  (APPS)   (recursive depth: 1)

Rows     Row Source Operation
-------  ---------------------------------------------------
      0  DELETE  HDFC_REP_GL_TRIAL_BAL_DAN_MV1 (cr=10635012 pr=10564636 pw=0 time=0 us)
 635919   HASH JOIN RIGHT SEMI (cr=10634968 pr=10564428 pw=0 time=1400861312 us cost=9744568 size=148 card=1)
 674212    TABLE ACCESS BY INDEX ROWID MLOG$_GL_BALANCES (cr=10462 pr=2469 pw=0 time=736435 us cost=1 size=138 card=1)
 674212     INDEX RANGE SCAN MLOGSNAP (cr=5610 pr=2469 pw=0 time=273282 us cost=2 size=0 card=1)(object id 2112025)
404672870    MAT_VIEW ACCESS GL_BAL_MV1 (cr=10624506 pr=10561959 pw=0 time=980955008 us cost=9744566 size=4047014600 card=404701460)

I checked with mv_capabilities that the MV is eligible for fast refresh.

Please suggest why the mv is still using hash join after setting the parameter to true. My db version is 11.2.0.1. Please suggest as i am trying to improve the performance of MV last more than 30 days.

Thanks]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>154</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-01-09 12:11:40]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-01-09 10:11:40]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Daniesh,

does an index on table GL_BAL_MV1(C2) column exist, and are its index statistics fresh ?

The index must have C2 as its first column.

Also check the columns stats of C2 ... must be fresh as well.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>153</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>155</wp:comment_id>
			<wp:comment_author><![CDATA[daniesh]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[daniesh.shaikh@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[116.203.65.141]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-01-10 20:24:30]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-01-10 18:24:30]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto,

This is very helpful. I learned a lot from you.

After creating the index on C2 col now the Mv refresh del query is running fine i can see the performance has improved. Now i see the problem with ins query. Index is  impacting the performance of insert query. Is there any way so than Mv refresh should not use index during ins statement.

Please suggest.

Thanks]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>156</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-01-11 20:09:38]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-01-11 18:09:38]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Daniesh,

no, you can't disable the index during the INS phase, since it happens straight after DEL under the control of the refresh procedure, and you can't get control back in the middle.

It seems strange, anyway, that a simple index might affect INS performances that much; have you indexed the joined columns in the BASE tables as well ? 

Also, I have noticed that rows from your MV log are fetched using a custom index MLOGSNAP; this is USUALLY inefficient and could be avoided. That kind of index is useful only if you have a lot of empty blocks in the MV log table, because a previous "outlier" refresh grew it to a very large HWM (say, 30 times as the normal size at least) - if that's not the case, and hence the MV log is more or less the same size for every refresh, the index is just overhead and it is better dropped. 

First thing you might try is to collect fresh stats on the MV log before the refresh and check whether the CBO skips the index, improving performance at least for the INS step.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>155</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>157</wp:comment_id>
			<wp:comment_author><![CDATA[daniesh]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[daniesh.shaikh@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[175.100.162.155]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-01-12 08:04:14]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-01-12 06:04:14]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto,

Thanks,

We can see that the del query which took 1428.80 seconds last time.It took 556.15 seconds after creating the index on C2.
call     count       cpu    elapsed       disk      query    current        rows
------- ------  -------- ---------- ---------- ---------- ----------  ----------
Parse        1      0.00       0.01          0          0          0           0
Execute      1     65.92     556.14     372581    1480763    5879720      636184
Fetch        0      0.00       0.00          0          0          0           0
------- ------  -------- ---------- ---------- ---------- ----------  ----------
total        2     65.92     556.15     372581    1480763    5879720      636184

MLOGSNAP index is created on SNAPTIME$$ of MLOG$_GL_BALANCES tables.

call     count       cpu    elapsed       disk      query    current        rows
------- ------  -------- ---------- ---------- ---------- ----------  ----------
Parse        1      0.01       0.02          0          0          0           0
Execute      1     62.33     451.38     386122    3829213    2166450      636184
Fetch        0      0.00       0.00          0          0          0           0
------- ------  -------- ---------- ---------- ---------- ----------  ----------
total        2     62.34     451.41     386122    3829213    2166450      636184

Misses in library cache during parse: 1
Misses in library cache during execute: 1
Optimizer mode: ALL_ROWS
Parsing user id: 175  (APPS)   (recursive depth: 1)

Rows     Row Source Operation
-------  ---------------------------------------------------
      0  LOAD TABLE CONVENTIONAL  (cr=3829603 pr=386128 pw=0 time=0 us)
 636184   NESTED LOOPS  (cr=3719922 pr=43313 pw=0 time=100880216 us)
 636184    NESTED LOOPS  (cr=3083737 pr=21824 pw=0 time=48839680 us cost=6 size=325 card=1)
 636184     NESTED LOOPS  (cr=2653648 pr=15136 pw=0 time=27271778 us cost=4 size=223 card=1)
 636184      NESTED LOOPS  (cr=2016739 pr=15131 pw=0 time=21884716 us cost=3 size=175 card=1)
 636184       VIEW  (cr=1379832 pr=15130 pw=0 time=16619372 us cost=2 size=145 card=1)
 636184        NESTED LOOPS  (cr=1379832 pr=15130 pw=0 time=15831465 us cost=2 size=198 card=1)
 636184         SORT UNIQUE (cr=1357666 pr=5686 pw=0 time=751081 us cost=0 size=138 card=1)
 674932          TABLE ACCESS BY INDEX ROWID MLOG$_GL_BALANCES (cr=1357666 pr=5686 pw=0 time=9713998 us cost=0 size=138 card=1)
 674932           INDEX RANGE SCAN MLOGSNAP (cr=677872 pr=4489 pw=0 time=6187752 us cost=0 size=0 card=1)(object id 2112025)
 636184         TABLE ACCESS BY USER ROWID GL_BALANCES PARTITION: ROW LOCATION ROW LOCATION (cr=22166 pr=9444 pw=0 time=0 us cost=1 size=60 card=1)
 636184       TABLE ACCESS BY INDEX ROWID GL_SETS_OF_BOOKS (cr=636907 pr=1 pw=0 time=0 us cost=1 size=30 card=1)
 636184        INDEX UNIQUE SCAN GL_SETS_OF_BOOKS_U2 (cr=723 pr=0 pw=0 time=0 us cost=0 size=0 card=1)(object id 33648)
 636184      TABLE ACCESS BY INDEX ROWID GL_PERIODS (cr=636909 pr=5 pw=0 time=0 us cost=1 size=48 card=1)
 636184       INDEX UNIQUE SCAN GL_PERIODS_U2 (cr=725 pr=3 pw=0 time=0 us cost=0 size=0 card=1)(object id 33612)
 636184     INDEX UNIQUE SCAN GL_CODE_COMBINATIONS_U11 (cr=430089 pr=6688 pw=0 time=0 us cost=1 size=0 card=1)(object id 2110687)
 636184    TABLE ACCESS BY GLOBAL INDEX ROWID GL_CODE_COMBINATIONS PARTITION: ROW LOCATION ROW LOCATION (cr=636185 pr=21489 pw=0 time=0 us cost=2 size=102 card=1)

last time ins query took 2 mins. this time it took around 451  seconds.
I will refresh the statistics on MV log and run one  more load and update you.

Thanks]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>158</wp:comment_id>
			<wp:comment_author><![CDATA[Gaetano]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[bortgae@iol.it]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[93.61.40.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-01-18 13:15:34]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-01-18 11:15:34]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto,


I ask  information about how run the refresh materialized views to type fast on commit.


I have a DB Spatial composed of 25 regional themes that presents many common columns, which often must be interrogated by region and theme.
I created a table with a spatial column geometric t_element_common_det with  range partition  (id_themes_fk, id_region_fk) with PK Id_seqn.
Each themes then presents specific attributes, really few columns.I created a table for each thematic t_themes_n with (WITH n from 1 to 25) with PK Id_seqn,
t_themes_n.Id_seqn with FK to t_element_common_det.id_seqn.

Now to get the complete alphanumeric data of each themes I created a join-only MV for each theme,
partitioned by region with fast refresh on commit.
Each MV is created as follows:

[sql] 
CREATE MATERIALIZED VIEW MV_themes_14
partition by range (id_region_fk)
(
..
)
BUILD IMMEDIATE
REFRESH FAST ON COMMIT with rowid
AS
SELECT e.column_1,
       e.column_2,
       ....
       t.column_1,
       t.column_2,
       t.rowid rowid_theme,
       e.rowid rowid_ele
  FROM T_themes_14 T,
       T_element_common_det
WHERE T.ID_SEQN = E.ID_SEQN
  AND E.ID_themes_FK = 14 -- id_themes_fk
[/sql] 

Now the problem is in performance.In select there is no problem, but I have problems in insert or Update.
For example, if I update a record on t_themes_14 okay (time of 3 of seconds), while if the upgrade t_element_common_det for a record with
id_themes_fk = 14 I have performance problems because if I update / delete a record it takes between 60/90 seconds.
I analized the trace file I changed only a recordupdate a record on t_themes_14 Oracle upgrade on all MV_themes_n (I have 25 themes....)
Performs tasks such as:
[sql] 
/ * MV_REFRESH (DEL) * /
DELETE FROM &quot;REGISTER&quot;. &quot;MV_themes_8&quot; SNA $
 WHERE &quot;ROWID_ELE&quot; IN
       (SELECT / * + NO_MERGE HASH_SJ * /
         *
          FROM (SELECT CHARTOROWID (&quot;MAS $&quot;. &quot;M_ROW $ $&quot;) $ RID
                  FROM &quot;REGISTER&quot;. &quot;MLOG $ _t_element_common_det&quot; &quot;MAS $&quot;
                 WHERE &quot;MAS $&quot;. XID = $ $: 1) $ MAS)

/ * MV_REFRESH (INS) * /
INSERT INTO &quot;REGISTER&quot;. &quot;MV_themes_8&quot;
  SELECT / * + NO_MERGE (&quot;JV $&quot;) * /
   &quot;JV $&quot;. &quot;ID_SEQN&quot;
   &quot;JV $&quot;. &quot;ID_themes_FK&quot;
   .......
   &quot;MAS $ 1&quot;. ROWID,
   &quot;JV $&quot;. &quot;$ RID&quot;
    FROM (SELECT &quot;MAS $&quot;. &quot;ROWID&quot; &quot;RID $&quot;, &quot;MAS $&quot;. *
            FROM &quot;REGISTER&quot;. &quot;t_element_common_det&quot; &quot;MAS $&quot;
           WHERE ROWID IN (SELECT / * + HASH_SJ * /
                            CHARTOROWID (&quot;MAS $&quot;. &quot;M_ROW $ $&quot;) $ RID
                             FROM &quot;REGISTER&quot;. &quot;MLOG $ _t_element_common_det&quot; &quot;MAS $&quot;
                            WHERE &quot;MAS $&quot;. XID $ $ =: 1)) &quot;JV $&quot;
         &quot;T_themes_8&quot; AS SNAPSHOT OF (: B_SCN) &quot;MAS $ 1&quot;
   WHERE &quot;MAS $ 1&quot;. &quot;ID_SEQN&quot; = &quot;JV $&quot;. &quot;ID_SEQN&quot;
     AND &quot;JV $&quot;. &quot;ID_ELEMENTO_FK&quot; = 8
[/sql] 

Now my question is: Is there a way to set to refresh the materialized views regarding t_element_common_det, if you upadte a record
the t_element_common_det with ID_themes_FK = 14 to refresh only on MV_themes_14 and not all Materialized view?
Any other suggestions are welcome.

Thanks in advance.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>159</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-01-18 20:26:27]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-01-18 18:26:27]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Gaetano,

I haven't really understood how the two table rows are related - do you have a 1:1 match between the themes_N and the  t_element_common_det, or a 1:N, or a N:1 ?

Partitioning is irrelevant by the way; probably even the fact that the table has a spatial-type column is irrelevant.

Do you have these four indexes defined ? 
t_themes_N(rowid_theme)
t_element_common_det(rowid_ele)
t_themes_N(id_seqn)
t_element_common_det(id_seqn,id_themes_fk)  (or the opposite order)
Note: probably some of them are created by the PK constraints; just check that they exist and are valid]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>158</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>160</wp:comment_id>
			<wp:comment_author><![CDATA[The mess that is fast-refresh join-only Materialized Views | OraStory]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://orastory.wordpress.com/2014/11/27/the-mess-that-is-fast-refresh-join-only-materialized-views/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[192.0.82.67]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-11-28 15:28:03]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-11-28 13:28:03]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] http://www.adellera.it/blog/2010/03/11/fast-refresh-of-join-only-mvs-_mv_refresh_use_stats-and-locki... [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>161</wp:comment_id>
			<wp:comment_author><![CDATA[Yogendra]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[pahariayogi@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[5.67.197.36]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2015-04-04 04:14:32]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2015-04-04 02:14:32]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto, Thanks for sharing this info. we faced the same nasty HASH_SJ hint issue with MV FAST REFRESH (with OUTER JOIN though) on 11.2.0.3

Unfortunately, both of remedies did NO work for us on 11.2.0.3 

Oracle Doc ID 1949537.1 suggests that setting the hidden _mv_refresh_use_hash_sj parameter to FALSE should prevent it using that hint.

[sql]alter session set &quot;_mv_refresh_use_hash_sj&quot;=FALSE;  [/sql]

That stopped CBO using the HASH_SJ hint.

Posting it here in the interests of others.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>162</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[93.33.135.136]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2015-04-04 10:19:33]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2015-04-04 08:19:33]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Yogendra, 
many thanks! 
Nice to know that there is an underscore parameter specifically introduced to solve this issue, probably since 11.2.0.2 according to the note  ;)]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>161</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>163</wp:comment_id>
			<wp:comment_author><![CDATA[Jasmin]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[jasooty@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[115.111.176.13]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2016-08-31 14:43:03]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2016-08-31 12:43:03]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto

We have a scenario in my project, the same scenario you have explained in another post
"For example, consider the typical case of a parent table (say, CUSTOMER), with a child (say, ORDER) and a grandchild (say, ORDER_LINE); if you update a column of a row of the parent (say, ORDERS_TOTAL_AMOUNT), the parent row and its whole progeny (the "slice") will be deleted and then recreated."

The child table is just to get one column, where we are not expecting much updates, but due to the delete based on the Child table key, lot many tables in the MV is getting deleted and then recreated. Which is going for hours.
Is there any way we can restrict the mv refresh (del)  from the child tables MV log?]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>164</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[93.33.142.118]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2016-09-02 12:49:33]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2016-09-02 10:49:33]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Jasmin,

none that I'm aware of ... it's built in the algorithm. 

You might try 12c, I haven't studied that version yet...

ciao
Alberto]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>163</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>165</wp:comment_id>
			<wp:comment_author><![CDATA[DANISH]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[mailtodanish@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[125.18.177.97]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2017-06-20 11:03:08]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2017-06-20 09:03:08]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[I have two Materialized View based on join tables. S_CONTACT table is used in both Materialized view. If I am refreshing first Materialized view. Will it refresh S_CONTACT Data of second materialized view as well without refreshing second MV?]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>166</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[213.156.34.234]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2017-06-30 11:19:04]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2017-06-30 09:19:04]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Damish,

of course not; if you want to refresh all the MVs that depend on S_CONTACT, you might try invoking dbms_mview.refresh_dependent() on it - something I don't like doing since I prefer to control exactly what I'm working on.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>165</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>9108</wp:comment_id>
			<wp:comment_author><![CDATA[https://500px.com/paulinaandini94]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[latonya_tan@arcor.de]]></wp:comment_author_email>
			<wp:comment_author_url>https://500px.com/paulinaandini94</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[196.247.224.30]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2019-10-06 23:20:39]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2019-10-06 22:20:39]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Excellent way of telling, and pleasant paragraph to get data 
regarding my presentation focus, which i am going to deliver in university.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1570400439.1721439;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:3:{s:4:"time";d:1598802484.8507979;s:5:"event";s:15:"status-approved";s:4:"user";s:15:"alberto.dellera";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>10534</wp:comment_id>
			<wp:comment_author><![CDATA[gia xe o to]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[javierbracegirdle@aol.com]]></wp:comment_author_email>
			<wp:comment_author_url>https://medium.com/%40blogmycar</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[192.3.195.115]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2019-12-26 10:25:44]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2019-12-26 09:25:44]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[I used to be suggested this blog by means of my cousin. I'm no longer positive whether 
this publish is written through him as nobody else recognise such specified about 
my trouble. You are wonderful! Thank you!]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1577352344.7057209;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:3:{s:4:"time";d:1598802483.9128561;s:5:"event";s:15:"status-approved";s:4:"user";s:15:"alberto.dellera";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>84802</wp:comment_id>
			<wp:comment_author><![CDATA[Officer]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[Annetta5@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://Practical%20Cotton%20Chair</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[31.220.3.148]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2020-12-11 15:03:07]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2020-12-11 14:03:07]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Pizza]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1607695387.8709559;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>104249</wp:comment_id>
			<wp:comment_author><![CDATA[open architecture]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[travisadams32@yahoo.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://Auto%20Loan%20Account</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[185.220.101.208]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-02-10 20:12:08]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-02-10 19:12:08]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Public-key]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1612984328.5081861;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>127310</wp:comment_id>
			<wp:comment_author><![CDATA[Unbranded Concrete Bike]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[dianelipson@yahoo.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://interface</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[185.107.70.202]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-04-12 17:52:39]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-04-12 16:52:39]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[French Southern Territories]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1618246359.0899169;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					</item>
					<item>
		<title>Xtrace: an Oracle session trace browser (introduction)</title>
		<link>http://www.adellera.it/blog/2010/04/08/xtrace-an-oracle-session-trace-browser-introduction/</link>
		<pubDate>Thu, 08 Apr 2010 16:23:17 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=435</guid>
		<description></description>
		<content:encoded><![CDATA[<a href="http://www.adellera.it/xtrace">Xtrace</a> is a graphical tool that can navigate Oracle trace files, manipulate them, and optionally get them back as a text file. It actually makes (much) more, but in this first post we are going to focus on its basic browsing capabilities.

Let’s see the tool in action on the trace file produced by this simple PL/SQL block:
[sql]
begin
  for r in (select * from t) loop
    null;
  end loop;
end;
[/sql]

The resulting trace file is 
[text wraplines="false" gutter="false"]
WAIT #2: nam='SQL*Net message from client' ela= 61126 driver id=1413697536 #bytes=1 p3=0 obj#=76357 tim=5789636384898
=====================
PARSING IN CURSOR #26 len=66 dep=0 uid=73 oct=47 lid=73 tim=5789636385129 hv=3421439103 ad='aeb809c8'
begin
  for r in (select * from t) loop
    null;
  end loop;
end;
END OF STMT
PARSE #26:c=0,e=153,p=0,cr=0,cu=0,mis=0,r=0,dep=0,og=1,tim=5789636385122
BINDS #26:
=====================
PARSING IN CURSOR #28 len=15 dep=1 uid=73 oct=3 lid=73 tim=5789636386184 hv=1406298530 ad='a0503300'
SELECT * FROM T
END OF STMT
PARSE #28:c=0,e=804,p=0,cr=0,cu=0,mis=1,r=0,dep=1,og=1,tim=5789636386181
BINDS #28:
EXEC #28:c=0,e=64,p=0,cr=0,cu=0,mis=0,r=0,dep=1,og=1,tim=5789636386284
WAIT #28: nam='db file sequential read' ela= 19 file#=4 block#=59 blocks=1 obj#=76357 tim=5789636386383
WAIT #28: nam='db file sequential read' ela= 11 file#=4 block#=60 blocks=1 obj#=76357 tim=5789636386457
FETCH #28:c=0,e=243,p=2,cr=3,cu=0,mis=0,r=100,dep=1,og=1,tim=5789636386566
FETCH #28:c=0,e=54,p=0,cr=1,cu=0,mis=0,r=100,dep=1,og=1,tim=5789636386663
FETCH #28:c=0,e=3,p=0,cr=0,cu=0,mis=0,r=0,dep=1,og=1,tim=5789636386693
EXEC #26:c=0,e=1543,p=2,cr=4,cu=0,mis=0,r=1,dep=0,og=1,tim=5789636386746
WAIT #26: nam='SQL*Net message to client' ela= 2 driver id=1413697536 #bytes=1 p3=0 obj#=76357 tim=5789636387057
WAIT #26: nam='SQL*Net message from client' ela= 42743 driver id=1413697536 #bytes=1 p3=0 obj#=76357 tim=5789636429824
STAT #28 id=1 cnt=200 pid=0 pos=1 obj=76357 op='TABLE ACCESS FULL T (cr=4 pr=2 pw=0 time=363 us)'
[/text]
Even for this artificially simple trace file, it takes a lot of effort to read and understand it; for example, it takes a while to associate the recursive SQL lines to the execution of the PL/SQL blocks (the “EXEC #26” line).

With Xtrace, the trace reading experience is remarkably much better:
<img src="http://34.247.94.223/wp-content/uploads/2010/04/xtrace_hello_10_2_0_4_lines.gif">
<script type="text/javascript" src="http://www.java.com/js/deployJava.js"></script>
<script type="text/javascript">
        // you can enable tracing using the "Java Control Panel"; in Windows is inside the "Control Panel"
        // check "http://www.java.com/js/deployJava.txt" for code of deployJava.js
        // using JavaScript to get location of JNLP file relative to HTML page
        var dir = location.href.substring(0, location.href.lastIndexOf('/')+1);
        var url =  "http://www.adellera.it/xtrace/dist/xtrace_hello_10_2_0_4.jnlp";
        // following requires Java SE 6 update 18, downloads it automatically
        // minimumVersion is of the form #[.#[.#[_#]]]
        //deployJava.createWebStartLaunchButtonEx(url, '1.6.0_18'); DOES NOT WORK starting from 6u19
        deployJava.createWebStartLaunchButton(url);
</script>
Note the indentation by recursive level (which is provided out-of-the -box) and the color of the lines by statement (that takes perhaps a minute in order to be set up).
You can try this example live by pressing the “Launch” button above if you are interested;  in particular, try the “Options” button of the middle pane, and the “set color” popup menus of the top pane.  

Suggestion: you might even check the hyperlinks that links together the lines; for example, the xct pointer that links the SQL recursive calls to the parent “EXEC #26” (check the <a href="http://www.adellera.it/xtrace/manual/xtrace_manual.html ">interactive manual</a> for more information).

You can also get the trace back as a text file, if so desired:
[text wraplines="false" gutter="false"]
000 line zero
001 xtrace: log file 'E:\localCVS30\TrilogyLectures\MioSitoWeb\xtrace\dist\xtrace.log'
002 VIRTUAL CALL #-4: 'null call - ignore this'
003 VIRTUAL CALL #-4: 'null call - ignore this'
004 +WAIT #2: nam='SQL*Net message from client' xe=ela=61126 p1='driver id'=1413697536 p2='#bytes'=1 p3=''=0 xphy=0 obj#=76357 tim=5789636384898
005 VIRTUAL CALL #-8: 'wait-for-client'
006 VIRTUAL CALL #-5: 'client-message-received'
007 ---------------------PARSING IN CURSOR #26: len=66 dep=0 uid=73 oct=47 lid=73 tim=5789636385129 hv=3421439103 ad='0eb809c8'
    begin
      for r in (select * from t) loop
        null;
      end loop;
    end;
    END OF STMT
008 PARSE #26: mis=0 r=0 dep=0 og=1 tim=5789636385122 e=153 c=0 p=0 cr=0 cu=0
009 BINDS #26:
010   ---------------------PARSING IN CURSOR #28: len=15 dep=1 uid=73 oct=3 lid=73 tim=5789636386184 hv=1406298530 ad='00503300'
      SELECT * FROM T
      END OF STMT
011   PARSE #28: mis=1 r=0 dep=1 og=1 tim=5789636386181 e=804 c=0 p=0 cr=0 cu=0
012   BINDS #28:
013   EXEC  #28: mis=0 r=0 dep=1 og=1 tim=5789636386284 e=64 c=0 p=0 cr=0 cu=0
014   +WAIT #28: nam='db file sequential read' xe=ela=19 p1='file#'=4 p2='block#'=59 p3='blocks'=1 xphy=1 obj#=76357 tim=5789636386383
015   +WAIT #28: nam='db file sequential read' xe=ela=11 p1='file#'=4 p2='block#'=60 p3='blocks'=1 xphy=1 obj#=76357 tim=5789636386457
016   FETCH #28: mis=0 r=100 dep=1 og=1 tim=5789636386566 e=243 c=0 p=2 cr=3 cu=0
017   FETCH #28: mis=0 r=100 dep=1 og=1 tim=5789636386663 e=54 c=0 p=0 cr=1 cu=0
018   FETCH #28: mis=0 r=0 dep=1 og=1 tim=5789636386693 e=3 c=0 p=0 cr=0 cu=0
019 EXEC  #26: mis=0 r=1 dep=0 og=1 tim=5789636386746 e=1543 c=0 p=2 cr=4 cu=0
020 -WAIT #26: nam='SQL*Net message to client' xe=ela=2 p1='driver id'=1413697536 p2='#bytes'=1 p3=''=0 xphy=0 obj#=76357 tim=5789636387057
021 +WAIT #26: nam='SQL*Net message from client' xe=ela=42743 p1='driver id'=1413697536 p2='#bytes'=1 p3=''=0 xphy=0 obj#=76357 tim=5789636429824
022 VIRTUAL CALL #-8: 'wait-for-client'
023 VIRTUAL CALL #-5: 'client-message-received'
024   STAT  #28: id=1 pid=0 pos=1 obj=76357 op='TABLE ACCESS FULL T' cnt=200 avg(cnt)=200.0 card=n/a cr=4 avg(cr)=4.0 cost=n/a pr=2 pw=0 time=363 size=n/a xnexecs=1 xstatn=0 xplannum=0
025  
026 VIRTUAL CALL #-4: 'null call - ignore this'
[/text]
This can be obtained using the “save as text“ popup menu of the middle pane.

We are going to keep exploring Xtrace in the upcoming posts.]]></content:encoded>
		<excerpt:encoded><![CDATA[<a href="http://www.adellera.it/xtrace">Xtrace</a> is a graphical tool that can navigate Oracle trace files, manipulate them, and optionally get them back as a text file. It actually makes (much) more, but in this first post we are going to focus on its basic browsing capabilities.]]></excerpt:encoded>
		<wp:post_id>435</wp:post_id>
		<wp:post_date><![CDATA[2010-04-08 18:23:17]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2010-04-08 16:23:17]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[xtrace-an-oracle-session-trace-browser-introduction]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="xtrace"><![CDATA[xtrace]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_syntaxhighlighter_encoded]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[traci_l_rivers_hsij42@yahoo.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[aliandrea73@yahoo.it]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>167</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; Xtrace: an Oracle session trace browser &#8211; exec flow]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2010/05/17/xtrace-an-oracle-session-trace-browser-exec-flow/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-05-17 16:21:16]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-05-17 14:21:16]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] introduced Xtrace in this post; the Xtrace home page contains the tool (which can be used online or downloaded) - and a manual for [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>168</wp:comment_id>
			<wp:comment_author><![CDATA[Kamus]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[kamusis@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.dbform.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[117.79.69.90]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-05-23 05:08:55]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-05-23 03:08:55]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[But ... How can I use this utility to open a specified log file? I just double click it and it opens an ora11gr2_ora_2776_xtrace_exec_flow_11_2_0_1.trc for me? why?]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>169</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[87.15.201.69]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-05-23 11:25:49]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-05-23 09:25:49]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[@Kamus

That's because you clicked on the "launch" button on the "exec flow" post, a button that is designed to browse the file I used as an example in the post.

If you want to process your own file, try clicking on the "launch" button on the main page:
http://www.adellera.it/xtrace/
(also linked as the "xtrace" tab above)

and the tool will ask you to select a trace file as input.

Another option, perhaps less convenient: download xtrace.jar from the main page, and then, from the command line:
java -jar xtrace.jar mytracefile.trc]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>168</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>170</wp:comment_id>
			<wp:comment_author><![CDATA[Blogroll Report 02/04 /2010 &#8211; 09/04/2010 &laquo; Coskan&#8217;s Approach to Oracle]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://coskan.wordpress.com/2010/07/19/blogroll-report-43/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[74.200.247.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2010-07-19 15:41:49]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2010-07-19 13:41:49]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] 9-XTRACE session trace browser to browse in a tracefile  Alberto Dell&#8217;era-Xtrace: an Oracle session trace browser (introduction) [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>171</wp:comment_id>
			<wp:comment_author><![CDATA[Satheesh]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[satheesh.nagaraj@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[24.13.160.156]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-07-01 22:02:07]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-07-01 20:02:07]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Thanks for providing such a great tool. I tried to use the tool for my trace file but it is getting failed with below error. Could you please suggest how to fix it

java.lang.NumberFormatException: For input string: "1844674406941641933000"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Long.parseLong(Unknown Source)
	at java.lang.Long.parseLong(Unknown Source)
	at xtrace.e.k.b(Unknown Source)
	at xtrace.e.k.m(Unknown Source)
	at xtrace.e.k.q(Unknown Source)
	at xtrace.e.k.b(Unknown Source)
	at xtrace.e.i.b(Unknown Source)
	at xtrace.Xtrace.main(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at com.sun.javaws.Launcher.executeApplication(Unknown Source)
	at com.sun.javaws.Launcher.executeMainClass(Unknown Source)
	at com.sun.javaws.Launcher.doLaunchApp(Unknown Source)
	at com.sun.javaws.Launcher.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>172</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-07-10 15:48:47]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-07-10 13:48:47]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Satheesh,

please send me the trace file at alberto.dellera@gmail.com, so that I can investigate the issue

thanks
Alberto]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>171</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>An improved OakTable web site</title>
		<link>http://www.adellera.it/blog/2010/04/23/an-improved-oaktable-web-site/</link>
		<pubDate>Fri, 23 Apr 2010 14:48:43 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=441</guid>
		<description></description>
		<content:encoded><![CDATA[Today the new OakTable web site, <a href="http://www.oaktable.net">www.oaktable.net</a>, has been published: many thanks to <a href="http://www.ora600.be/">Kurt Van Meerbeeck</a> (that I'm told worked the most on the site), <a href="http://jamesmorle.wordpress.com/">James Morle</a> and <a href="http://www.liberidu.com/blog/">Marco Gralike</a>!

I really like (besides the light and modern look) the aggregator of the OakTable members' blogs - a window on high-quality news and investigations about Oracle ...]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>441</wp:post_id>
		<wp:post_date><![CDATA[2010-04-23 16:48:43]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2010-04-23 14:48:43]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[an-improved-oaktable-web-site]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
						</item>
					<item>
		<title>Xtrace: an Oracle session trace browser - exec flow</title>
		<link>http://www.adellera.it/blog/2010/05/17/xtrace-an-oracle-session-trace-browser-exec-flow/</link>
		<pubDate>Mon, 17 May 2010 14:21:06 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=448</guid>
		<description></description>
		<content:encoded><![CDATA[Tracing a session is extremely useful when you need to investigate how  a client interacts with the database - the client could be an application of yours, a third-party application, or an Oracle module such as dbms_stats or dbms_mview.  To get the perfect picture of the client-server dialogue,  you "simply" need to consider all EXEC lines in the trace file, and associate to each line the executed statement and the bind variable values; a very tedious and error-prone task  when done manually, that <a href="http://www.adellera.it/xtrace">Xtrace</a>  can make for you (and for free).

Let's see the tool in action. Consider tracing a call to this stored procedure, that executes a recursive SQL statement : 
[sql]
create or replace procedure test_proc( p_x int )
is
begin
  for i in 1..p_x loop
    for k in (select count(*) from t where x &gt; i) loop
      null;
    end loop;
  end loop;
end; 
[/sql]
Here  is the output of Xtrace:
<img src="http://34.247.94.223/wp-content/uploads/2010/05/xtrace_exec_flow_11_2_0_1_lines_no_binds.gif">
Reading it bottom-up, you can see that the client called the SP, which in turn executed recursively (note the indentation) the SQL statement twice.  

You can also ask Xtrace to display the bind variable values used for each execution:
<img src="http://34.247.94.223/wp-content/uploads/2010/05/xtrace_exec_flow_11_2_0_1_lines_with_binds.gif">
So - the client passed the value "2" for :p_x to the SP, which in turn executed the SQL statement first passing  "1" for :B1,  and  then passing "2". 

Interested ? Try it live  (requires Java Web Start):
<script type="text/javascript" src="http://www.java.com/js/deployJava.js"></script>
<script type="text/javascript">
        // you can enable tracing using the "Java Control Panel"; in Windows is inside the "Control Panel"
        // check "http://www.java.com/js/deployJava.txt" for code of deployJava.js
        // using JavaScript to get location of JNLP file relative to HTML page
        var dir = location.href.substring(0, location.href.lastIndexOf('/')+1);
        var url =  "http://www.adellera.it/xtrace/dist/xtrace_exec_flow_11_2_0_1.jnlp";
        // following requires Java SE 6 update 18, downloads it automatically
        // minimumVersion is of the form #[.#[.#[_#]]]
        //deployJava.createWebStartLaunchButtonEx(url, '1.6.0_18'); DOES NOT WORK starting from 6u19
        deployJava.createWebStartLaunchButton(url); 
</script>
When Xtrace opens up, press the "options" button and then the "EXEC FLOW analysis" button.  Enable/disable the bind variable values using the "display BINDS under EXEC" checkbox; color the statements as you like.

We introduced Xtrace in <a href="http://www.adellera.it/blog/2010/04/08/xtrace-an-oracle-session-trace-browser-introduction/">this post</a>; the <a href="http://www.adellera.it/xtrace">Xtrace home page</a> contains the tool (which can be used online or downloaded) - and a manual for advanced uses.]]></content:encoded>
		<excerpt:encoded><![CDATA[Tracing a session is extremely useful when you need to investigate how  a client interacts with the database - the client could be an application of yours, a third-party application, or an Oracle module such as dbms_stats or dbms_mview.  To get the perfect picture of the client-server dialogue,  you "simply" need to consider all EXEC lines in the trace file, and associate to each line the executed statement and the bind variable values; a very tedious and error-prone task  when done manually, that <a href="http://www.adellera.it/xtrace">Xtrace</a>  can make for you (and for free).]]></excerpt:encoded>
		<wp:post_id>448</wp:post_id>
		<wp:post_date><![CDATA[2010-05-17 16:21:06]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2010-05-17 14:21:06]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[xtrace-an-oracle-session-trace-browser-exec-flow]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="xtrace"><![CDATA[xtrace]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_syntaxhighlighter_encoded]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[will.hoffman.it89@lycos.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>173</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; refresh &#8220;fast&#8221; of materialized views optimized by Oracle as &#8220;complete&#8221;]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2012/09/16/refresh-fast-of-materialized-views-optimized-by-oracle-as-complete/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-09-16 18:49:17]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-09-16 16:49:17]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] test case .zip above - including of course spool files and traces, the latter also processed with xtrace exec flow to quickly mine the SQL statements of [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>Tom Kyte in Italia - 5 Aprile 2011</title>
		<link>http://www.adellera.it/blog/2011/05/01/tom-kyte-in-italia-5-aprile-2011/</link>
		<pubDate>Sun, 01 May 2011 15:38:08 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=467</guid>
		<description></description>
		<content:encoded><![CDATA[[<i>Note: I'm writing in Italian since this post is about a local event</i>] <br/>
Anche quest'anno Thomas "Tom" Kyte, il "Tom dietro <a href=" http://asktom.oracle.com ">asktom.oracle.com</a>" e autore di diversi libri, è tornato in Italia per tenere una delle sue conferenze ricorrenti più popolari (ecco le <a href="http://asktom.oracle.com/pls/asktom/z?p_url=ASKTOM%2Edownload_file%3Fp_file%3D11017632703950282679&p_cat=Rome_Milan.zip&p_company=822925097021874">slides</a>) - quella sulle features più significative della versione corrente di Oracle (quindi 11gR2 al momento). <br/>
Non avevo mai visto Tom sul palco nonostante ci conoscessimo da tempo, per cui ho approfittato subito della gentile offerta dell'Ufficio Stampa Oracle di incontrarlo a valle della conferenza - un'incontro che si è trasformato in una lunga informale chiacchierata di due ore (insieme a  <a href=" http://antognini.ch/blog ">Christian Antognini</a>) cominciata a pranzo e continuata sul taxi. Oltre al piacere di parlare con Tom (sempre molto disponibile e amichevole) ne ho tratto diverse informazioni e impressioni che espongo in ordine sparso. <br/>
<b>La conferenza in generale</b>. L'aspetto che meglio descrive Tom Kyte, come chiunque abbia avuto modo di leggere uno dei suoi libri può intuire,  è di essere una perfetta  (quanto rarissima) sintesi fra un ottimo tecnico ed un efficace comunicatore:  e difatti, dalla conferenza ho ricavato una conoscenza molto più netta e chiara delle features presentate, anche se già le conoscevo.  Mi sono dunque pentito di non aver partecipato alle conferenze degli anni passati - sarebbe stato un ottimo investimento del mio tempo ... <br/>
<b>Total Recall (Flashback Data Archive)</b>. A mio parere è la killer feature di 11g (era già presente in 10g ma i miglioramenti in 11g riguardo al supporto di molti tipi di DDL sulle tabelle tracciate la rendono nettamente più usabile): poter eseguire una query nel passato (anche anni) semplicemente aggiungendo la clausola "AS OF TIMESTAMP" può davvero "cambiare la vita", sia agli sviluppatori che ai DBA. Basti solo pensare alle investigazioni di problemi segnalati oggi ma verificatosi giorni addietro, al ripristino dei dati a fronte di errori, etc. Uno degli usi che voglio indagare è l'estrazione di dati dai sistemi operazionali verso i DWH; a prima vista è più efficiente (e senz'altro infinitamente più manutenibile e generalizzabile) delle classiche tecniche utilizzate. Importantissimo poi sapere come le history tables delle tabelle tracciate vengano aggiornate leggendo le informazioni dagli undo segments, dunque senza impatti sul tempo di esecuzione degli statements DML operanti sulle tabelle tracciate. Total Recall è anche una delle extra-cost options più economiche. <br/>
<b>Smart Flash Cache</b>. L'informazione cruciale è che il disco a stato solido ("SSD" o "Flash") della Flash Cache viene usato solo per i blocchi clean, quelly dirty vengono scritti solo sui datafile: quindi solo sistemi il cui bottleneck sono le letture da disco possono trarne beneficio. <br/>
La mia impressione  è che il suo uso più interessante sia di rendere disponibile memoria veloce per la nuova feature "In-Memory Parallel Execution" (che permette di leggere blocchi nella buffer cache invece che solo nella UGA del processo); sarebbe interessante verificarlo. <br/>
<b>Edition-based Redefinition</b>. Certamente è possibile usare questa feature per installare nuove versioni sia dei dati (tabelle con colonne nuove, etc) che del software (package, stored procedures), ma mentre il primo caso è relativamente complesso da gestire, il secondo è semplicissimo - c'è un baratro nella difficoltà d'uso nei due casi. Quindi ritengo che salvo casi particolarissimi (in sistemi con requisiti di altissima disponibilità, gestiti da personale molto preparato, e con alti budget), questa feature troverà uso diffuso "solo" nel secondo caso. Forse era voluto che la demo della conferenza fosse incentrata proprio sul secondo caso ... <br/>
<b>Kernel Programmers</b>. Non faceva parte della conferenza, ma gentilmente Tom ha soddisfatto alcune mie curiosità riguardo il kernel di Oracle. Ho così scoperto che vengono seguite delle coding covention strettissime che sono un poco difficili da comprendere inizialmente, ma che permettono a chiunque sia membro del team di leggere e modificare agevolmente il codice (scritto in C ovviamente) del kernel. Inoltre, per entrare a far parte del Team (o meglio di uno dei Team) che lavorano sul kernel, o si è brillantissimi laureati di Università di primo piano, oppure si proviene dall'interno dell'azienda e dunque si è già conosciuti come ottimi professionisti. Ed ovviamente (ma questo è noto), prima di introdurre una nuova feature,  questa viene descritta dettagliatamente in appositi documenti ed  analizzata per rilevanza  e fattibilità con un preciso flusso decisionale. Insomma, un ambiente di lavoro rigorosissimo ed estremamente professionale - un tipo di ambiente ormai raro oggigiorno, ma certamente al cuore del successo di Oracle. <br/>
<b>Conclusione</b>. Queste erano le mie considerazioni principali, che ovviamente riflettono i miei interessi e le mie necessità professionali. Per il futuro, mi ripropongo di partecipare più spesso alle conferenze tenute da Oracle Italia - sono sempre state utili e di alta qualità, con un approccio "americano" : tanti fatti, poche chiacchiere, e impostati sulle necessità di chi ascolta.
]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>467</wp:post_id>
		<wp:post_date><![CDATA[2011-05-01 17:38:08]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2011-05-01 15:38:08]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[tom-kyte-in-italia-5-aprile-2011]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="social-events"><![CDATA[Social Events]]></category>
		<category domain="category" nicename="technical-meetings"><![CDATA[Technical Meetings]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[bethany-mckee-gnm97@aol.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[vern.a.mullins.tlg56@rocketmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[madgenburksvyi90@mail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[earline-i-fry-xsw43@aol.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[barbara-l-pitts-av81@hotmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>174</wp:comment_id>
			<wp:comment_author><![CDATA[Donatello Settembrino]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[donatello.settembrino@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.97.16.34]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2011-05-03 10:07:13]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2011-05-03 08:07:13]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Ciao Alberto,
sono rimasto molto soddisfatto anch'io dell'evento, molto intenso
e ricco di spunti. Condivido il tuo pensiero, credo
questo sia un ottimo modo di investire il proprio tempo.
Ho avuto modo di vedere Thomas Kyte dal vivo per la prima volta
ed apprezzarne doti tecniche e comunicative.
Quel giorno è stata un'esperienza molto positiva, 
tral'altro ho avuto modo di incontrare anche Christian Antognini 
e fare una chiacchierata con lui.


Saluti

Donatello Settembrino]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>175</wp:comment_id>
			<wp:comment_author><![CDATA[Log Buffer #219, A Carnival of the Vanities for DBAs | The Pythian Blog]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.pythian.com/news/22581/log-buffer-219-a-carnival-of-the-vanities-for-dbas/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[174.143.243.63]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2011-05-08 14:19:46]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2011-05-08 12:19:46]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] Alberto Dellera informs us that the top Oracle celebrity Tom Kyte is visiting the beautiful Italia. Wow starts in Italy now. [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>Third International NoCOUG SQL &amp; NoSQL Challenge!</title>
		<link>http://www.adellera.it/blog/2012/05/28/third-international-nocoug-sql-nosql-challenge/</link>
		<pubDate>Mon, 28 May 2012 11:09:02 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=478</guid>
		<description></description>
		<content:encoded><![CDATA[For anyone into using their SQL skills creatively, and getting out of the boring SQL-coding daily routine ... here is a puzzle that is both entertaining and challenging, and with a real prize for the winner! 

Official abstract:
"In <a href="http://bit.ly/JvJS46">this challenge</a> (see page 25), the Wicked Witch of the West needs help in creating a magic spell to ensure that the Third Annual Witching & Wizarding Ball is a grand success. The winner will receive the August Order of the Wooden Pretzel in keeping with the Steven Feuerstein’s observation that "some people can perform seeming miracles with straight SQL, but the statements end up looking like pretzels created by somebody who is experimenting with hallucinogens." There are currently four knights of the August Order of the Wooden Pretzel: Alberto Dell’Era (Italy) who won the <a href="http://bit.ly/heUb1T">first challenge</a> in 2009 and Andre Araujo (Australia), Rob van Wijk (Netherlands), and Ilya Chuhnakov (Russia) who won the <a href="http://bit.ly/NoCOUG-SQL-Challenge-2">second challenge</a> in 2011."   

I remember having a lot of fun when I joined the first edition of this Challenge - I hope the same for you :)]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>478</wp:post_id>
		<wp:post_date><![CDATA[2012-05-28 13:09:02]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2012-05-28 11:09:02]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[third-international-nocoug-sql-nosql-challenge]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="uncategorized"><![CDATA[Uncategorized]]></category>
						<wp:comment>
			<wp:comment_id>176</wp:comment_id>
			<wp:comment_author><![CDATA[Log Buffer #274, A Carnival of the Vanities for DBAs | The Pythian Blog]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.pythian.com/news/33551/log-buffer-274-a-carnival-of-the-vanities-for-dbas/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[174.143.243.63]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-06-01 09:01:47]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-06-01 07:01:47]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] into using their SQL skills creatively, and getting out of the boring SQL-coding daily routine, Alberto Dell&#8217;Era has an [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>Xplan: now with &quot;self&quot; measures for row source operations</title>
		<link>http://www.adellera.it/blog/2012/08/27/xplan-now-with-self-measures-for-row-source-operations/</link>
		<pubDate>Mon, 27 Aug 2012 10:21:04 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=493</guid>
		<description></description>
		<content:encoded><![CDATA[One of the most useful information that the Oracle kernel attaches to plans in the library cache are measures of various resource consumption figures, such as elapsed time, consistent and current gets, disk reads, etcetera. These can be made available for each plan line (aka "row source operation").

These figures are always cumulative, that is, include both the resource consumed by the line itself and all of its progeny. It is very often extremely useful to <i>exclude</i> the progeny from the measure, to get what we could name the "self" figure (following, of course, the terminology introduced by Cary Millsap and Jeff Holt in their famous book <a href="http://www.amazon.com/Optimizing-Oracle-Performance-Cary-Millsap/dp/059600527X">Optimizing Oracle Performance</a>).

My sqlplus script <a href="http://www.adellera.it/scripts_etcetera/xplan">xplan</a>  now implements the automatic calculation of the "self" for the most important measures, including elapsed time and buffer gets, the most used ones when tuning a statement. 

Let's see an example, and then elaborate on their most important application: as a resource profile when tuning.

<b>A simple example</b>
Here's an illustrative example for the measure "elapsed time":
[sql light="true"]
---------------------------------------------------
|Ela    |Ela+    |Id|Operation                    |
-last----last--------------------------------------
|801,097|       =| 0|SELECT STATEMENT             |
|801,097| +79,017| 1| HASH JOIN                   |
|673,010|+262,274| 2|  TABLE ACCESS BY INDEX ROWID|
|410,736| 410,736| 3|   INDEX FULL SCAN           |
| 49,070|  49,070| 4|  TABLE ACCESS FULL          |
-usec----usec--------------------------------------
[/sql]
The first column ("Ela"), whose values are read straight from v$sql_plan_statistics, is the cumulative elapsed time of each row source operation and all its progeny (children, grandchildren, etc). Hence for example, you can see that line#1 (HASH JOIN) run for 801msec, including the time spent by line #2,3,4 (its progeny). 

The second column ("Ela+") is the corresponding "self" column, derived from "Ela" by subtracting the time spent by the children - line#1 has two children (#2 and #4), and hence we get 801-673-49=79msec.

<b>Self measures as a resource profile for the plan</b> 
Having the "self" measures available makes extremely easy to identify the most expensive row source operations, which are (usually) the first worth considering when tuning (or studying) a SQL statement. Actually, the "self" set <i>is</i> the resource profile of the plan: it blames each consumer  (here, the plan lines) for its share of the resource consumed.

For example, line#3 is the most expensive with its  410 msec worth of time - if we are lucky and can reduce its time consumption almost to zero, we would cut the consumption of the whole statement by (about) 50%. It is definitely a line on which to invest some of our tuning time - by e.g. investigating whether a predicate failed to being pushed down; try building a more optimal (e.g. smaller) index; try hinting it into a "FAST FULL SCAN", etc etc. 

The second best option for tuning is line#2, a "TABLE ACCESS BY INDEX ROWID"... maybe we could eliminate it completely by adding the fetched columns at the end of the index read by line#3, thus possibly saving 262msec (about 25%) of time. 

And so on. 

I have found these "self" figures extremely useful in <i>all</i> my recent tuning projects - I hope that the same could turn true for some of you, and maybe that you could suggest me some way to improve xplan :)
]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>493</wp:post_id>
		<wp:post_date><![CDATA[2012-08-27 12:21:04]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2012-08-27 10:21:04]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[xplan-now-with-self-measures-for-row-source-operations]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="cbo"><![CDATA[CBO]]></category>
		<category domain="category" nicename="performance-tuning"><![CDATA[performance tuning]]></category>
		<category domain="category" nicename="xplan"><![CDATA[xplan]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_syntaxhighlighter_encoded]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[fayexwalterde75@yahoo.ca]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[marjoriechristianmh02@msn.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[pauline_snow_lvi41@lycos.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>177</wp:comment_id>
			<wp:comment_author><![CDATA[Galo Balda]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[galo.balda@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[167.137.1.14]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-08-27 15:51:30]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-08-27 13:51:30]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Nice post Alberto. Good to have you back.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>178</wp:comment_id>
			<wp:comment_author><![CDATA[Jagjeet Singh]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[jagjeet.malhi@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://jagjeet.wordpress.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[59.177.209.135]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-08-28 09:26:29]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-08-28 07:26:29]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Nice, Thanks for sharing.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>179</wp:comment_id>
			<wp:comment_author><![CDATA[Max]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[abdulirfan33@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[12.1.219.177]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-11-19 17:53:00]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-11-19 15:53:00]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto,

i recently came across you blog and started using the XPLAN script.  While playing around with it, i noticed the "self" measure output dose not show up in my output.  Going thru your header of xplan, looks like self=y is the default behaviour and still do not get any output for ela/ela+...

my DB version is 11.2.0.3(hp-ux itanium) and my client is 11.2.0.1(win 7).... here is how i ran your script by passing the sql_id

@xplan "" "sql_id=92kcxp7m7n2sk"

also tried
@xplan "" "sql_id=92kcxp7m7n2sk" "self=y"

i am also trying to make my output smaller by getting rid of table info by saying tabinfos=n and still dose not work...maybe i am doing something wrong...here is what i am trying for that

@xplan "" "sql_id=92kcxp7m7n2sk" "tabinfos=n"]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>180</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-11-19 18:50:32]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-11-19 16:50:32]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Max,

ela is calculated by the kernel only if statistics_level is set to "all", or if the corresponding hint is specified; have you checked this ?

Try it for your session:
alter session set statistics_level=all;

the correct syntax for specifying more than one option is using a comma-separated list, for example:

@xplan "%" "sql_id=xxxxxxxxxxx,tabinfos=n,objinfos=n"

Bonus: you can specify ti and oi for tabinfos and objinfos, respectively

Happy XPLAnning ;)]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>179</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>181</wp:comment_id>
			<wp:comment_author><![CDATA[Max]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[abdulirfan33@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[12.1.219.177]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-11-19 19:19:08]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-11-19 17:19:08]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Thank you Sir for prompt response.

Looks like statistics_level is set to typical at DB level.  and obviously setting statistics_level=all at session level is not going to help me get info for other SQL_ID running in my system.  So my question to you is, are there any bad implication of setting statistics_level=all at DB level.  If so what are those.

Also how is the SQL Monitor in OEM getting that same info(elapsed time for each step) with statistics_level=typical.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>182</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.7]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-11-19 19:33:37]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-11-19 17:33:37]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[statististics_level=all means more resource consumption (CPU especially) to calculate the stats. Before 11g it was also expensive due to the increased number of system OS calls to get the time difference; in 11g that is managed (afaik) by the VKTM process and hence is less expensive. Hence, I wouldn't recommend setting it instance-wise in production without testing first.

I don't know how OEM Sql Monitor is able to do that - unless of course for sessions that have run with the parameter set to all.

Anyway, if ela is set in v$plan_statistics_all, XPLAN will display it alongside ela+ ; it just displays what it finds ...

ciao
Al]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>181</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>183</wp:comment_id>
			<wp:comment_author><![CDATA[Max]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[abdulirfan33@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[12.1.219.177]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-11-19 19:36:07]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-11-19 17:36:07]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Awesome and Thanks for sharing this with the community.

God Bless you and your Family.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>184</wp:comment_id>
			<wp:comment_author><![CDATA[Alex]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alex.9.iving@gsk.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[152.51.56.1]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-03-23 03:04:29]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-03-23 01:04:29]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Alberto,
I tried your xplan script for the first time. It doesn't work for me. I'm always getting 'no statement found'.  I'm using  10.2.0.5 client and i tried the following immediately after running SQL:

@xplan "sql_id=ghu0r7nfv8h3p"
@xplan "SELECT%NIKU%"
@xplan "parsed_by=dba_ora"

Non of them worked.

Regards,
Alex]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>185</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[151.64.131.134]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-03-23 11:46:16]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-03-23 09:46:16]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Alex,

you syntax is wrong, it should be

@xplan "" "sql_id=ghu0r7nfv8h3p"
@xplan "SELECT%NIKU%" ""
@xplan "" "parsed_by=dba_ora"

you can find documentation for xplan in the header of the main script (xplan.sql) and a detailed showcase in http://www.adellera.it/scripts_etcetera/xplan/index.html

ciao
Alberto]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>184</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>186</wp:comment_id>
			<wp:comment_author><![CDATA[Alex]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alex.9.iving@gsk.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[152.51.56.1]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-03-23 20:55:01]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-03-23 18:55:01]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Alberto,

Thanks a lot. Now it is working.

Regards,
Alex]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>187</wp:comment_id>
			<wp:comment_author><![CDATA[Neto]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[neto.longhi@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[200.186.48.101]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2015-11-24 16:19:51]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2015-11-24 14:19:51]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi ALberto,
the script does not works in Oracle 10g? right?]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>188</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[151.37.91.54]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2015-11-25 20:50:18]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2015-11-25 18:50:18]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[It should, but I haven't checked it for a long time, neither I have a 10g instance handy at the moment. Could you please send the error to alberto.dellera@gmail.com? Thanks]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>187</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>refresh &quot;fast&quot; of materialized views optimized by Oracle as &quot;complete&quot;</title>
		<link>http://www.adellera.it/blog/2012/09/16/refresh-fast-of-materialized-views-optimized-by-oracle-as-complete/</link>
		<pubDate>Sun, 16 Sep 2012 16:49:14 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=513</guid>
		<description></description>
		<content:encoded><![CDATA[In my current "big" project, I am building a network of nested materialized views to transform rows of  one schema into rows of another (very different) schema. The former is used by the old (but still live) version of an application of ours, the latter by the new version; our idea is to incrementally (aka "fast") refresh the network daily in order to have the new schema ready when the new version goes live. We need this nework because we have only a few hours of allowed downtime, and the transformations are very complex: the MV network is going to be composed of at least 200+ MVs, each containing tens of millions of rows.<br/>
We have carefully  designed all MVs as fast refreshable, and built a simple PL/SQL engine to refresh them in parallel using Oracle jobs; we are hence sure that we can meet our time constraints. Now I'm looking at optimizing the COMPLETE refresh, both for damage limitation (should some MVs required to be refreshed as complete, due to corruption or recreation mandated by to last-minute functional changes) and to speed up the initial network build. <br/>
One of the optimization I was thinking about was to refresh as complete any MV whose masters have been completely refreshed before, since it is common knowledge that in this case, "complete" is much faster then "fast" (pardon the pun) - mostly because using the MV log to identify  modified rows is far from cheap and it's a huge, useless overhead when ALL rows have been modified. But actually I don't need to worry, since I have discovered that in this case, Oracle <i>silently</i> turns the fast refresh into a complete one, at least in 11.2.0.3. <br/>
The <a href=" http://34.247.94.223/wp-content/uploads/2012/09/mv_fast_becomes_complete.zip ">test case</a> (script mv_fast_becomes_complete.sql) builds a chain of three MVs:
[sql light="true"]
create table dellera_t ..
create materialized view dellera_mv1 .. as select .. from dellera_t;
create materialized view dellera_mv2 .. as select .. from dellera_mv1;
create materialized view dellera_mv3 .. as select .. from dellera_mv2;
[/sql]
Then the test case modifies some rows of the master table and asks for fast refresh:
[sql light="true"]
exec dbms_mview.refresh('dellera_mv1', method=&gt;'f', atomic_refresh =&gt; true);
exec dbms_mview.refresh('dellera_mv2', method=&gt;'f', atomic_refresh =&gt; true);
exec dbms_mview.refresh('dellera_mv3', method=&gt;'f', atomic_refresh =&gt; true);
[/sql]
It's no surprise that we get:
[sql light="true"]

SQL&gt; select mview_name, last_refresh_type from user_mviews 
where mview_name like 'DELLERA%' order by mview_name;
MVIEW_NAME           LAST_REFRESH_TYPE                                                                                                                
-------------------- ------------------------                                                                                                         
DELLERA_MV1          FAST                                                                                                                         
DELLERA_MV2          FAST                                                                                                                         
DELLERA_MV3          FAST                                                                                                                         
[/sql]
But, when the test case refreshes the first alone as complete, keeping the next ones as fast:
[sql light="true"]
exec dbms_mview.refresh('dellera_mv1', method=&gt;'c', atomic_refresh =&gt; true);
exec dbms_mview.refresh('dellera_mv2', method=&gt;'f', atomic_refresh =&gt; true);
exec dbms_mview.refresh('dellera_mv3', method=&gt;'f', atomic_refresh =&gt; true);
[/sql]
We get:
[sql light="true"]
MVIEW_NAME           LAST_REFRESH_TYPE                                                                                                                
-------------------- ------------------------                                                                                                         
DELLERA_MV1          COMPLETE                                                                                                                         
DELLERA_MV2          COMPLETE                                                                                                                         
DELLERA_MV3          COMPLETE    
[/sql]
Hence, our request for fast has been silently turned by Oracle into a complete refresh, for all MVs down the chain. By the way, I have verified that this is true also for join-only and aggregates-only Mvs (check the test case if interested):  all it takes to trigger this silent optimization is that at least one master has been completely refreshed before.<br/>
Moreover, the trace file shows the following steps, for the fast-turned-complete refresh of dellera_mv2 (edited for readability):
[sql light="true"]
a) update mlog$_dellera_mv1  set snaptime$$ = :1  where ...; 
b) delete from dellera_mv2;
c) delete from mlog$_dellera_mv2;
d) insert into dellera_mv2 (m_row$$, x , y , rid#) 
select rowid,x,y,rowid from dellera_mv1;
e) delete from mlog$_dellera_mv1 where snaptime$$ &lt;= :1;
[/sql]
This is indeed the signature of a complete refresh: a complete delete (b) of the refreshing MV (dellera_mv2) followed by a straight insert (d) from the master (dellera_mv1), with no visit of the MV log of the master besides the usual initial marking (a) and the final purge (e).
What is also interesting is that the MV log is completely (no reference to snaptime$$) deleted in (c) BEFORE the insert; insertion that does not populate the MV log since the kernel trigger is "disabled" during a complete refresh (otherwise we would find a lot of rows in the log since the delete happens before and not after, but the script verifies that no row is found). No MV log management overhead, as expected.<br/>
It's also interesting to check what changes when the refresh is done with atomic => false (NB I have skipped table-locking and index-maintenance operations, and non pertinent hints, for brevity):
[sql light="true"]
a) same as above
b) same as above
c) truncate table dellera_mv2 purge snapshot log;
d) insert /*+ append */ into dellera_mv2 (m_row$$, x , y , rid#) 
select rowid,x,y,rowid from dellera_mv1;
e) same as above
[/sql]
That is, the delete has turned into a "truncate purge snapshot log" and the insert is now running in append mode, the rest is the same. In passing, (b) looks a tad redundant.<br/>
As always, you can find all scripts in the test case .zip above - including of course spool files and traces, the latter also processed with <a href="http://www.adellera.it/blog/2010/05/17/xtrace-an-oracle-session-trace-browser-exec-flow/">xtrace exec flow</a> to quickly mine the SQL statements of interest. 

]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>513</wp:post_id>
		<wp:post_date><![CDATA[2012-09-16 18:49:14]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2012-09-16 16:49:14]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[refresh-fast-of-materialized-views-optimized-by-oracle-as-complete]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="materialized-views"><![CDATA[materialized views]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_syntaxhighlighter_encoded]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>189</wp:comment_id>
			<wp:comment_author><![CDATA[Uwe Hesse]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[uwe.hesse@oracle.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://uhesse.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[193.9.13.133]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2012-09-17 11:15:49]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2012-09-17 09:15:49]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[That is all to your best - even when we don't talk about it :-)
Thank you for publishing this fine bit of research about MV fast refresh, turning into complete refresh under the covers, Alberto! Keep up the good work &amp;
Kind regards
Uwe]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>overlapping ranges with priority</title>
		<link>http://www.adellera.it/blog/2012/10/01/overlapping-ranges-with-priority/</link>
		<pubDate>Mon, 01 Oct 2012 08:54:57 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=529</guid>
		<description></description>
		<content:encoded><![CDATA[A customer of ours (a leading Italian consumer goods retailer) has asked us to solve the following  problem, that occurs quite frequently and that is not trivial to solve efficiently - and that is very interesting to design and fun to blog about! </br>
<b>the problem</b>
Prices of <a href="http://en.wikipedia.org/wiki/Stock-keeping_unit">sku</a>s (i.e. goods) have validity ranges (time intervals) and can overlap;  on an overlapping range, the strongest priority  (lower number) wins. In pictures:
<pre>
b---(0,$200)---d
          c---(1,$300)---e
</pre></br>
the expected output is, since priority 0 is stronger then 1:
<pre>
b----($200)----d---($300)---e
</pre></br>
I'm going to illustrate in detail the pure-SQL algorithm I have designed, and then discuss about its performance and efficiency. As usual, everything I discuss is supported by an <a href="http://34.247.94.223/wp-content/uploads/2012/09/overlapping_ranges_with_priority.zip">actual demo</a>. Please note that the algorithm uses analytics functions very, very heavily.</br>
<b>pure SQL solution</b>
The input table:
[sql light="true"]
create table ranges (
  sku   varchar2(10) not null,
  a     int not null,
  b     int not null,
  prio  int not null,
  price int not null
);
alter table ranges add constraint ranges_pk primary key (sku, a, b);
[/sql]
Let's provide the opening example as input:
[sql light="true"]  
insert into ranges(sku, a, b, prio, price) values ('sku1', ascii('b'), ascii('d'), 0, 200);
insert into ranges(sku, a, b, prio, price) values ('sku1', ascii('c'), ascii('e'), 1, 300);
[/sql]
The algorith is implemented as a single view; let's comment each step and show its output over the example:
 [sql light="true"]  
create or replace view ranges_output_view
as
[/sql]
The instants in time where the ranges start or begin:
 [sql light="true"]  
with instants as (
  select sku, a as i from ranges
  union
  select sku, b as i from ranges
), 
[/sql]
Output: b,c,d,e. </br>
The base ranges, i.e. the consecutive ranges that connect all the instants:
[sql light="true"]  
base_ranges as (
  select *
    from (
  select sku, 
         i as ba,
         lead(i) over (partition by sku order by i) as bb 
    from instants
         )
   where bb is not null 
), 
[/sql]
<pre> b------c------d------e </pre></br>
The original ranges factored over the base ranges; in other words, "cut" by the instants:
[sql light="true"]  
factored_ranges as (
  select i.sku, bi.ba, bi.bb, i.a, i.b, i.prio, i.price
    from ranges i, base_ranges bi 
   where i.sku = bi.sku
     and (i.a &lt;= bi.ba and bi.ba &lt; i.b)  
), 
[/sql]
<pre>
b---(0,$200)---c---(0,$200)---d
               c---(1,$300)---d---(1,$300)---e
</pre></br>
Then, let's filter out the factored ranges with weaker priority (that have a stronger priority range with the same extremes "covering" them):
[sql light="true"]  
strongest_factored_ranges as (
  select sku, ba, bb, prio, price 
    from (
  select sku, ba, bb, prio, price,
         dense_rank () over (partition by sku, ba, bb order by prio) as rnk
    from factored_ranges
         )
   where rnk = 1
), 
[/sql]
<pre>
b---(0,$200)---c---(0,$200)---d---(1,$300)---e
</pre></br>
The problem could be now considered solved, if you could live with consecutive intervals showing the same price (such as b--c and c--d above). If you can't for whatever reason (I couldn't), we can join them using analytics again in a way similar to this <a href=" http://www.oracle.com/technetwork/issue-archive/o24asktom-095715.html ">asktom technique</a> (look at the bottom for "Analytics to the Rescue (Again)"). 
First, we calculate "step", a nonnegative number  that will be zero if a range can be joined to the previous one, since:
a) they are consecutive (no gap between them)
 b) they have the same price:
[sql light="true"]  
ranges_with_step as (
  select sku, ba, bb, prio, price,
         decode ( price, lag(price) over (partition by sku order by ba),  ba - lag(bb) over (partition by sku order by ba), 1000 ) step
    from strongest_factored_ranges
), 
[/sql]
<pre>
RANGE_CODED                    STEP
------------------------ ----------
b---(0,$200)---c               1000
c---(0,$200)---d                  0
d---(1,$300)---e               1000
</pre></br>
Then we compute the integral of step over the ranges;  joinable ranges will hence have the same value for "interval" since step is zero:
[sql light="true"]  
ranges_with_step_integral as (
  select sku, ba, bb, prio, price, step,
         sum(step) over (partition by sku order by ba rows between unbounded preceding and current row) as integral
    from ranges_with_step
), 
[/sql]
<pre>
RANGE_CODED                INTEGRAL 
------------------------ ---------- 
b---(0,$200)---c               1000 
c---(0,$200)---d               1000 
d---(1,$300)---e               2000 
</pre></br>
The joined joinable ranges :
[sql light="true"]  
ranges_joined as (
  select * 
    from (
  select sku, ba, bb, prio, price, step, integral,
         min(ba) over (partition by sku, integral) as a,
         max(bb) over (partition by sku, integral) as b
    from ranges_with_step_integral
         )
   where step &gt; 0 
)
select sku, a, b, price from ranges_joined;
[/sql]
<pre>
b---(0,$200)---c---(1,$300)---e
</pre></br>
<b>predicate-"pushability"</b>
The first desirable property of this view is that a predicate (such as an equality predicate, but it works even for the "between" operator, less-than, etc) on sku  can be pushed down the view to the base tables. For:
[sql light="true"]  
select * from ranges_output_view where sku = 'k100'; 
[/sql]
the plan is:
 [sql light="true"]  
----------------------------------------------------------
| Id  | Operation                            | Name      |
----------------------------------------------------------
...
|  10 |           TABLE ACCESS BY INDEX ROWID| RANGES    |
|* 11 |            INDEX RANGE SCAN          | RANGES_PK |
...
|* 17 |                INDEX RANGE SCAN      | RANGES_PK | 
|* 18 |                INDEX RANGE SCAN      | RANGES_PK |
----------------------------------------------
---
11 - access(&quot;I&quot;.&quot;SKU&quot;='k100') 
---
17 - access(&quot;SKU&quot;='k100')     
18 - access(&quot;SKU&quot;='k100')     
[/sql]
That means that only the required SKU(s) are fed to the view, and proper indexes (such as RANGES_PK in this case) can be used. So, if you need to refresh only a few skus the response time is going to be almost istantaneous - provided that you have only sane (a few) ranges per sku. Hence you can use the same view for both calculating prices of all skus (say, in a nightly batch) and calculating a small subset of skus (say, online), and that is a great help for maintenance and testing.</br>
<b>running in parallel</b>
Another desirable property is that the view can operate efficiently in parallel, at least in 11.2.0.3 (I have not tested other versions): 
[sql light="true"]  
-------------------------------------------------------------------
| Operation                                   |IN-OUT| PQ Distrib |
-------------------------------------------------------------------
| SELECT STATEMENT                            |      |            |
|  PX COORDINATOR                             |      |            |
|   PX SEND QC (RANDOM)                       | P-&gt;S | QC (RAND)  |
|    VIEW                                     | PCWP |            |
|     WINDOW SORT                             | PCWP |            |
|      VIEW                                   | PCWP |            |
|       WINDOW SORT                           | PCWP |            |
|        VIEW                                 | PCWP |            |
|         WINDOW BUFFER                       | PCWP |            |
|          VIEW                               | PCWP |            |
|           WINDOW SORT PUSHED RANK           | PCWP |            |
|            HASH JOIN                        | PCWP |            |
|             PX RECEIVE                      | PCWP |            |
|              PX SEND HASH                   | P-&gt;P | HASH       |
|               PX BLOCK ITERATOR             | PCWC |            |
|                TABLE ACCESS FULL            | PCWP |            |
|             PX RECEIVE                      | PCWP |            |
|              PX SEND HASH                   | P-&gt;P | HASH       |
|               VIEW                          | PCWP |            |
|                WINDOW SORT                  | PCWP |            |
|                 PX RECEIVE                  | PCWP |            |
|                  PX SEND HASH               | P-&gt;P | HASH       |
|                   VIEW                      | PCWP |            |
|                    SORT UNIQUE              | PCWP |            |
|                     PX RECEIVE              | PCWP |            |
|                      PX SEND HASH           | P-&gt;P | HASH       |
|                       UNION-ALL             | PCWP |            |
|                        PX BLOCK ITERATOR    | PCWC |            |
|                         INDEX FAST FULL SCAN| PCWP |            |
|                        PX BLOCK ITERATOR    | PCWC |            |
|                         INDEX FAST FULL SCAN| PCWP |            |
-------------------------------------------------------------------  
[/sql]
There's no point of serialization (all servers communicate parallel-to-parallel), the rows are distributed evenly using an hash distribution function (probably over the sku) and all operations are parallel.</br>
<b>sku subsetting and partitioning</b>
It is well known that analytics functions use sort operations heavily, and that means (whether or not you are running in parallel) that the temporary tablespace may be used a lot, possibly too much - as it actually happened to me , leading to (in my case) unacceptable performance.</br>
<i>Side note:  as I'm writing this, I realize now that I had probably been hit by the bug illustrated by Jonathan Lewis in <a href="http://jonathanlewis.wordpress.com/2009/09/07/analytic-agony/">Analytic Agony</a>, but of course, overuse of temp could happen, for large datasets, without the bug kicking in.</i></br>
A possible solution is to process only a sub-batch of the skus at a time, to keep the sorts running in memory (or with one-pass to temp), leveraging the predicate-pushability of the view. In my case,  I have made one step further:  I have partitioned the table "ranges" by "sku_group", replaced in the view every occurrence of "sku" with the pair "sku_group, sku", and then run something like:
[sql light="true"]  
 for s in (select sku_group from &quot;list of sku_group&quot;) loop
  select .. from ranges_output_view where sku_group = s.sku_group;
end loop;
[/sql]
The predicate gets pushed down to the table, hence partition elimination kicks in and I can visit the input table one time only, one partition at a time, using a fraction of the resources at a time, and hence vastly improving performance.</br>
And that naturally leads to "do-it-yourself parallelism": running a job for every partition in parallel. I'm going to implement it since the customer is salivating about it ... even if it is probably over-engineering :D .
]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>529</wp:post_id>
		<wp:post_date><![CDATA[2012-10-01 10:54:57]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2012-10-01 08:54:57]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[overlapping-ranges-with-priority]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="case-studies"><![CDATA[case studies]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_syntaxhighlighter_encoded]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[ila.calderon.rs93@gmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[ginger_barron_qra13@hushmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>190</wp:comment_id>
			<wp:comment_author><![CDATA[Overlapping ranges with priority | An Oracle Programmer]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://stewashton.wordpress.com/2014/03/15/overlapping-ranges-with-priority/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[192.0.81.188]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-03-22 23:01:32]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-03-22 21:01:32]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] few years ago, Alberto Dell&#8217;Era blogged about product prices with overlapping date ranges; &#8220;on an overlapping range, the strongest priority (lower number) wins.&#8221; His analysis, [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>191</wp:comment_id>
			<wp:comment_author><![CDATA[Sam]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[samuel_ezeiruaku@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.mugu.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[199.166.186.1]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2015-01-29 01:12:34]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2015-01-28 23:12:34]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[I have similar problem, is there a way i can use your solution in Microsoft Access?]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>192</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.51]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2015-01-30 21:14:15]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2015-01-30 19:14:15]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Sam,

sorry but I know nothing about MS Access]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>191</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>OLTP compression: migrated rows are compressed</title>
		<link>http://www.adellera.it/blog/2013/04/07/oltp-compression-migrated-rows-are-compressed/</link>
		<pubDate>Sun, 07 Apr 2013 18:29:22 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=589</guid>
		<description></description>
		<content:encoded><![CDATA[In his articles <a href="http://allthingsoracle.com/compression-in-oracle-part-2-read-only-data/ " >Compression in Oracle – Part 2: Read-Only Data</a> and <a href="http://allthingsoracle.com/compression-in-oracle-part-3-oltp-compression/">Compression in Oracle – Part 3: OLTP Compression</a>, <a href=" http://jonathanlewis.wordpress.com/all-postings/">Jonathan Lewis</a> has shown that block (re)compression is never attempted on updates - it is attempted only on inserts (and, of course, only if the used space crosses the PCTFREE threshold).</br>
Now,  since a row migration could be considered a row re-insertion - does it trigger a compression attempt of the block that the row is migrated into? The answer is yes, as I will show you in a while.</br>
It is worth remembering that row migration can be quite dramatic in an OLTP-compressed table, because (as shown by Jonathan above)  when a tokenized column of a compressed row is updated to a new value, the whole token is expanded, modified and left uncompressed, even if the new value could be substituted by a token already present in the block. Hence any kind of update, even the tiniest, has the potential to inflate the row considerably, and of course, if the row can't fit into the free space, the row has to be migrated to a new block. </br>
Compressing migrated rows has the benefit that at least the whole size of the table is not probably going to grow much, assuming a reference scenario where rows were inserted randomly in the first place (i.e. without cleverly colocating similar rows in the same block, e.g. by inserting them in bulk using a well-designed order by), and assuming that the updating process that causes migration is random as well (which is probably almost always true). The "only" overhead is the additional block get necessary to follow the rowid that acts as the "forwarding address"  from the original row position (where only the row header is stored) to the new (where the row piece is now stored). </br>
Side note: it's interesting to note that this overhead is not present when doing a full table scan, since full scans simply do not follow the "forwarding address" since they are going to find the row piece anyway (a well-known fact that is also checked in my test case for completeness). Since, as reasoned about above for our reference scenario, the table size probably does not change much, a frequently-full-scanning DWH is probably going to enjoy similar performance even after updates (and this is a bit ironic for a feature named "OLTP compression"); not so for OLTP systems or DWHs that use single row access a lot (e.g. by following rowids from bitmap indexes), that have to pay the migration penalty. </br>
But let's leave speculations alone, and get back to hacking ... </br>
<b>test case: migrated rows are compressed</b>
Note: the test case (main.sql),  its spool (main.lst) and block dumps (main.trc) are available in <a href="http://34.247.94.223/wp-content/uploads/2013/04/oltp_compress_migrated_rows.zip"> oltp_compress_migrated_rows.zip</a>, alongside other test cases mentioned in the following. </br>
For simplicity, we are going to use a tablespace with segment space managed manually, i.e. where free blocks are linked together by one freelist, and with a block size of 4K; Oracle version is 11.2.0.3. </br>
The test table is (note the PCTFREE  set to 50%):
 [sql light="true"]  
create table t (x varchar2(400 char))
pctfree 50
compress for oltp
;
[/sql]
The initial row set is generated by: 
[sql light="true"]  
insert /*+ append */ into t 
select rpad( 'A', 400, 'A') from dual connect by level &lt;= 10000;
[/sql]
That is, all identical rows, all chars set to 'A' (coded as 0x41 in the WE8ISO8859P1 single-byte charset of my test database). Note that each row is sized 400 bytes and hence, when not compressed, only 10 rows can fit in a  4K block, and only 5 rows would be inserted given the PCTFREE=50 setting. </br>
The block dump of the first block after the segment header shows that we have 2017 bytes free (tosp=0x7e1), as expected. In the row dump we find, in order, first the (lonely) token:
<pre>
tab 0, row 0, @0xdf3
tl: 405 fb: --H-FL-- lb: 0x0  cc: 1
col  0: [400] {repeat 41, 400 times}
bindmp: 00 8a fa 01 90 {repeat 41, 400 times}</pre></br>
and then 137 highly-compressed rows, all with the same structure,  referencing the token:
<pre>
tab 1, row 0, @0xdee
tl: 5 fb: --H-FL-- lb: 0x0  cc: 1
col  0: [400] {repeat 41, 400 times}
bindmp: 2c 00 01 01 00
</pre></br>
Note: check the above mentioned articles by Jonathan for a detailed explanation of the compression format. The bindmp line shows what's  actually stored in the block:  "2c 00 01" are the flag byte, the lock byte, and the column count; "01" means "1 token follows"  and  "00" is the pointer  to token zero. </br>
Let's update every row to lowercase. i.e. to a string of 400 'a' (0x61), thus causing massive row migration:
[sql light="true"]  
update t set x = lower(x);
[/sql]
After the update, in our block the token is gone; the first 5 rows were uncompressed but were kept in the block since they fit in the free space:
<pre>
tab 1, row 0, @0xc5c
tl: 407 fb: --H-FL-- lb: 0x2  cc: 1
col  0: [400] {repeat 61, 400 times}
bindmp: 2c 02 01 00 fa 01 90 {repeat 61, 400 times}
</pre></br>
but , indeed, all the other  132 (=137-5) ones were migrated:
<pre>
tab 1, row 5, @0x5f7
tl: 9 fb: --H----- lb: 0x2  cc: 0
nrid:  0x04000148.0
bindmp: 20 02 00 04 00 01 48 00 00
</pre></br>
The flag byte "--H-----" means "this is just the row header" (check <a href=" http://www.ixora.com.au/q+a/0107/27152941.htm "> this  great note by Steve Adams</a>) and nrid is the "forwarding address" rowid we spoke about previously. </br>
Now, the interesting part - <i>migrated rows got compressed</i>. </br>
Indeed, walking down the blocks containing the migrated rows, we see
a)  token 0, holding  400 bytes set to 0x61 (same as above, not shown)
b)  a certain number (usually a dozen) of compressed rows:
<pre>
tab 1, row 0, @0xce0
tl: 11 fb: ----FL-- lb: 0x1  cc: 1
hrid: 0x04000101.5
col  0: [400] {repeat 61, 400 times}
bindmp: 0c 01 01 04 00 01 01 00 05 01 00
</pre></br>
note that the row is migrated: the flag byte "----FL--" means "this is the First and Last row piece, the Header is not here" and hrid is the pointer to the header (i.e. the original row position).  Of course, note that the row is compressed: the  bindmp shows the usual row header  triplet "0c 01 01", then the hrid "04 00 01 01 00 05" and then the usual  "01" meaning  "1 token follows"  plus "00", the pointer  to token zero. </br>
 c)  uno or two uncompressed rows:
<pre>
tab 1, row 10, @0xae0
tl: 413 fb: ----FL-- lb: 0x1  cc: 1
hrid: 0x04000101.f
col  0: [400] {repeat 61, 400 times}
bindmp: 0c 01 01 04 00 01 01 00 0f 00 fa 01 90 {repeat 61, 400 times}
</pre></br>
note the bindmp, and the flag byte telling us, again, that this row is indeed migrated.
In addition, tosp is usually set to 0x907 (2311 bytes), about half of the block, honoring the PCTFREE setting to 50%. </br>
This layout is typical of a series of row insertions in a empty block:  the first inserts get simply stored uncompressed, until one that would make the used space cross the pctfree threshold triggers a potential compression before being inserted uncompressed.  Note the order (already noted by Jonathan Lewis): first the compression is potentially attempted, then the row is stored - hence at least one uncompressed row is always present. There can be more because the compression is not always attempted, depending, possibly, on some cost consideration by the kernel. Check thr.sql and thr.trc if interested. </br>
<b> uncompressed un-migration </b>
As a side investigation, I have also checked what happens when a row is "un-migrated";  I was expecting that un-migration could trigger a compression, but this does not seem to be the case, at least in my scenario. </br>
I have prepared the first block (check the last part of main.trc) with only 12 migrated rows (leaving a very big free space of tosp=0xde6=3558 bytes), and then I have updated them to the original value in uppercase using "update t set x = upper(x)" .  These rows, being identical, could be comfortably be un-migrated and compressed all together in the original block (just remember that we observed a block with 137 such rows at the start of the main investigation), but that has not happened. Instead, the first 8 rows have been un-migrated indeed but left uncompressed, and the last 4 has been simply left migrated; also, the block free space has dropped to a mere tosp=0x176=374 bytes, thus severely hitting the PCTFREE reserve. </br>
Un-migration is a potential source of table size increase and/or pctfree space consumption, if this happens all the times in all scenarios - but I have not checked this extensively, though.]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>589</wp:post_id>
		<wp:post_date><![CDATA[2013-04-07 20:29:22]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2013-04-07 18:29:22]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[oltp-compression-migrated-rows-are-compressed]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="compression"><![CDATA[compression]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_syntaxhighlighter_encoded]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[earnestmweaveryik80@live.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[jimmie-osborn-us53@rocketmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[glenna-m-petty-zt83@yahoo.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[hector-p-bryant-lmx68@yahoo.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[marion-holmes-wlns16@gmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[darrelgarzatn89@gmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[christi.g.aguirre.stu75@yahoo.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[annette.kemp.kv12@hotmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[scottie.k.doyle.dls80@msn.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[leewcooperohi52@msn.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[darryligibsonub70@excite.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>193</wp:comment_id>
			<wp:comment_author><![CDATA[Kevin Mede]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[km133688@sbcglobal.net]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[71.234.208.94]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2015-01-16 09:12:24]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2015-01-16 07:12:24]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[I am confused by your use of the term UN-MIGRATED.  To my knowledge, there is no such thing as an un-migrate event.  Please explain what you mean.

Are you suggesting that with each update of a migrated row, Oracle checks to see if it could fit in the prior owning block?  I could believe that an update to a migrated row might cause it to migrate again, and that by co-incidence a prior owning block might receive this row, at which point the receiving block knowing that it is receiving a migrated row might check the migration chain to see if it already owns a pointer to this row and if so clean up the chain.  Is that what happened?  Or did Oracle actively check to see if migrated rows being updated could be sent back up their migration chain?  If so, does this happen for non-compressed tables?  I have never heard of it.

Kevin]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>194</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.51]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2015-01-19 11:29:38]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2015-01-19 09:29:38]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Kevin,

a row can be "unmigrated", the most effective demo I know is this one:

https://jonathanlewis.wordpress.com/2014/02/10/row-migration/

interestingly, Jonathan shows that the "unmigrating trigger" is the row needing to be migrated again, at which point Oracle tries, first thing, to migrate it back where the row header is (and that makes perfect sense, since when updating, the row header is locked and its block is [should be?] pinned, so the overhead of checking its free space is almost immaterial). Note that the row must grow enough to be forced to migrate again to be considered for "unmigration".

In my test case I haven't changed the row size at all (I have switched the letter case only, so the size remains exactly the same); I don't know what triggers this - possibly, as you say, it's an optimization for compressed tables only, but that should be investigated properly (I might do it when I have time).

The scope  of the post, however, was to investigate whether compression is triggered or not - and it looks rather strange to me that migrated rows gets compressed but "unmigrated" ones not.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>193</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>fast refresh of outer-join-only materialized views - algorithm, part 1</title>
		<link>http://www.adellera.it/blog/2013/04/22/fast-refresh-of-outer-join-only-materialized-views-algorithm-part-1/</link>
		<pubDate>Mon, 22 Apr 2013 07:40:24 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=631</guid>
		<description></description>
		<content:encoded><![CDATA[In this series of posts we will discuss how Oracle refreshes materialized views (MV) containing only OUTER  joins, covering only 11.2.0.3. We will use the very same scenario (MV log configuration, DML type, etc) as in the  <a href=" http://www.adellera.it/blog/2009/08/04/fast-refresh-of-join-only-materialized-views-algorithm-summary/"><i>inner</i> join</a> case, "just" turning the inner join into an outer join:
 
[sql light="true"]
create materialized view test_mv
build immediate
refresh fast on demand
as
select test_outer.*, test_outer.rowid as test_outer_rowid,
       test_inner.*, test_inner.rowid as test_inner_rowid
  from test_outer, test_inner
 where test_outer.jouter = test_inner.jinner(+)
; 
[/sql]

For the outer case, the overall strategy is the same we already saw for inner joins: modifications from each master table are propagated separately to the MV, and by still performing, for each master table, the same two macro steps (first the DEL, and then the INS one).

Actually, propagation from the outer table is exactly the same (with the obvious slight difference of performing an outer join to recalculate the "slice" in the INS step), and hence we will discuss only the propagation from the inner table, which is considerably more complex.

There are actually <i>two</i> different propagation algorithms, one much simpler and less resource-intensive that requires a <b>unique constraint on the joined columns</b> (here, "jinner" alone); in this post I will discuss the details of this specialized algorithm only, leaving the details of the "general" other one for the next post. 

Does the existence of a a unique constraint on the joined colum(s) enable such a dramatic simplification of the propagation that justifies a specialized algorithm? Yes, absolutely - and it is interesting to understand the reason since it comes out naturally from the very semantic of the outer join SQL construct, and hence we can also improve our understanding of this important component of the SQL syntax as a by-product.

Let's start by remembering that every row of the outer table is always represented in the MV, possibly with all columns coming from the inner table set to null (including, most importantly, test_inner_rowid) if no match is found in the inner table. If  M matches are found for a given outer row, M rows will be present in the MV; e.g. for M=2, we will see the following "outer slice" (my definition) corresponding to outer row ooo:

ooo inn1
ooo inn2

Now, if a unique constraint exists on the joined column(s), M can be at most 1, and hence only two possible states are possible for our outer slice:

(a) ooo inn1
(b) ooo *null*

Hence, if inn1 is marked in the log, propagating its deletion in the DEL step is just a matter of simply switching the slice from state (a) to (b) using an update statement, and conversely, propagating its insertion in the INS step is just a matter of updating the slice from state (b) to state (a). In other words, the possible matching rows of the outer table are already there, in the MV, and all we need to do is to "flip their state" if necessary. Thus it is possible to propagate using only quite efficient update statements  - no delete or insert needs to be performed at all.

Now, consider how the absence of unique constraint adds additional complexity. In this case this scenario is possible:
 
ooo inn1
ooo inn2

if only one of (inn1, inn2) is marked in the log, the DEL step can simply delete only the corresponding row in the MV, but if both are marked, it must leave a single row with all the columns coming from the inner table set to null:

ooo *null*

conversely, the INS step must remember to remove the above row if it finds at least a match in the outer table.

In other words, <i>the whole "outer slice" must be considered and examined by both steps</i>; it is not enough to consider only marked rows "in isolation", as it was the case in the inner join scenario and the constrained outer join scenario. This is considerably more complex, and in fact, the "general" algorithm was designed and implemented only in 10g - before 10g it was <i>mandatory</i> to have a unique constraint on the joined columns to enable fast refresh.

<b>conventions and investigation scope</b>
To reduce the visual clutter, instead of this log reading fragment (whose meaning we already discussed in the previous post)
[sql light="true"]
(select rid$ 
   from (select  chartorowid(mas$.m_row$$) rid$     
           from mlog$_test_inner mas$   
          where mas$.snaptime$$ &gt; :b_st0 
        ) 
) as of snapshot(:b_scn) mas$ 
[/sql] 
I will use the following simplified notation
[sql light="true"]
(select rid$ from mlog$_test_inner)
[/sql] 
And of course, I will restructure and simplify the SQL statements to increase readability (the original statements are included in the <a href="http://34.247.94.223/wp-content/uploads/2013/04/join_mv_outer_part1_unique.zip">test case</a> of course).

I will also define a row as "marked in the log" if it has a match in the set "select rid$ from mlog$_test_inner" - the matching column being test_inner_rowid for the MV and the actual rowid for the inner table test_inner. 

I am covering only 11.2.0.3 in the same scenario of the inner join post quoted above: MV logs configured to "log everything" and a single fast refresh propagating all possible types of regular (no direct-path) INSERTs, UPDATEs and DELETEs performed on the master tables (I haven't investigated  possible variants of the refresh algorithm if only a subset of those DML types is performed).

<b>The DEL macro step with the unique constraint</b>
As stated above , it consists of a simple update:
[sql light="true"]
/* MV_REFRESH (UPD) */ 
update test_mv
   set jinner = null, xinner = null, pkinner = null, test_inner_rowid = null 
 where test_inner_rowid in (select rid$ from mlog$_test_inner)
[/sql]
that simply flips to null the columns coming from the inner table of all marked rows of the MV.

<b>The INS macro step with the unique constraint </b>
Again, as stated above, this step consists of a (not so simple) update:
[sql light="true"]
/* MV_REFRESH (UPD) */ 
update /*+ bypass_ujvc */ (
select test_mv.jinner           target_0, jv.jinner  source_0, 
       test_mv.xinner           target_1, jv.xinner  source_1, 
       test_mv.pkinner          target_2, jv.pkinner source_2, 
       test_mv.test_inner_rowid target_3, jv.rid$    source_3 
 from ( select test_inner.rowid rid$, test_inner.*  
          from test_inner
         where rowid in (select rid$ from mlog$_test_inner)
      ) jv,
      test_outer, 
      test_mv                 
where test_outer.jouter = jv.jinner 
  and test_mv.test_outer_rowid = test_outer.rowid  
) 
set target_0 = source_0, 
    target_1 = source_1, 
    target_2 = source_2, 
    target_3 = source_3
[/sql]
this statement joins the marked rows of the inner table with the outer table (using an inner join, not an outer join, of course) and then looks for matching slices (by test_outer_rowid) in the MV; for every match, it flips the columns coming from the inner table from null to their actual values.

As a side note, it's worth noting that the statement updates an updatable in-line view, which is actually "tagged as updatable" by the hint "bypass_ujvc" ("bypass the Updatable Join Validity Check" probably), an hint that only Oracle code can use nowadays.

<b>speeding up</b>

Looking at the above SQL statements, it comes out naturally that if your fast refresh process propagates a small number of modifications, it is beneficial, to speed up the fast refresh from the inner table, to create 
- for the DEL step: an index on test_mv (test_inner_rowid)
- for the INS step: an index on test_mv(test_outer_rowid) and another on test_outer(jouter).

To also speed up the refresh from the outer table (not shown in this post), you would also create an index on on test_inner(jinner) and test_mv(test_outer_rowid).

So in essence, the very same indexes as in the inner join case need to be created for the outer join. But note that if you never propagate from the outer table, the index on test_mv(test_outer_rowid) has to be created anyway - that index was not necessary in the inner join case.

Of course, as the number of modifications increase, and/or if you fast-refresh in parallel, the indexes might not be used by the CBO that could prefer full-scanning the tables; in that case they would just be update overhead. Your mileage may vary, as always - but knowing the actual algorithm and SQL submitted is for sure very helpful to decide. Hope this helps.

]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>631</wp:post_id>
		<wp:post_date><![CDATA[2013-04-22 09:40:24]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2013-04-22 07:40:24]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[fast-refresh-of-outer-join-only-materialized-views-algorithm-part-1]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="materialized-views"><![CDATA[materialized views]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[miles-c-vargas-ye78@yahoo.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_syntaxhighlighter_encoded]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[madelyn_t_cash_zxc23@aol.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[patnguyenuhy54@msn.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[britney_gilliam_vyj38@gmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[jamaal_wong_qwi19@yahoo.ca]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[genevaprincedl71@yahoo.ca]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[effierichmondzb49@msn.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[mitchellbowensjc46@lycos.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[jocelynyhurleyabg94@gmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[heriberto.valdez.uc19@msn.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[rosa_small_umg13@msn.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[rico-drake-oj02@lycos.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[alfred.o.richardson.zy18@gmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[guadalupe_prince_qcy72@hotmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[stacey-q-walsh-uet42@lycos.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[deehoganwmi90@hotmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>195</wp:comment_id>
			<wp:comment_author><![CDATA[Latest Data News, Oracle, MySQL, SQL Server, BigData]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.pythian.com/blog/log-buffer-317-a-carnival-of-the-vanities-for-dbas/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[50.56.240.252]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-04-26 14:06:25]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-04-26 12:06:25]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] Alberto has a good post on fast refresh of outer-join-only materialized views. [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>196</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; fast refresh of outer-join-only materialized views &#8211; algorithm, part 2]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2013/04/29/fast-refresh-of-outer-join-only-materialized-views-algorithm-part-2/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-04-29 11:03:24]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-04-29 09:03:24]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] this post, we are going to complete part 1 illustrating the (considerably more complex) general case of a fast refresh from a master inner [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>197</wp:comment_id>
			<wp:comment_author><![CDATA[Article 1 &#8211; Millenni]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://dev.layoutindex.com/millenni/article-1/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[96.30.44.136]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2016-03-15 07:17:55]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2016-03-15 05:17:55]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] And in fact this warning will be removed in 11.2.0.3. It seems that the reason for Oracle to give this error, is because, when an unique constraint exists on JOIN columns the refresh algorithm becomes far more efficient. [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>198</wp:comment_id>
			<wp:comment_author><![CDATA[Oracle 11g Materialized View Fast Refresh &#8211; Duplicated results and DB alert &#8211; Mubasher Financial Services Blog]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://blog.mubasher.net/2015/10/05/oracle-11g-materialized-view-fast-refresh-duplicated-results-db-alert/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[72.251.248.20]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2017-10-03 05:23:02]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2017-10-03 03:23:02]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] And in fact this warning will be removed in 11.2.0.3. It seems that the reason for Oracle to give this error, is because, when an unique constraint exists on JOIN columns the refresh algorithm becomes far more efficient. [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>fast refresh of outer-join-only materialized views - algorithm, part 2</title>
		<link>http://www.adellera.it/blog/2013/04/29/fast-refresh-of-outer-join-only-materialized-views-algorithm-part-2/</link>
		<pubDate>Mon, 29 Apr 2013 08:57:14 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=711</guid>
		<description></description>
		<content:encoded><![CDATA[In this post, we are going to complete <a href="http://www.adellera.it/blog/2013/04/22/fast-refresh-of-outer-join-only-materialized-views-algorithm-part-1/">part 1</a> illustrating the (considerably more complex) general case of a fast refresh from a master inner table without a unique constraint on the joined column(s).

To recap, now the outer slice can be composed of more than one row, for example:

ooo inn1
ooo inn2

and hence, both the DEL and INS step must consider (and read) the whole outer slice even if only a subset of the inner rows have been modified. This requires both more resources and a considerably more complex algorithm. Let's illustrate it (the mandatory test case is <a href=" http://34.247.94.223/wp-content/uploads/2013/04/join_mv_outer_part2.zip">here</a>).

<b>The DEL macro step</b>

This sub step (named DEL.del by me) is performed first:
[sql light="true"]
/* MV_REFRESH (DEL) */ 
delete from test_mv where rowid in ( 
select rid 
  from ( 
select test_mv.rowid rid,  
       row_number() over (partition by test_outer_rowid order by rid$ nulls last) r,  
       count(*)     over (partition by test_outer_rowid ) t_cnt,  
       count(rid$)  over (partition by test_outer_rowid ) in_mvlog_cnt  
  from test_mv, (select distinct rid$ from mlog$_test_inner) mvlog 
 where /* read touched outer slices start */ 
       test_mv.test_outer_rowid in 
          ( 
          select test_outer_rowid 
            from test_mv 
           where test_inner_rowid in (select rid$ from mlog$_test_inner)
          ) 
       /* read touched outer slices end */ 
   and test_mv.test_inner_rowid = mvlog.rid$(+)                                       
       )  
 /* victim selection start */
 where t_cnt &gt; 1  
   and ( (in_mvlog_cnt = t_cnt and r &gt; 1) 
          or 
         (in_mvlog_cnt &lt; t_cnt and r &lt;= in_mvlog_cnt) 
       ) 
 /* victim selection end */
) 
[/sql]
followed by the DEL.upd one:
[sql light="true"]
/* MV_REFRESH (UPD) */ 
update test_mv
   set jinner = null, xinner = null, pkinner = null, test_inner_rowid = null 
 where test_inner_rowid in (select rid$ from mlog$_test_inner)
[/sql]
This two steps combined do change all the rows of the MV marked in the log (and only them, other rows are not modified at all); the first step deletes some of them, leaving all the others to the second one, that sets to null their columns coming from the inner table.

DEL.upd is straighforward. Let's illustrate the DEL.del algorithm:

a) the section "read touched outer slices" fetches all the MV outer slices that have at least one of their rows marked in the log;
b) the slices are outer joined with the "mvlog" in-line view, so that rid$ will be nonnull for all rows marked in the log;
c) the analytic functions, for each outer slice separately, compute the number of rows (column t_cnt), the number of rows marked (column in_mvlog_cnt), and then attach a label (column r) that orders the row (order is not important at all besides non-marked rows being ordered last)
d) the where-predicate "victim selection" dictates which rows to delete.

The victim selection predicate  has three sub-components, each implementing a different case (again, considering each slice separately):

<b>"t_cnt > 1"</b>: do not delete anything if the slice contains only one row (since it is for sure marked and hence will be nulled by DEL.upd)
<pre>
             rid$ t_cnt in_mvlog_cnt r  action 
ooo inn1 not-null     1            1 1  updated by DEL.upd   
 
</pre><br/>

<b>"in_mvlog_cnt = t_cnt and r > 1"</b>: all rows are marked, delete all but one (that will be nulled by DEL.upd)
<pre>
             rid$ t_cnt in_mvlog_cnt r  action 
ooo inn1 not-null     3            3 1  updated by DEL.upd    
ooo inn2 not-null     3            3 2  deleted by DEL.del    
ooo inn3 not-null     3            3 3  deleted by DEL.del    
</pre><br/>


<b>"in_mvlog_cnt < t_cnt and r <= in_mvlog_cnt"</b>: only some rows are marked; delete all marked rows, keep all the others.
<pre>
             rid$ t_cnt in_mvlog_cnt r  action 
ooo inn1 not-null     3            2 1  deleted by DEL.del    
ooo inn2 not-null     3            2 2  deleted by DEL.del    
ooo inn3     null     3            2 3  nothing    
</pre><br/>

<b>The INS macro step</b>

The first sub-step is INS.ins:

[sql light="true"]
/* MV_REFRESH (INS) */ 
insert into test_mv 
select  o.jouter,  o.xouter,  o.pkouter, o.rowid,
       jv.jinner, jv.xinner, jv.pkinner, jv.rid 
  from ( select test_inner.rowid rid,  
                test_inner.*  
           from test_inner 
          where rowid in (select rid$ from mlog_test_inner)
       ) jv, test_outer o 
 where jv.jinner = o.jouter
[/sql]
this sub-step simply find matches in the outer table for the marked inner table rows (note that it is an inner join, not an outer join), and inserts them in the MV.

Then, INS.del:
[sql light="true"]
/* MV_REFRESH (DEL) */ 
delete from test_mv sna$ where rowid in (
select rid 
 from ( 
select test_mv.rowid rid,
       row_number()            over (partition by test_outer_rowid order by test_inner_rowid nulls first) r,  
       count(*)                over (partition by test_outer_rowid ) t_cnt,  
       count(test_inner_rowid) over (partition by test_outer_rowid ) nonnull_cnt  
  from test_mv 
 where /* read touched outer slices start */
       test_mv.test_outer_rowid in 
          (
          select o.rowid  
            from ( select test_inner.rowid rid$,  
                          test_inner.*  
                     from test_inner
                    where rowid in (select rid$ from mlog$_test_inner)
                 ) jv, test_outer o 
           where jv.jinner = o.jouter 
          ) 
      /* read touched outer slices end */    
      )  
 /* victim selection start */     
 where t_cnt &gt; 1  
   and ( (nonnull_cnt = 0 and r &gt; 1) 
          or 
         (nonnull_cnt &gt; 0 and r &lt;= t_cnt - nonnull_cnt) 
       ) 
 /* victim selection end */
)
[/sql]
this substep has a SQL structure very similar to DEL.upd, hence I will simply outline the algorith: first, the statement identifies (in the "read touched outer slices" section) all the outer slices that had at least one rows inserted by INS.ins, by replaying its join; then, for each slice, it deletes any row, if it exists,  that has column "test_inner_rowid" set to null (check the "victim selection predicate"). 

Side note: I cannot understand how nonnull_cnt could be = 0 - possibly that is for robustness only or because it can handle variants of the DEL step I haven't observed. 

<b>speeding up</b>

These are the indexes that the CBO might enjoy using to optimize the steps of the propagation from the inner table:
- DEL.del: test_mv(test_inner_rowid, test_outer_rowid)
- DEL.upd: test_mv(test_inner_rowid)
- INS.ins: test_outer(jouter)
- INS.del: test_outer(jouter) and test_mv(test_outer_rowid , test_inner_rowid)

And hence, to optimize all steps:
- test_outer(jouter)
- test_mv(test_inner_rowid, test_outer_rowid)
- test_mv(test_outer_rowid , test_inner_rowid)

And of course we need the usual index on test_inner(jinner) to optimize the propagation from the outer table (not shown in this post), unless we positively know that the outer table is never modified.

Note that the two indexes test_mv(test_inner_rowid, test_outer_rowid) and test_mv(test_outer_rowid , test_inner_rowid) allow to skip visiting the MV altogether (except for deleting rows, obviously) and hence might reduce the number of consistent gets dramatically (the indexes are both "covering" indexes for the SQL statements we observed in the DEL.del and INS.del) . 

For example, in my test case (check ojoin_mv_test_case_indexed.sql), the plan for the DEL.del step is:
[sql light="true"]  
--------------------------------------------------------------
| 0|DELETE STATEMENT                |                        |
| 1| DELETE                         |TEST_MV                 |
| 2|  NESTED LOOPS                  |                        |
| 3|   VIEW                         |VW_NSO_1                |
| 4|    SORT UNIQUE                 |                        |
| 5|     VIEW                       |                        |
| 6|      WINDOW SORT               |                        |
| 7|       HASH JOIN OUTER          |                        |
| 8|        HASH JOIN SEMI          |                        |
| 9|         INDEX FULL SCAN        |TEST_MV_TEST_INNER_ROWID|
|10|         VIEW                   |VW_NSO_2                |
|11|          NESTED LOOPS          |                        |
|12|           TABLE ACCESS FULL    |MLOG$_TEST_INNER        |
|13|           INDEX RANGE SCAN     |TEST_MV_TEST_INNER_ROWID|
|14|        VIEW                    |                        |
|15|         SORT UNIQUE            |                        |
|16|          TABLE ACCESS FULL     |MLOG$_TEST_INNER        |
|17|   MAT_VIEW ACCESS BY USER ROWID|TEST_MV                 |
--------------------------------------------------------------
5 - filter[ (T_CNT&gt;1 AND ((IN_MVLOG_CNT=T_CNT AND R&gt;1) 
OR (IN_MVLOG_CNT&lt;T_CNT AND R&lt;=IN_MVLOG_CNT))) ]
...
[/sql]
Note the absence of any access to the MV to identify the rows to be deleted (row source operation 5 and its progeny; note the filter operation, which is the final "victim selection predicate"); the MV is only accessed to physically delete the rows. 

Ditto for the INS.del step:
[sql light="true"]  
-------------------------------------------------------------------
| 0|DELETE STATEMENT                     |                        |
| 1| DELETE                              |TEST_MV                 |
| 2|  NESTED LOOPS                       |                        |
| 3|   VIEW                              |VW_NSO_1                |
| 4|    SORT UNIQUE                      |                        |
| 5|     VIEW                            |                        |
| 6|      WINDOW SORT                    |                        |
| 7|       HASH JOIN SEMI                |                        |
| 8|        INDEX FULL SCAN              |TEST_MV_TEST_INNER_ROWID|
| 9|        VIEW                         |VW_NSO_2                |
|10|         NESTED LOOPS                |                        |
|11|          NESTED LOOPS               |                        |
|12|           TABLE ACCESS FULL         |MLOG$_TEST_INNER        |
|13|           TABLE ACCESS BY USER ROWID|TEST_INNER              |
|14|          INDEX RANGE SCAN           |TEST_OUTER_JOUTER_IDX   |
|15|   MAT_VIEW ACCESS BY USER ROWID     |TEST_MV                 |
------------------------------------------------------------------- 
5 - filter[ (T_CNT&gt;1 AND ((NONNULL_CNT=0 AND R&gt;1) 
OR (NONNULL_CNT&gt;0 AND R&lt;=T_CNT-NONNULL_CNT))) ]
...
[/sql]
<br/>
You might anyway create just the two "standard" single-column indexes on test_mv(test_inner_rowid)  and test_mv(test_outer_rowid) and be happy with the resulting performance, even if you now will access the MV to get the "other" rowid - it all depends, of course, on your data (how many rows you have in each slice, and how many slices are touched by the marked rows) and how you modify the master tables. 

]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>711</wp:post_id>
		<wp:post_date><![CDATA[2013-04-29 10:57:14]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2013-04-29 08:57:14]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[fast-refresh-of-outer-join-only-materialized-views-algorithm-part-2]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="materialized-views"><![CDATA[materialized views]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[reinaldo.l.klein.hgx06@yahoo.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[deborah.ayala.br93@msn.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_syntaxhighlighter_encoded]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[odessa.jarvis.kyt35@hotmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[ora-k-benton-qng42@excite.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[cheryloconnorhw73@excite.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[edgarsullivankmg28@hotmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[dario.i.underwood.gxk25@msn.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[tom-bennett-sxr90@hotmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[kellywellsye04@msn.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[kellie.p.finley.owg50@msn.com]]></wp:meta_value>
		</wp:postmeta>
							</item>
					<item>
		<title>&quot;alter session force parallel query&quot;, and indexes</title>
		<link>http://www.adellera.it/blog/2013/05/17/alter-session-force-parallel-query-and-indexes/</link>
		<pubDate>Fri, 17 May 2013 12:15:05 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=751</guid>
		<description></description>
		<content:encoded><![CDATA[This post is a brief discussion about the advantages of activating parallelism by altering the session environment instead of using the alternative ways (hints, DDL). The latter ways are the most popular in my experience, but I have noticed that their popularity is actually due, quite frequently, more to imperfect understanding rather than informed decision - and that's a pity since "alter session force parallel query" can really save everyone a lot of tedious work and improve maintainability a great deal. 

We will also check that issuing
[sql light="true"]
alter session force parallel query parallel N;
[/sql]
is the same as specifying the hints
[sql light="true"]
/*+ parallel (t,N)  */
/*+ parallel_index (t, t_idx, N) */
[/sql]
for all tables referenced in the query, and <b>for all indexes defined on them</b> (the former is quite obvious, the latter not that much).

Side note: it is worth remembering that hinting the table for parallelism does not cascade automatically to its indexes as well - you must explicitly specify the indexes that you want to be accessed in parallel by using the separate parallel_index hint (maybe specifying "all indexes" by using the two-parameter variant "parallel_index(t,N)"). The same holds for "alter table parallel N" and "alter <b>index</b> parallel N", of course.

<b>the power of "force parallel query"</b>

I've rarely found any reason for avoiding index parallel operations nowadays - usually both the tables and their indexes are stored on disks with the same performance figures (if not the same set of disks altogether), and the cost of the initial segment checkpoint is not generally different. At the opposite, using an index can offer terrific opportunities for speeding up queries, especially when a full table scan can be substituted by a fast full scan on a (perhaps much) smaller index.

Thus, I almost always let the CBO consider index parallelism as well. Three methods can be used:
- statement hints (the most popular option)
- alter table/index parallel N 
- "force parallel query". 

I rather hate injecting parallel hints everywhere in my statements since it is very risky. It is far too easy to forget to specify a table or index (or simply misspell them), not to mention to forget new potentially good indexes added after the statement had been finalized. Also, you must change the statement as well even if you simply want to change the degree of parallelism, perhaps just because you are moving from an underequipped, humble and cheap test environment to a mighty production server. At the opposite, "force parallel query" is simple and elegant - just a quick command and you're done, and with a single place to touch in order to change the parallel degree.

"alter table/index parallel N" is another weak technique as well in my opinion, mainly for two reasons. The first one is that it is a permanent modification to the database objects, and  after the query has finished, it is far too easy to fail to revert the objects back to their original degree setting (because of failure or coding bug). The second one is the risk of  two concurrent sessions colliding on the same object that they both want to read, but with different degrees of parallelism.
Both the two problems above do not hold only when you always want to run with a fixed degree for all statements; but even in this case, I would consider issuing "force parallel query" (maybe inside a logon trigger) instead of having to set/change the degree for all tables/indexes accessed by the application.

I have noticed that many people are afraid of "force parallel query" because of the word "force", believing that it switches every statement into parallel mode. But <b>this is not the case</b>: as <a href="http://blog.tanelpoder.com/2013/03/20/alter-session-force-parallel-query-doesnt-really-force-anything/">Tanel Poder recently illustrated</a>, the phrase "force parallel query" is misleading; a better one would be something like "<i>consider</i> parallel query", since it is perfectly equivalent to hinting the statement for parallelism as far as I can tell (see below). And hinting itself tells the CBO to <i>consider</i> parallelism <i>in addition</i> to serial execution; the CBO is perfectly free to choose a serial execution plan if it estimates that it will cost less - as <a href=" http://jonathanlewis.wordpress.com/2007/06/17/hints-again/ ">demonstrated by Jonathan Lewis</a> years ago. 
Hence there's no reason to be afraid, for example, that a nice Index Range Scan that selects just one row might turn into a massively inefficient Full Table Scan (or index Fast Full Scan) of a one million row table/index. That is true besides bugs and CBO limitations, obviously; but in these hopefully rare circumstances, one can always use the no_parallel and no_parallel_index to fix the issue.

<b>"force parallel query" and hinting: test case</b>

Let's show that altering the session is equivalent to hinting. I will illustrate the simplest case only - a single-table statement that can be resolved either by a full table scan or an index fast full scan (check script force_parallel_main.sql in the <a href="http://34.247.94.223/wp-content/uploads/2013/05/force_parallel_query.zip">test case</a>), but in the test case zip two other scenarios (a join and a subquery) are tested as well. Note: I have only checked 9.2.0.8 and 11.2.0.3 (but I would be surprised if the test case could not reproduce in 10g as well).

Table "t" has an index t_idx on column x, and hence the statement
[sql light="true"]
select sum(x) from t;
[/sql]
can be calculated by either scanning the table or the index. In serial, the CBO chooses to scan the smaller index (costs are from 11.2.0.3):
[sql light="true"]
select /* serial */ sum(x) from t;
--------------------------------------
|Id|Operation             |Name |Cost|
--------------------------------------
| 0|SELECT STATEMENT      |     | 502|
| 1| SORT AGGREGATE       |     |    |  
| 2|  INDEX FAST FULL SCAN|T_IDX| 502|
--------------------------------------  
 [/sql]
If we now activate parallelism for the table, but not for the index, the CBO chooses to scan the table:
[sql light="true"]
select /*+ parallel(t,20) */ sum(x) from t
------------------------------------------
|Id|Operation              |Name    |Cost|
------------------------------------------
| 0|SELECT STATEMENT       |        | 229|
| 1| SORT AGGREGATE        |        |    |
| 2|  PX COORDINATOR       |        |    |
| 3|   PX SEND QC (RANDOM) |:TQ10000|    |
| 4|    SORT AGGREGATE     |        |    |
| 5|     PX BLOCK ITERATOR |        | 229|
| 6|      TABLE ACCESS FULL|T       | 229|
------------------------------------------
[/sql]
since the cost for the parallel table access is now down from the serial cost of 4135 (check the test case logs) to the parallel cost 4135 / (0.9 * 20) = 229, thus less than the cost (502) of the serial index access.

Hinting the index as well makes the CBO apply the same scaling factor (0.9*20) to the index as well, and hence we are back to index access:
[sql light="true"]
select /*+ parallel_index(t, t_idx, 20) parallel(t,20) */ sum(x) from t
---------------------------------------------
|Id|Operation                 |Name    |Cost|
---------------------------------------------
| 0|SELECT STATEMENT          |        |  28|
| 1| SORT AGGREGATE           |        |    |
| 2|  PX COORDINATOR          |        |    |
| 3|   PX SEND QC (RANDOM)    |:TQ10000|    |
| 4|    SORT AGGREGATE        |        |    |
| 5|     PX BLOCK ITERATOR    |        |  28|
| 6|      INDEX FAST FULL SCAN|T_IDX   |  28|
---------------------------------------------  
[/sql]
Note that the cost computation is 28 = 502 / (0.9 * 20), less than the previous one (229).

"Forcing" parallel query:

[sql light="true"]
alter session force parallel query parallel 20;

select /* force parallel query  */ sum(x) as from t
---------------------------------------------
|Id|Operation                 |Name    |Cost|
---------------------------------------------
| 0|SELECT STATEMENT          |        |  28|
| 1| SORT AGGREGATE           |        |    |
| 2|  PX COORDINATOR          |        |    |
| 3|   PX SEND QC (RANDOM)    |:TQ10000|    |
| 4|    SORT AGGREGATE        |        |    |
| 5|     PX BLOCK ITERATOR    |        |  28|
| 6|      INDEX FAST FULL SCAN|T_IDX   |  28|
--------------------------------------------- 
[/sql]
Note that the plan is the same (including costs), as predicted.

Side note: let's verify, just for fun, that the statement can run serially even if the session is "forced" as parallel (note that I have changed the statement since the original always benefits from parallelism):

[sql light="true"]
alter session force parallel query parallel 20;

select /* force parallel query (with no parallel execution) */ sum(x) from t 
WHERE X &lt; 0
----------------------------------
|Id|Operation         |Name |Cost|
----------------------------------
| 0|SELECT STATEMENT  |     |   3|
| 1| SORT AGGREGATE   |     |    |
| 2|  INDEX RANGE SCAN|T_IDX|   3|
----------------------------------       
[/sql]

Side note 2: activation of parallelism for all referenced objects  can be obtained, in 11.2.0.3, using the new statement-level parallel hint (check <a href="http://oracle-randolf.blogspot.it/2011/03/things-worth-to-mention-and-remember-ii.html">this note by Randolf Geist</a> for details):
[sql light="true"]
select /*+ parallel(20) */ sum(x) from t
---------------------------------------------------
|Id|Operation                 |Name    |Table|Cost|
---------------------------------------------------
| 0|SELECT STATEMENT          |        |     |  28|
| 1| SORT AGGREGATE           |        |     |    |
| 2|  PX COORDINATOR          |        |     |    |
| 3|   PX SEND QC (RANDOM)    |:TQ10000|     |    |
| 4|    SORT AGGREGATE        |        |     |    |
| 5|     PX BLOCK ITERATOR    |        |     |  28|
| 6|      INDEX FAST FULL SCAN|T_IDX   |T    |  28|
---------------------------------------------------
[/sql]
This greatly simplifies hinting, but of course you must still edit the statement if you need to change the parallel degree.]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>751</wp:post_id>
		<wp:post_date><![CDATA[2013-05-17 14:15:05]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2013-05-17 12:15:05]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[alter-session-force-parallel-query-and-indexes]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="cbo"><![CDATA[CBO]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_syntaxhighlighter_encoded]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[xavier.r.watts.kjn09@mail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[shawndmeadowsesc82@aol.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[simone.cotton.uob34@lycos.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[miriam_n_stephenson_oa73@yahoo.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[elmoschwartzphz95@excite.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[guy-l-simpson-ah57@hotmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[shanembryantye54@rocketmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[scott.martin.gu58@hushmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[gonzalo_u_weber_pyg10@live.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[owen.h.carr.gsv86@hushmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[yvette-gentry-ra03@aol.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[theodore_k_kelly_ct27@aol.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[bret.n.silva.hx08@live.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[tylerdiazpia91@gmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[gail.garrison.cek93@mail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[conrad_stanley_hs38@excite.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[lillieesalinasjxt90@yahoo.ca]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[miriamstephensonoa60@excite.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[guillermoweaverpk62@lycos.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[shivahindwan@gmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>199</wp:comment_id>
			<wp:comment_author><![CDATA[Bidu]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[beat.ramseier@teecup.net]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[138.188.100.232]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-05-22 08:46:26]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-05-22 06:46:26]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Thanks for the clear and concise write up...]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>200</wp:comment_id>
			<wp:comment_author><![CDATA[Peter]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[ojock@hotmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[217.44.157.144]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2017-08-22 13:55:37]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2017-08-22 11:55:37]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[When you try to enable and validate a foreign key constraint in parallel, 
behind the scenes, Oracle is executing a recursive SELECT statement to validate the constraint, but you cannot make that recursive query go parallel simply with "alter session force parallel query", you have to alter the table parallel attribute, like so;

alter table xyz parallel;
alter table xyz modify constraint xyz_fk1 enable novalidate;
alter table xyz modify constraint xyz_fk1 validate;
alter table xyz noparallel;

I couldn't get it to go parallel otherwise unless I've missed something from reading your post.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>201</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[213.156.34.234]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2017-08-28 11:33:51]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2017-08-28 09:33:51]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Peter,

you are correct; this post focuses on parallel query, not DDL.

For parallel DDL, I have never bothered forcing the session because I prefer to be specific and cautious when modifying/creating my objects, and avoid impacting the whole session. 

But Christian Antognini did check it, and in his book "Troubleshooting Oracle Performance", 2nd edition, page 635, confirms that the technique you are using (and that I use myself) for FKs is the only one possible: the session parallel DDL settings are ignored. 

In passing, the post was mainly motivated for DWH/BI reporting scenarios, where you want parallelism for your analysis but cannot/do not want to specify hints in queries or to change the table/indexes degree. In 12c, a much better alternative is to use autoDOP, that will tune the DOP to the complexity of the query (mainly influenced by the size of scanned tables/indexes).

ciao :)
Al]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>200</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>Fast refresh of aggregate-only materialized views - introduction</title>
		<link>http://www.adellera.it/blog/2013/08/05/fast-refresh-of-aggregate-only-materialized-views-introduction/</link>
		<pubDate>Mon, 05 Aug 2013 12:48:43 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=768</guid>
		<description></description>
		<content:encoded><![CDATA[This post introduces a series about the algorithm used by Oracle (in 11.2.0.3) to fast refresh a materialized view (MV) containing only an aggregate:
 
[sql light="true"]
create materialized view test_mv
build immediate
refresh fast on demand
with rowid
as
select gby        as mv_gby, 
       count(*)   as mv_cnt_star,
       AGG  (dat) as mv_AGG_dat,
       count(dat) as mv_cnt_dat
  from test_master
 where whe = 0
 group by gby
;
[/sql]

Where AGG is either SUM or MAX, the most important aggregates. 

In the next posts, I will illustrate the algorithms used to propagate conventional (not direct-load) inserts, updates and deletes on the master table; I will illustrate also the specialized versions of the algorithms used when only one type of DML has been performed (if they exist).

In this post, we sets the stage, make some general observations, and illustrate the very first steps of the algorithm that are common to all scenarios. Everything is supported by the usual <a href="http://34.247.94.223/wp-content/uploads/2013/08/gby_mv_intro.zip">test case</a>.


<b>Materialized view logs configuration</b>

I have configured the materialized view log on the master table to "log everything", to give the most complete information possible to the MV refresh engine:

[sql light="true"]
create materialized view log on test_master 
with rowid ( whe, gby, dat ), sequence 
including new values;
[/sql]

With this configuration, each modification to the master table logs the rowid of the affected rows (in column m_row$$), and it is labeled with an increasing value (in sequence$$) that enables the MV refresh engine to reconstruct the order in which the modifications happened. In detail, let’s see what’s inside the logs after we modify a single row (from mvlog_examples.sql):

After an INSERT:
[sql light="true"]
SEQUENCE$$ M_ROW$$              DMLTYPE$$ OLD_NEW$$    WHE    GBY    DAT
---------- -------------------- --------- --------- ------ ------ ------
     10084 AAAWK0AAEAAAxTHAD6   I         N             10     10     10
[/sql]
This logs the <i>new values</i> (old_new$$=’N’) of an Insert (dmltype$$=’I’).


After a DELETE:
[sql light="true"]
SEQUENCE$$ M_ROW$$              DMLTYPE$$ OLD_NEW$$    WHE    GBY    DAT
---------- -------------------- --------- --------- ------ ------ ------
     10085 AAAWK0AAEAAAxTFAAA   D         O              0      0      1
[/sql]
This logs the <i>old values</i> (old_new$$=’O’) of a Delete (dmltype$$=’D’).

After an UPDATE:
[sql light="true"]
SEQUENCE$$ M_ROW$$              DMLTYPE$$ OLD_NEW$$    WHE    GBY    DAT
---------- -------------------- --------- --------- ------ ------ ------
     10086 AAAWK0AAEAAAxTHAD6   U         U             10     10     10
     10087 AAAWK0AAEAAAxTHAD6   U         N             10     10     99
[/sql]
This logs both the <i>old values</i> (old_new$$=’U’)  and the the <i>new values</i> (old_new$$=’N’)  of an Update (dmltype$$=’U’). So we see that the update changed DAT from 10 to 99, without changing the other columns.

Note that the update log format is the same as a delete (at sequence 10086) immediately followed by an insert (at sequence 10087) at the same location on disk (AAAWK0AAEAAAxTHAD6), the only differences being dmltype$$=’U’ and old_new$$ set to ’U’ instead of ‘O’ for the old values.

But if you ignore these differences, you can consider the log a sequence of deletes/inserts, or if you prefer, a stream of old/new values. And this is <i>exactly what the refresh engine does</i> - it does not care whether an old value is present because it logs a delete or the "erase side" of an update, and ditto for new values. It "sees" the log as a stream of old/new values, as we will demonstrate.  

<b>Log snapshots</b>

When the MV fast refresh is started, the first step is to "mark" the logged modifications to be propagated to the MV by setting snaptime$$ equal to the current time - check the description contained <a href="http://www.adellera.it/blog/2009/08/04/fast-refresh-of-join-only-materialized-views-algorithm-summary">in this post</a> for details (note also <a href="http://www.adellera.it/blog/2009/11/03/11gr2-materialized-view-logs-changes">another possible variant with "commit-scn mv logs"</a>). MV log purging (at the end of the refresh) is the same as well.

<b>TMPDLT (deleting the redundant log values)</b>

The stream of old/new values marked in the log might contain <b>pairs</b> of  redundant values, each pair being composed of a new value (insert) immediately followed by an old value (delete) on the same row; every such pair can be ignored without affecting the refresh result. Filtering out these pairs is the job of this SQL fragment (nicknamed "TMPDLT"), heavily edited for readability:

[sql light="true"]
with tmpdlt$_test_master as ( 
  select /*+ result_cache(lifetime=session) */ 
         rid$, gby, dat, whe,  
         decode(old_new$$, 'N', 'I', 'D') dml$$,         
         old_new$$,  snaptime$$, 
         dmltype$$  
   from (select log.*,   
                min( sequence$$ ) over (partition by rid$) min_sequence$$,   
                max( sequence$$ ) over (partition by rid$) max_sequence$$   
           from (select chartorowid(m_row$$) rid$, gby, dat, whe, 
                        dmltype$$, sequence$$, old_new$$, snaptime$$  
                   from mlog$_test_master     
                  where snaptime$$ &gt; :b_st0 
                ) as of snapshot(:b_scn) log 
        )  
  where ( (old_new$$ in ('O', 'U') ) and (sequence$$ = min_sequence$$) ) 
     or ( (old_new$$ = 'N'         ) and (sequence$$ = max_sequence$$) )
) 
[/sql]
The "log" in-line view is the usual one selecting the marked log rows; the outer query blocks, for each rowid, keeps only the first logged value <i>but only if it is old</i>, and the last logged one, <i>but only if it is new</i>.

So for example (check tmpdlt_pair_removal_examples.sql), TMPDLT filters out the rows marked with (*) from this triple update of the same row:
[sql light="true"]
SEQUENCE$$ OLD_NEW$$    GBY    DAT    WHE
---------- --------- ------ ------ ------
     10142 U              0      1      0
     10143 N              0   1000      0  *
     10144 U              0   1000      0  *
     10145 N              0   2000      0  * 
     10146 U              0   2000      0  *
     10147 N              0   3000      0 
[/sql]
and it removes completely this pair (obtained by inserting a row and then deleting it):
[sql light="true"]
SEQUENCE$$ OLD_NEW$$    GBY    DAT    WHE
---------- --------- ------ ------ ------
     10162 N             -1     -1     -1  *
     10163 O             -1     -1     -1  *
[/sql]

As we will see, the result of TMPDLT is (almost always) the actual input to the refreshing algorithm, instead of the "raw" log rows. Note that this prefiltering is relatively expensive, and while it might be somehow beneficial to remove some redundant values, it is useful especially when the log contains a mix of new and old values and TMPDLT is able to turn it into a stream of new-only(insert-only) or old-only(delete-only) one. When it happens, the more specialized versions of the algorithm can be used, thus saving resources - even if the savings could not repay the cost of TMPDLT, in general. 

Even better, this prefiltering shows its greatest advantage when you have to refresh a so-called "insert-only MV", that is, a MV that refuses to fast-refresh if updates or deletes where performed, but it fast-refreshes happily when only inserts were performed: you might be able to <i>fast refresh and avoid a complete refresh</i> if TMPDLT is able to filter out all the old values. This happens for example if you insert some rows first, and then modify (or delete) only the newly inserted rows before refreshing - as demonstrated by tmpdlt_enables_fast_refresh_of_insert_only_mv.sql using the classic insert-only MV, a MV containing MAX and a where clause.

<b>TMPDLT caching</b>

The first operation performed by the refresh engine is to classify the log content as new-only(insert-only), old-only(delete-only) or mixed, both to decide which refresh algorithm to use (insert-only, delete-only, general) and to raise, possibly, "ORA-32314 REFRESH FAST unsupported after deletes/updates" for insert-only MVs.

To classify the log, it issues a SQL statement on TMPDLT, that lists for every possible DML (Insert,Update,Delete) the max value of snaptime$$ contained in the log. In passing, this might enable some optimizations such as multi-step refreshes, but I have not investigated this. 

Immediately after this, the chosen refreshing algorithm version might reference TMPDLT again - this time (possibly) saving resources since TMPDLT is result-cached, thanks to the hint "result_cache(lifetime=session)". 

The caching is a potentially relevant optimization since analytic functions can use a lot or resources for big (long and/or wide) MV logs. It means also that one must check also the result cache size (and utilization) when tuning for performance - and check that the analytic functions in the first place, of course, have enough resources to operate efficiently.

Side note: the undocumented modifier "lifetime=session" simply means that the result is flushed (at least) when the session ends (check result_cache_session_lifetime.sql), which is a nice optimization since TMPDLT is flashed back in time and hence is NOT flushed when the log is modified. It is anayway explicitly flushed as soon as the refresh ends, hence this is only a safe net just in case the refresh fails for some reason (e.g. disk full).

<b>TMPDLT disabling</b>

What if you don't benefit from TMPDLT since your log does not contain (enough) redundant values, and you don't want to pay the cost of its processing and/or caching ? 

You can disable it by removing the sequence from the MV log, that actually, as far as I know, seems to be used only by this prefilter. If this is done, all the refreshing statements read directly from the log; script tmpdlt_disabling_all.sql proves this (you will better appreciate how it works and its output after the next two posts that illustrate the actual refreshing algorithms of SUM and MAX, but you can already see that TMPDLT disappears from the refreshing statements).

The same scripts investigates also disabling it by setting the undocumented parameter "_mav_refresh_opt"=32, but as always, ask Oracle Support first (also because there's no official note explaining how it works on MOS, and I haven't used it in production yet - since I actually discovered it about one week ago while preparing this post).

In the next post, we will examine the SUM scenario. ]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>768</wp:post_id>
		<wp:post_date><![CDATA[2013-08-05 14:48:43]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2013-08-05 12:48:43]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[fast-refresh-of-aggregate-only-materialized-views-introduction]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="materialized-views"><![CDATA[materialized views]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_syntaxhighlighter_encoded]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[morgan_w_silva_utm40@msn.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[trent_j_pearson_yce26@yahoo.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[monroe_swanson_kzq16@hotmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[luther.knight.cfx52@hotmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[althea.v.mcpherson.om10@gmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[willhoffmantb86@gmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[jeffery_p_murphy_di46@msn.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[jerald.fowler.hc63@aol.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>202</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; Fast refresh of aggregate-only materialized views with SUM &#8211; algorithm]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2013/08/19/fast-refresh-of-aggregate-only-materialized-views-with-sum-algorithm/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-08-19 14:26:07]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-08-19 12:26:07]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] the general introduction to aggregate-only MVs we have seen how the refresh engine first marks the log rows, then inspects TMPDLT (loading its [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>203</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell&#8217;Era&#8217;s Oracle blog &raquo; Fast refresh of aggregate-only materialized views with MAX &#8211; algorithm]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it/blog/2013/08/23/fast-refresh-of-aggregate-only-materialized-views-with-max-algorithm/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.164.246]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2013-08-23 14:04:00]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2013-08-23 12:04:00]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[[...] the general introduction to aggregate-only MVs we have seen how the refresh engine first marks the log rows, then inspects TMPDLT (loading its [...] ]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[pingback]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>204</wp:comment_id>
			<wp:comment_author><![CDATA[Sandeep]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[hegsandeep@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[64.111.160.20]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-08-19 00:50:12]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-08-18 22:50:12]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi,

I was looking for a description of the columns of the Materialized View Log tables and found your site.  Thanks for the nice description.

I have a scenerio and need your thoughts on it. We are currently using Oracle Apps EBS, and doing a migration to a higher version. We have only the MLOG$ table created on a base PO table and have trigger on the MLOG$ table to get approved PO records out of the oracle apps system. Do you see any disadvantage of using triggers on the MLOG$ tables? Is there any performance hit? We have not seen any performance issues by and large till now but wanted to make sure we are doing it right.

Thanks,
Sandeep]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>205</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[93.33.129.250]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2014-08-24 10:57:46]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2014-08-24 08:57:46]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Sandeep,

I don't think that having a trigger on the mlog table is neither supported nor a good thing to do ... those tables are "private" and we are not supposed to do anything on them, besides (sometimes) indexing them or perform (even more rarely) some maintenance operation such as coalescing.

Especially, the issue is that the algorithm Oracle uses to populate the mlog table might change, and that would break your trigger. By the way, do you know that records inserted by insert-append are not replicated to the log ?

I would suggest to rewrite the trigger on the base table; probably you would get similar performance, since the mlog is populated, and hence your current trigger fires, for every row modified in the base table (besides insert-append, of course).]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>85134</wp:comment_id>
			<wp:comment_author><![CDATA[EOTechanu]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[cforbis@rc-sheriff.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[218.21.96.128]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2020-12-12 16:55:32]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2020-12-12 15:55:32]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[mostly in monasteries.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1607788532.1081729;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>86765</wp:comment_id>
			<wp:comment_author><![CDATA[Batteriesxgp]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[jpcotex@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[200.73.132.106]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2020-12-17 03:58:00]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2020-12-17 02:58:00]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[number of surviving European]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1608173880.5623879;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>86946</wp:comment_id>
			<wp:comment_author><![CDATA[Juicerzgr]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[bac0501@att.net]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[60.250.159.191]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2020-12-17 13:36:26]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2020-12-17 12:36:26]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[way. Handwritten book]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1608208586.60168;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>88177</wp:comment_id>
			<wp:comment_author><![CDATA[Ascentszz]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[rob@roblicht.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[139.5.132.29]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2020-12-20 01:51:19]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2020-12-20 00:51:19]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[manuscripts underwent in the Middle]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1608425479.8767071;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>88638</wp:comment_id>
			<wp:comment_author><![CDATA[Sunburstqik]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[kurt@finehospitality.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[188.237.135.3]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2020-12-20 23:20:51]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2020-12-20 22:20:51]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Of his works, he is especially famous]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1608502851.5983379;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>94523</wp:comment_id>
			<wp:comment_author><![CDATA[Carpetmcd]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[mikeistre@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[186.159.1.58]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-01-10 03:33:13]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-01-10 02:33:13]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[multiplies (see also article]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1610245993.0998211;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>94840</wp:comment_id>
			<wp:comment_author><![CDATA[Vitamixmdd]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[ndjokic@shaw.ca]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[74.56.229.191]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-01-11 06:26:12]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-01-11 05:26:12]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[or their samples written]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1610342772.9115479;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>98520</wp:comment_id>
			<wp:comment_author><![CDATA[Vintagedcm]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[farley_dtd@hotmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[114.86.199.135]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-01-25 13:23:10]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-01-25 12:23:10]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[manuscripts attributed to Robins]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1611577390.208128;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>100719</wp:comment_id>
			<wp:comment_author><![CDATA[Holographicfrr]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[marc@sfcontractor.net]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[200.116.226.210]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-02-02 13:41:05]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-02-02 12:41:05]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[manuscripts underwent in the Middle]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1612269665.134203;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>102618</wp:comment_id>
			<wp:comment_author><![CDATA[Vintageohd]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[saj03saj@aol.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[41.169.139.2]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-02-07 04:29:47]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-02-07 03:29:47]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[from a printed book, reproduction]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1612668587.252449;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>128872</wp:comment_id>
			<wp:comment_author><![CDATA[Beaconawj]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[raquelgarcia223@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[92.60.190.249]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-04-17 11:43:59]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-04-17 10:43:59]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[book about the chess of love ", created by]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1618656239.7678831;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>129955</wp:comment_id>
			<wp:comment_author><![CDATA[Rubberfjj]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[epicmotors1@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[43.229.73.230]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-04-19 21:36:51]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-04-19 20:36:51]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Since the era of Charlemagne]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1618864611.5810521;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>131457</wp:comment_id>
			<wp:comment_author><![CDATA[Pouringdgu]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[lauren.miceli@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[120.35.178.96]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-04-25 04:33:28]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-04-25 03:33:28]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[among them acquired "Moral]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1619321608.5004039;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					</item>
					<item>
		<title>Fast refresh of aggregate-only materialized views with SUM - algorithm</title>
		<link>http://www.adellera.it/blog/2013/08/19/fast-refresh-of-aggregate-only-materialized-views-with-sum-algorithm/</link>
		<pubDate>Mon, 19 Aug 2013 12:26:04 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=791</guid>
		<description></description>
		<content:encoded><![CDATA[In this post I will illustrate the algorithm used by Oracle (in 11.2.0.3) to fast refresh a materialized view (MV) containing only the SUM aggregate function:

[sql light="true"]
create materialized view test_mv
build immediate
refresh fast on demand
with rowid
as
select gby        as mv_gby, 
       count(*)   as mv_cnt_star,
       sum  (dat) as mv_sum_dat,
       count(dat) as mv_cnt_dat
  from test_master
 where whe = 0
 group by gby
;
[/sql]

Note that count(dat) is specified - you could avoid that if column dat is constrained to be not-null (as stated in the documentation), but I'm not covering that corner case here.

The MV log is configured to "log everything":
[sql light="true"]
create materialized view log on test_master 
with rowid ( whe, gby, dat ), sequence 
including new values;
[/sql]
 
In the <a href="http://www.adellera.it/blog/2013/08/05/fast-refresh-of-aggregate-only-materialized-views-introduction/">general introduction to aggregate-only MVs</a> we have seen how the refresh engine first marks the log rows, then inspects TMPDLT (loading its rows into the result cache at the same time) to classify its content as insert-only (if it contains only new values), delete-only (if it contains only old values) or general (if it contains a mix of new/old values). Here we illustrate the refreshing SQL in all three scenarios, extracted from the supporting <a href="http://34.247.94.223/wp-content/uploads/2013/08/post_0270_gby_mv_sum.zip">test case</a>.

<b>refresh for insert-only TMPDLT</b>

The refresh is made using this single merge statement:
[sql light="true"]
/* MV_REFRESH (MRG) */ 
merge into test_mv 
using ( 
  with tmpdlt$_test_master as ( 
    -- check introduction post for statement 
  ) 
  select gby, 
         sum( 1 )                           as cnt_star,
         sum( 1 * decode(dat, null, 0, 1) ) as cnt_dat,
         nvl( sum( 1 * dat), 0 )            as sum_dat 
    from (select gby, whe, dat   
            from tmpdlt$_test_master 
         ) as of snapshot(:b_scn)   
   where whe = 0 
   group by gby 
) deltas 
on ( sys_op_map_nonnull(test_mv.mv_gby) = sys_op_map_nonnull(deltas.gby) ) 
when matched then 
  update set 
    test_mv.mv_cnt_star = test_mv.mv_cnt_star + deltas.cnt_star,
    test_mv.mv_cnt_dat  = test_mv.mv_cnt_dat  + deltas.cnt_dat, 
    test_mv.mv_sum_dat  = decode( test_mv.mv_cnt_dat + deltas.cnt_dat,
                                  0, null,
                                  nvl(test_mv.mv_sum_dat,0) + deltas.sum_dat
                                 )
when not matched then 
  insert ( test_mv.mv_gby, test_mv.mv_cnt_dat, test_mv.mv_sum_dat, test_mv.mv_cnt_star ) 
  values ( deltas.gby, deltas.cnt_dat, decode (deltas.cnt_dat, 0, null, deltas.sum_dat), deltas.cnt_star)
[/sql]
It simply calculates the delta values to be propagated by grouping-and-summing the new values contained in TMPDLT that satisfy the where-clause (essentially, it executes the MV statement on the mv log without redundant values), and then looks for matches over the grouped-by expression (using the null-aware function sys_op_map_nonnull, more on this later). It then applies the deltas to the MV, or simply inserts them if no match is found. 

Note that mv_sum_dat (that materializes sum(dat)) is set to null if, and only if, (the updated value of) mv_cnt_dat (that materializes count(dat)) is zero (signaling that for this value of mv_gby, all values of dat in the master table are null). This is done in all three scenarios of the algorithm. 

The matching function sys_op_map_nonnull() is there to match null values with null values, since aggregating by null is perfectly legal, yet you cannot match null with null in a merge/join. This function returns a raw value that is never null, and set to 0xFF when the input is null and to the binary representation of the input postfixed with 0x00 for other input values. Note that a function-based index, named I_SNAP$_TEST_MV in our case, is automatically created on sys_op_map_nonnull(mv_gby) to give the CBO the opportunity to optimize the match (unless the MV is created specifying USING NO INDEX, which is probably almost never a good idea when you need to fast refresh).

Note also that the master table, test_master, is not accessed at all, as it is always the case for SUM (but not necessarily for MAX, as we will see in the next post). This elegant decoupling (possible thanks to the mathematical properties of the addition, of course) of the master table from the MV greatly improves performance and also simplifies performance tuning. 

<b>refresh for delete-only TMPDLT</b>

The refresh is made in two steps, the first being this update statement:
[sql light="true"]
/* MV_REFRESH (UPD) */
update /*+ bypass_ujvc */ (
  select test_mv.mv_cnt_dat, 
         deltas .cnt_dat, 
         test_mv.mv_sum_dat, 
         deltas .sum_dat, 
         test_mv.mv_cnt_star, 
         deltas .cnt_star 
    from test_mv, 
         ( with tmpdlt$_test_master as ( 
             -- check introduction post for statement
           ) 
           select gby, 
                  sum( -1 )                           as cnt_star 
                  sum( -1 * decode(dat, null, 0, 1) ) as cnt_dat, 
                  nvl( sum(-1 * dat), 0)              as sum_dat  
             from (select gby, whe, dat   
                     from tmpdlt$_test_master mas$
                  ) as of snapshot(:b_scn)  
            where whe = 0 
            group by gby 
         ) deltas 
   where sys_op_map_nonnull(test_mv.mv_gby) = sys_op_map_nonnull(deltas.gby)
)  
set mv_cnt_star = mv_cnt_star + cnt_star,
    mv_cnt_dat  = mv_cnt_dat  + cnt_dat, 
    mv_sum_dat  = decode(mv_cnt_dat + cnt_dat, 0, null, nvl(mv_sum_dat,0) + sum_dat) 
[/sql]
this calculates the same deltas as the insert-only case, just with signs reversed since, of course, we are propagating deletes instead of inserts; it then applies them using an updatable join in-line view instead of a merge.

Then, this delete statement is issued:
[sql light="true"]
/* MV_REFRESH (DEL) */
delete from test_mv where mv_cnt_star = 0;
[/sql]
this is because, when mv_cnt_star (that materializes count(*)) is zero after the deltas application, it means that all the rows belonging to that value of mv_gby have been deleted in the master table, and hence that value must be removed from the MV as well.

Note that an index on mv_cnt_star is NOT automatically created (as of 11.2.0.3) - it might be a very good idea to create it, to avoid a full scan of the MV at every refresh, which is O(mv size) and not O(modifications) as the other steps (thus rendering the whole refresh process O(mv size)). 

<b>refresh for mixed-DML TMPDLT</b>

The refresh is accomplished using a single merge statement, which is an augmented version of the insert-only statement plus a delete clause that implements the last part of the delete-only refresh:

[sql light="true"]
/* MV_REFRESH (MRG) */ 
merge into test_mv
using (
 select gby, 
        sum( decode(dml$$, 'I',  1, -1) )                          as cnt_star, 
        sum( decode(dml$$, 'I',  1, -1) * decode(dat, null, 0, 1)) as cnt_dat, 
        nvl( sum(decode(dml$$, 'I',  1, -1) * dat), 0)             as sum_dat 
   from (select chartorowid(m_row$$) rid$, gby, whe, dat, 
                decode(old_new$$, 'N', 'I', 'D') as dml$$, 
                dmltype$$   
           from mlog$_test_master    
          where snaptime$$ &gt; :b_st0
        ) as of snapshot(:b_scn)    
  where whe = 0 
  group by gby 
  ) deltas 
on ( sys_op_map_nonnull(test_mv.mv_gby) = sys_op_map_nonnull(deltas.gby) ) 
when matched then 
  update set 
    test_mv.mv_cnt_star = test_mv.mv_cnt_star + deltas.cnt_star,
    test_mv.mv_cnt_dat  = test_mv.mv_cnt_dat  + deltas.cnt_dat, 
    test_mv.mv_sum_dat  = decode( test_mv.mv_cnt_dat + deltas.cnt_dat,
                                  0, null,
                                  nvl(test_mv.mv_sum_dat,0) + deltas.sum_dat
                                ),        
  delete where ( test_mv.mv_cnt_star = 0 ) 
when not matched then 
  insert ( test_mv.mv_gby, test_mv.mv_cnt_dat, test_mv.mv_sum_dat, test_mv.mv_cnt_star ) 
  values ( deltas.gby, deltas.cnt_dat, decode (deltas.cnt_dat, 0, null, deltas.sum_dat), deltas.cnt_star) 
   where (deltas.cnt_star &gt; 0)
[/sql]
Here the deltas are calculated by reversing the sign of "old" values (dml$$ not equal to 'I', which is the same as old_new$$ not equal to 'N'; note in passing that it does not distinguish between old_new$$ equal to 'O' or 'U', as stated in the introduction post), of course adjusting cnt_star and cnt_dat accordingly. 

The removal of rows that get their mv_cnt_star set to zero is performed as a side case of the update, which is very nice since it does not call for an index on that column. 

Surprisingly, this statement does not use TMPDLT, but reads straight from the log; I don't know the reason behind this, and whether this is always the case or if TMPDLT is sometimes used, depending, perhaps, on some heuristic decision. Surely, while using TMPDLT is mandatory in the other two cases (since the statements work only if their input is insert/delete only, and that is checked over TMPDLT only), it is just a possible optimization choice here. 

<b>optimizations</b>

Knowing the "internal" workings presented here makes it vastly easier (I hope) to optimize the refresh process and avoid pitfalls; it is of course unfeasible to cover all possible real-life scenarios, but I can offer some general high-level considerations.

Obviously, fast refreshing is better than complete refreshing only when the number of modifications stored in the MV log is "small" compared to the MV size. In this scenario the usual optimal values propagation plan reads from the log, computes TMPDLT (when used), and joins the MV using NESTED LOOPS using the (automatically created) index on sys_op_map_nonnull(mv_gby) - or possibly using HASH JOIN, or SORT MERGE JOIN, again using the same index. 

Hence the only optimization worth making is to create the index on mv_cnt_star, unless you can be absolutely sure that you will never be in the delete-only scenario, or unless you don't care about the resulting full MV scan.

Since the master table is never read during the refresh, it can be left alone. This is great.

The best access method for the log is usually a full table scan, since all rows are normally read, and hence usually nothing has to be done on the log. I can imagine that in rare cases one might consider optimizing the log by e.g. creating an index - for example a covering index on all the referenced columns; or one to speed up the analytic functions computations of TMPDLT avoiding the sort; or one prefixed by snaptime$$ if other MVs read from the log and refreshes at different times, etc.

Maybe, sometimes, it might prove beneficial to disable TMPDLT, as discussed in the introduction post.
]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>791</wp:post_id>
		<wp:post_date><![CDATA[2013-08-19 14:26:04]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2013-08-19 12:26:04]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[fast-refresh-of-aggregate-only-materialized-views-with-sum-algorithm]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="materialized-views"><![CDATA[materialized views]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_syntaxhighlighter_encoded]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[franklin-cole-bry36@msn.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[taylor_raymond_mxb92@hotmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>206</wp:comment_id>
			<wp:comment_author><![CDATA[Mary]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[mary.poulson@hp.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[108.51.228.110]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2015-01-09 23:56:43]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2015-01-09 21:56:43]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi, Hoping you may know if a FAST refresh of a query using LISTAGGs is supported in 11.2?  We have successfully created a log and mview that is fast refreshing but non of the actual data shows up until a complete refresh occurs.  We have been modeling the requirements of an aggregate mview (ROWID, COMMIT SCN, SEQUENCE, column list, and INCLUDING NEW VALUES in the log).  We have count(*) and count (column_name) for each of the columns in the mview.  

Any thoughts are appreciated.

Thanks,]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>207</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[89.96.244.51]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2015-01-13 18:17:57]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2015-01-13 16:17:57]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Mary,

unfortunately not, I've never used listagg this way.

What does dbms_mview.explain_mview say ?]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>206</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					</item>
					<item>
		<title>Fast refresh of aggregate-only materialized views with MAX - algorithm</title>
		<link>http://www.adellera.it/blog/2013/08/23/fast-refresh-of-aggregate-only-materialized-views-with-max-algorithm/</link>
		<pubDate>Fri, 23 Aug 2013 12:03:56 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=804</guid>
		<description></description>
		<content:encoded><![CDATA[In this post I will illustrate the algorithm used by Oracle (in 11.2.0.3) to fast refresh a materialized view (MV) containing only the MAX aggregate function:

[sql light="true"]
create materialized view test_mv
build immediate
refresh fast on demand
with rowid
as
select gby        as mv_gby, 
       count(*)   as mv_cnt_star,
       max  (dat) as mv_max_dat
  from test_master
 --where whe = 0
 group by gby
;
[/sql]

The where clause is commented to enable fast refresh whatever type of DML occurs on the master table, in order to investigate all possible scenarios; the case having the where-clause is anywhere a sub-case of the former and we will illustrate it as well below.    

As usual, the MV log is configured to "log everything":
[sql light="true"]
create materialized view log on test_master 
with rowid ( whe, gby, dat ), sequence 
including new values;
[/sql]

In the <a href="http://www.adellera.it/blog/2013/08/05/fast-refresh-of-aggregate-only-materialized-views-introduction/">general introduction to aggregate-only MVs</a> we have seen how the refresh engine first marks the log rows, then inspects TMPDLT (loading its rows into the result cache at the same time) to classify its content as insert-only (if it contains only new values), delete-only (if it contains only old values) or general (if it contains a mix of new/old values). In the MAX scenario, a specialized (and much more performant) algorithm exists only for the insert-only case, and every other case falls back to the general algorithm. 

Let's illustrate, with the help of the usual supporting <a href="http://34.247.94.223/wp-content/uploads/2013/08/post_0280_gby_mv_max.zip">test case</a>, and building on the shoulders of the already illustrated <a href="http://www.adellera.it/blog/2013/08/19/fast-refresh-of-aggregate-only-materialized-views-with-sum-algorithm/">SUM case</a>.

<b>refresh for insert-only TMPDLT</b>

The refresh is made using this single merge statement:
[sql light="true"]
/* MV_REFRESH (MRG) */ 
/* MV_REFRESH (MRG) */ 
merge into test_mv
using ( 
  with tmpdlt$_test_master as  ( 
    -- check introduction post for statement 
  ) 
  select gby, 
         sum( 1 )   as cnt_star,
         max( dat ) as max_dat 
    from (select rid$, gby, dat, dml$$  
            from tmpdlt$_test_master 
         ) as of snapshot(:b_scn) 
    -- where whe = 0 (if the where clause is specified in the MV) 
  group by gby
) deltas
on (sys_op_map_nonnull(test_mv.mv_gby) = sys_op_map_nonnull(deltas.gby)) 
when matched then 
  update set 
    test_mv.mv_cnt_star = test_mv.mv_cnt_star + deltas.cnt_star
    test_mv.mv_max_dat = 
      decode( test_mv.mv_max_dat, 
              null, deltas.max_dat,
              decode( deltas.max_dat, 
                      null, test_mv.mv_max_dat, 
                      greatest( test_mv.mv_max_dat, deltas.max_dat ) 
                    )
            )  
when not matched then 
  insert ( test_mv.mv_gby, test_mv.mv_max_dat, test_mv.mv_cnt_star ) 
  values ( deltas.gby, deltas.max_dat, deltas.cnt_star ) 
[/sql]
Similarly to what it is done for the SUM case, it simply calculates the delta values to be propagated by grouping-and-maximazing the new values contained in TMPDLT (essentially, it executes the MV statement on the filtered mv log), and then looks for matches over the grouped-by expression (using the null-aware function sys_op_map_nonnull, already illustrated in the post about SUM). It then applies the deltas to the MV, or simply inserts them if no match is found. 

The delta application algorithm is very simple: since only inserts have been performed, the MV max(dat) value cannot decrease, but only increase if max(dat) calculated by the deltas is greater. Hence it is simply a matter to set the new value to the greatest of the old and the max of the deltas, with a few decodes to handle nulls in the obvious way.

Note that count(dat)  is not used, and even not present in the MV definition. 

Note especially, as in the SUM case, that the master table, test_master, is not accessed at all - unfortunately that cannot be done for the general case, as we will see shortly.

This algorithm is used also when the where clause is specified in the MV (adding this clause makes the MV an "insert-only MV", as per Oracle definition, which means that can be fast refreshed only after inserts and not after other DML types); the only difference is the obvious addition of the where clause in the deltas calculation as well (as commented in the statement above).

It's also very interesting to remember that this algorithm can be used when only inserts(new values) are present <i>in TMPDLT</i>, not in the log, and hence it can be used <i>even when deletes or inserts are present in the log</i>, provided they are redundant (as seen in the general introduction post). This is especially useful for where-clause MVs, since it widens the possibility to refresh beyond insert-only, as already demonstrated in script tmpdlt_enables_fast_refresh_of_insert_only_mv.sql of the introduction post. 

<b>refresh for mixed-DML TMPDLT</b>

The refresh is accomplished using two statements, a delete that removes every gby value referenced in the log: 
[sql light="true"]
/* MV_REFRESH (DEL) */ 
delete from test_mv
 where sys_op_map_nonnull(mv_gby) in ( 
        select sys_op_map_nonnull(gby) 
          from (select gby   
                  from mlog$_test_master   
                 where snaptime$$ &gt; :b_st0 
               ) as of snapshot(:b_scn) 
       ) 
[/sql]

and an insert that recalculates them reading from the master table:

[sql light="true"]
/* MV_REFRESH (INS) */ 
insert into test_mv 
select gby, count(*), max(dat) 
 from (select gby, dat 
         from test_master  
        where ( sys_op_map_nonnull(gby) ) in ( 
                select sys_op_map_nonnull(gby) 
                  from (select gby, dat   
                          from mlog$_test_master   
                         where snaptime$$ &gt; :b_st0 
                       ) as of snapshot(:b_scn) 
              )
       )   
 group by gby 
[/sql]

This is necessary since a delete(old value) might remove the max value present in the MV, and to know the new max value we must necessarily visit the master table. This might not happen for all log values, but the refresh engine takes the easiest (and drastic) option of deleting and recreating all anyway.

Note that this might result in massive degradation of performance - this algorithm in not O(modifications)  but O(modifications * V), where V is the average number of rows per distinct value of gby, which is generally O(mv size). For example: if your order table doubles in size, you must expect to double the refresh time, even if the number of orders modified is always the same.   

As in the SUM case, a bit surprisingly, this statement does not use TMPDLT, but reads straight from the log; the same observations made for the SUM case apply here as well.

<b>optimizations</b>

The insert-only case is very similar to the SUM case, and thus please refer to the high-level discussion presented there if interested (but, obviously, the creation of the index on mv_cnt_star is not needed in the MAX case). As a side note, one might notice that insert-only algorithms for aggregation are a class of their own, vastly simpler and vastly more performant (and that does not come as a surprise).

The mixed-DML case is another story altogether - to optimize it you must (almost always) create a proper index on the master table. At least the expression sys_op_map_nonnull(gby) must be indexed, but I would strongly advise to create this covering index:

create index test_master_covering on test_master ( sys_op_map_nonnull(gby), gby, dat )

this way everything needed for recalculating a given gby value is neatly clustered in some leaf blocks, instead of being spread out across all the table. You might spare thousands of table block visits if,  as it is quite often the case, you have thousands of rows for each gby values and a bad clustering_factor.

Note also that this index is probably highly compressible, thus adding compress 2 (or even 3, depending on the "dat" column statistic distribution) is a great thing to do as well.

Script gby_max_with_covering_index.sql shows the possible index-only resulting plan:

[sql light="true"]
--------------------------------------------------
|Id|Operation               |Name                |
--------------------------------------------------
| 0|INSERT STATEMENT        |                    |
| 1| LOAD TABLE CONVENTIONAL|                    |
| 2|  HASH GROUP BY         |                    |
| 3|   NESTED LOOPS         |                    |
| 4|    SORT UNIQUE         |                    |
| 5|     TABLE ACCESS FULL  |MLOG$_TEST_MASTER   |
| 6|    INDEX RANGE SCAN    |TEST_MASTER_COVERING|
--------------------------------------------------
[/sql]

For optimizing the log, and disabling TMPDLT, the same considerations made for the SUM case hold.]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>804</wp:post_id>
		<wp:post_date><![CDATA[2013-08-23 14:03:56]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2013-08-23 12:03:56]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[fast-refresh-of-aggregate-only-materialized-views-with-max-algorithm]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="materialized-views"><![CDATA[materialized views]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[milena1285@o2.pl]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_syntaxhighlighter_encoded]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[aurelio-l-todd-rgh08@yahoo.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[orville.banks.gr83@msn.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[jamel-a-lindsey-lve97@msn.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>94197</wp:comment_id>
			<wp:comment_author><![CDATA[viola]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[mitchellramer@cronostv.site]]></wp:comment_author_email>
			<wp:comment_author_url>https://www.qualenumero.info/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.141.66.110]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-01-09 00:26:45]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-01-08 23:26:45]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Presentazione sintetica e vaga, con richieste sempre più puntuali sull'utenza telefonica. Ho stappato molto in fretta.]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1610148405.199574;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					</item>
					<item>
		<title>&quot;ASH math&quot; of time_waited explained with pictures and simulation</title>
		<link>http://www.adellera.it/blog/2016/06/23/ash-math-of-time_waited-explained-with-pictures-and-simulation/</link>
		<pubDate>Thu, 23 Jun 2016 09:41:18 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://www.adellera.it/blog/?p=817</guid>
		<description></description>
		<content:encoded><![CDATA[As explained by John Beresniewicz, Graham Wood and Uri Shaft in their excellent overview <a href="http://www.slideshare.net/jberesni/ash-architecture-and-advanced-usage-rmoug2014-36611678">ASH architecture and advanced usage</a>, avg( v$active_session_history.time_waited ) is not a correct estimate of the average latency (the "true average") esperienced by a wait event, the reason being that short events are less likely to be sampled. In order to correct this, the authors propose a formula that gives an unbiased estimate of the "true average".

In this post I will quantitatively illustrate why sampling is so bad for time_waited, how the formula corrects it, and the sampling "distortion" of "reality" in general, by using an "ASH simulator" I have built and analyzing its data using basic statistic tools (and graphs). I hope that this might help others (as it has definitely helped myself) to better understand the formula and especially the characteristics of this fantastic tool of Oracle named ASH - the one that I use the most nowadays when tuning and troubleshooting, mined by almost every script of my toolbox.

All the code and spools are available <a href="http://34.247.94.223/wp-content/uploads/2016/06/post_0310_ash_math.zip">here</a>.

<b>the simulator</b>

Obviously implemented in PL/SQL, as all great things in life, this pipelined function produces a stream of events:
[sql light="true"]
SQL&gt; select ... from table( sim_pkg.events( ... ) );

SESSION_STATE ELAPSED_USEC
------------- ----------------
WAITING 180,759.713
ON CPU 500,000.000
WAITING 164,796.844
ON CPU 500,000.000
WAITING 2,068,034.610
ON CPU 500,000.000
WAITING 2,720,383.092
ON CPU 500,000.000 [/sql]

It simulates a process that alternates between consuming CPU and waiting for an event; the desired <a href="https://en.wikipedia.org/wiki/Probability_density_function">probability density functions</a> of the two stochastic processes "on cpu" and "waiting" can be passed as arguments.

This stream can then be sampled by pipelining the stream to this other function:
[sql light="true"]
SQL&gt; select ... from table( sim_pkg.samples (
cursor( select * from table( sim_pkg.events( ... ) ) )
);

SAMPLE_ID SAMPLE_TIME SESSION_STATE TIME_WAITED
---------- ----------- ------------- ----------------
0 0 WAITING 180,759.713
1 1000000 ON CPU .000
2 2000000 WAITING .000
3 3000000 WAITING 2,068,034.610
4 4000000 WAITING .000
5 5000000 WAITING .000
6 6000000 WAITING 2,720,383.092
7 7000000 ON CPU .000
[/sql]

Note that the function also reproduces the artificial zeros introduced by ASH's fix-up mechanism (i.e., event with time_waited =2,720,383.092 spans three samples and hence has the two previous samples set to zero; same for its predecessor).
Notice also that one "short" event has been missed by the reaping sampling hand.

<b>investigation by pictures</b>

Let's produce an event stream that follows an uniform distribution on the interval [0 .. 2 sec]; here is its histogram (produced by the wonderful geom_histogram() of R's ggplot2 package):

<a href="http://34.247.94.223/wp-content/uploads/2016/06/events.png"><img class="aligncenter size-full wp-image-825" title="ashevents" src="http://34.247.94.223/wp-content/uploads/2016/06/events.png" alt="histogram of event stream" width="480" height="480" /></a>

So we can visually appreciate and confirm that all events are contained in the requested interval and respect the desired distribution; please also note that the average (the thin dashed vertical line) is almost perfectly equal to the expected value E[ events ] = 1.0.

Let's sample the stream, ignore the artificial zeros, and superimpose the samples' histogram to the previous one:

<a href="http://34.247.94.223/wp-content/uploads/2016/06/combined.png"><img class="aligncenter size-full wp-image-828" title="ashcombined" src="http://34.247.94.223/wp-content/uploads/2016/06/combined.png" alt="histogram of events and samples combined" width="480" height="480" /></a>

So we can see that events longer then the sampling interval T (1sec) are always sampled and hence faithfully represented (the histograms bars match perfectly), but shorter events are not. For example, note that for time_waited = 0.5sec only half of the events are represented - in other words, the probability of being sampled is linearly proportional with time_waited.

More precisely, for time_waited &lt; 1sec, the histogram height of the samples is equal to the histogram height of the events times k * time_waited, with k = 1 / T = 1 / (1.0sec); same for the pdf but with a different value for k. Let's call this the "short waits distortion".

Now check avg(time_waited), the dashed blue line: because of the bias of the samples towards higher values, it overestimates the "true average" by about 0.25 sec. It is actually an almost perfect estimation of the expected value of the samples, that can be calculated by integrating the pdf as being E[samples] = 11/9sec - that unfortunately is nothing we care about, but it confirms the correctness of our analysis.

From the above illustration, it is evident that avg(time_waited) is going to always be an <b>over</b>estimation, regardless of the pdf of the event stream. Hence, it can be never used reliably when tuning of analyzing.

<b>ASH math to the rescue</b>

Since the simulator is written in PL/SQL, we can plug it in place of v$ash in the formula of the unbiased estimator and check its output easily:

[sql light="true"]

TIME_WAITED_AVG TRUE_AVG TIME_WAITED_MATH_USEC ERR_PERC
--------------- ---------------- --------------------- ----------
1221775.3 1,000,428.287 1,001,574.585 .11
[/sql]

So ASH math estimates about 1.001574 sec, extremely close to the true value of 1.000428 sec (an error of only 0.11%). Not bad at all!

The formula has been for sure derived using some statistical tool/theorem that I don't know [ yet ;) ], but its algorithm can be understood intuitively as a way of reversing the above illustrated pdf "short waits distortion" by re-counting events accordingly.

In fact, avg(time_waited) for N samples is, by definition, the ratio of

numerator = sum of time_waited ( i )
denominator = N

The formula uses instead (assuming all time_waited &lt; 1sec for simplicity)

numerator = sum of T = N * 1.0 sec
denominator = sum of T / time_waited ( i )

Note that in both cases the physical dimension of the numerator is time while the denominator is adimensional and has a physical meaning of counts.

The formula corrects the pdf distortion by assuming that, for each sample, we have T / time_waited(i) events in the original stream, all but one escaping the sampling hand (not necessarily in the current i-nth sampling interval, could be in another). E.g. for every observed sample of 0.1 sec there are actually 10 wait events in the original stream, 1 sampled, 9 missed - as we illustrated in the pretty pictures above.

Thus, for each observed sample, the "true" number of counts is not 1, but T / time_waited(i), for a total "true" waited time of time_waited(i) * counts = time_waited(i) * [ T / time_waited(i) ] = T. The formula then simply adds both "true" counts and "true" waited times for all samples.

I don't know why this formula estimator is unbiased, its statistical properties in general and how it was derived - if someone has any information or tip, please chime in. A background but strong interest of mine is to better understand ASH to apply data-mining algorithms to my everyday's tuning efforts, especially to produce prettier pictures ;)]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>817</wp:post_id>
		<wp:post_date><![CDATA[2016-06-23 11:41:18]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2016-06-23 09:41:18]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[open]]></wp:comment_status>
		<wp:ping_status><![CDATA[open]]></wp:ping_status>
		<wp:post_name><![CDATA[ash-math-of-time_waited-explained-with-pictures-and-simulation]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[post]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
										<category domain="category" nicename="ash"><![CDATA[ash]]></category>
		<category domain="category" nicename="ash-math"><![CDATA[ash math]]></category>
						<wp:postmeta>
		<wp:meta_key><![CDATA[_syntaxhighlighter_encoded]]></wp:meta_key>
		<wp:meta_value><![CDATA[1]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_sg_subscribe-to-comments]]></wp:meta_key>
		<wp:meta_value><![CDATA[miroslav.sivon@gmail.com]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_edit_last]]></wp:meta_key>
		<wp:meta_value><![CDATA[2]]></wp:meta_value>
		</wp:postmeta>
							<wp:comment>
			<wp:comment_id>64260</wp:comment_id>
			<wp:comment_author><![CDATA[kyran]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[kyranmckinney@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>https://www.trustpilot.com/review/killer-papers.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[62.149.29.178]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2020-09-18 10:38:16]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2020-09-18 09:38:16]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Welcome Everyone 
Thanks for checking out my writing blog . My name is Kyran Mckinney. 
I have worked  several years  in this niche. My passion for  writing started at a young age. I wrote  journaled as a child and eventually went on to work with my school newspaper. 
This early tryst into  journalism  eventually led me to academic writing. There is plenty of work for  skilled writers. I specialize in dissertations , but have the skills to do all types of academic writing. 
 Email me for more information about rates and a price quote. I’m looking forward to helping you. 
 
Academic Writer – Kyran Mckinney – <a href="https://www.trustpilot.com/review/killer-papers.com" rel="nofollow ugc">Killer Papers</a> Band]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1600421896.8895199;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>69439</wp:comment_id>
			<wp:comment_author><![CDATA[eduard]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[eduardjaramillo32@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>https://manvsclock.com/tips-to-make-remote-work-effective/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[31.28.162.21]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2020-10-08 12:22:05]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2020-10-08 11:22:05]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[My name is Eduard Jaramillo. And I am a professional Content writer with many years of experience in writing. 
 
My main focus is to solve problems related to writing. And I have been doing it for many years. I have been with several organizations as a volunteer and have assisted clients in many ways. 
My love for writing has no end. It is like the air we breathe, something I cherish with all my being. I am a full-time writer who started at an early age. 
I’m happy that I`ve already sold several copies of my works in different countries like Canada and China and others too numerous to mention. 
I also work in a company that provides assistance to many students from different parts of the world. Clients always come to me because I work no matter how hard their projects are. I help them to save time, because I feel happy when people come to me for professional help. 
 
Professional academic Writer – Eduard Jaramillo - <a href="https://manvsclock.com/tips-to-make-remote-work-effective/" / rel="nofollow ugc">Tips to make remote work effective.</a> Team]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1602156125.794414;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>70830</wp:comment_id>
			<wp:comment_author><![CDATA[leonard]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[leonardrossi91@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>https://www.asadeaguia.net/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[185.246.210.154]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2020-10-15 09:55:59]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2020-10-15 08:55:59]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[I’m an expert writer who loves to bring smiles to people's face. 
 
Writing is what I do for a living and I am so passionate about this. I have worked with several companies whose mission is to help people solve writing problems. 
I love traveling and have visited several places in the past few years. 
I’m happy to have written several books that have contributed positively to the lives of many. My books are available in several parts of the world. And I’m currently working with service providers that help people save energy. Being a part of this team has open more opportunities for me to excel as a writer. I have worked with different people and met many clients as a writer. 
I can handle any kind of writing and provide nothing but the best. People come to me all the time to ask if I can solve their writing problems and I accept. I find pleasure in assisting them to solve their problems as a writer. 
 
Professional Writer – Leonard - <a href="https://www.asadeaguia.net/" / rel="nofollow ugc">www.asadeaguia.net</a> Confederation]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1602752159.8285191;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>84712</wp:comment_id>
			<wp:comment_author><![CDATA[Blenderkby]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[jmgsols@bigpond.net.au]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[1.53.137.84]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2020-12-11 07:02:22]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2020-12-11 06:02:22]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[elements (case, binding).]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1607666542.4492731;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>88640</wp:comment_id>
			<wp:comment_author><![CDATA[Sprinklerfki]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[jakjak05@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[223.25.14.66]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2020-12-20 23:29:32]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2020-12-20 22:29:32]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[books in ancient times was papyrus]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1608503372.7597899;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>89302</wp:comment_id>
			<wp:comment_author><![CDATA[kelise]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[kelisehiggins@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.queronaao.com/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[185.246.210.195]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2020-12-22 14:30:17]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2020-12-22 13:30:17]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hello, my name is Nannie! 
 
I`m a professional writer and I`m going to change your lifes onсe and for all 
Writing has been my passion since early years and now I cannot imagine my life without it. 
Most of my works were sold throughout  Canada, USA, Old England and even India. Also I`m working with services that help people to save their nerves. 
People ask me "Sir, Nannie Morris, I need your professional help" and I always accept the request, `cause I know, that only I can solve all their problems! 
 
Academic Writer - Nannie - <a href="http://www.queronaao.com/" / rel="nofollow ugc">www.queronaao.com</a> Corps]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1608643817.571811;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>89325</wp:comment_id>
			<wp:comment_author><![CDATA[reema]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[reemabright704@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>https://www.leadershipeducationnelenhaiti.com/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[185.246.208.38]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2020-12-22 15:34:30]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2020-12-22 14:34:30]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hello  and welcome to my blog . I’m Reema. 
I have always dreamed of being a  book writer  but never dreamed I’d make a career of it. In college, though, I  assisted a fellow student who needed help. She could not stop  telling me how well I had done. Word got around and someone asked me for  to write their paper just a week later. This time they would pay me  for my work. 
During the summer, I started doing academic writing  for students at the local college. It helped me have fun that summer and even funded some of my college tuition. Today, I still offer my  research paper writing  to students. 
 
 Academic Writer  – Reema Bright – <a href="https://www.leadershipeducationnelenhaiti.com/" / rel="nofollow ugc">www.leadershipeducationnelenhaiti.com</a>Team]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1608647670.2710011;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>90017</wp:comment_id>
			<wp:comment_author><![CDATA[aedan]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[aedanireland@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://simonnejones.org/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[31.28.162.57]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2020-12-24 09:57:56]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2020-12-24 08:57:56]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hello, I am Eduard an expert in report writing. 
 
I enjoy solving people’s problems and make them happy. That is what I have been doing for many years now. 
I have been writing since I was 12 years old and never knew it would turn out to be a full-time career. I have also been able to manage several projects that involves writing. And I worked in three organizations as a volunteer to assist people.My interest has always been to help people succeed. And I go the extra mile to make that happen. 
I enjoy writing Thesis and have helped people from countries like Australia. 
I work with a service provider whose mission is to provide quality writing and make people happy. In fact, many students come to me for help on a daily basis because they know I always deliver. And I will continue to provide nothing but the best to build trust like I have been doing for the past few years. 
 
Academic writer - Eduard - <a href="http://simonnejones.org/" / rel="nofollow ugc">simonnejones.org</a> Corp]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1608800276.1863639;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>93861</wp:comment_id>
			<wp:comment_author><![CDATA[Batteriesfvi]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[bonsaidriven@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[18.231.50.194]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-01-07 22:07:53]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-01-07 21:07:53]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[55 thousand Greek, 30 thousand Armenian]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1610053673.3620679;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>94115</wp:comment_id>
			<wp:comment_author><![CDATA[Interfaceugs]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[carajurus@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[61.7.138.187]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-01-08 19:02:17]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-01-08 18:02:17]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[reproduced by hand, in contrast]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1610128937.0903649;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>96815</wp:comment_id>
			<wp:comment_author><![CDATA[adnan]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[chestermcarthur589@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>https://apnews.com/press-release/kisspr/technology-entertainment-search-technology-books-and-literature-arts-and-entertainment-f49c4853367a0bbf0a8ab1aded328cc2</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[84.17.55.5]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-01-19 10:46:38]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-01-19 09:46:38]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Thanks for visiting, 
I’m Adnan Underwood. 
If you’ve ever been too busy  and couldn’t finish a research assignment , then you’ve come to the right place. I  assist students in all areas of the writing  technique. I can also write the  essay  from start to finish. 
My career as  a professional writer started  early in college . After learning that I was very capable  in the field of academic writing, I decided to take it up as a  profession. 
 
 Skilled  Academic Writer- Adnan Underwood-  <a href="https://apnews.com/press-release/kisspr/technology-entertainment-search-technology-books-and-literature-arts-and-entertainment-f49c4853367a0bbf0a8ab1aded328cc2" rel="nofollow ugc">Write My Essay For Me, Please! – These Websites Will Help</a> Corps]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1611049598.2587581;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>97577</wp:comment_id>
			<wp:comment_author><![CDATA[Nespressorku]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[sdf@sdf.c]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[205.160.110.44]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-01-22 02:46:49]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-01-22 01:46:49]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[the best poets of his era and]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1611280009.8730371;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>100129</wp:comment_id>
			<wp:comment_author><![CDATA[Epiphonests]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[omahatrenching@yahoo.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[124.41.240.66]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-01-31 12:43:31]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-01-31 11:43:31]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[By the end of the 15th century, 35]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1612093411.3173039;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>101487</wp:comment_id>
			<wp:comment_author><![CDATA[Infraredwnb]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[kinderkidz@ndsupernet.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[118.173.66.131]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-02-04 14:37:56]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-02-04 13:37:56]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Century to a kind of destruction:]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1612445876.0370929;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>102418</wp:comment_id>
			<wp:comment_author><![CDATA[Boschjnw]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[a7xlover881@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url></wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[1.70.65.80]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-02-06 18:32:51]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-02-06 17:32:51]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Middle Ages as in Western]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1612632771.27897;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>112212</wp:comment_id>
			<wp:comment_author><![CDATA[camden]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[camdenpatton3@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>https://www.tacofactoryinc.com/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[84.17.55.9]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2021-03-05 10:05:56]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2021-03-05 09:05:56]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[My name is Camden Patton. And I am a professional academic writer with many years of experience in writing. 
 
My interest is to solve problems related to writing. And I have been doing it for many years. I have been with several organizations as a volunteer and have assisted people in many ways. 
My love for writing has no end. It is like the air we breathe, something I cherish with all my being. I am a full-time writer who started at an early age. 
I’m happy that I`ve already sold several copies of my poems in different countries like USA, Russia and others too numerous to mention. 
I also work in a company that provides assistance to many clients from different parts of the world. Students always come to me because I work no matter how difficult their projects are. I help them to save time, because I feel fulfilled when people come to me for writing help. 
 
Ghost Writer – Camden -  <a href="https://www.tacofactoryinc.com/" / rel="nofollow ugc">www.tacofactoryinc.com</a> Corp]]></wp:comment_content>
			<wp:comment_approved><![CDATA[0]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1614935156.8510799;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>208</wp:comment_id>
			<wp:comment_author><![CDATA[Randolf Geist]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[mahrah@web.de]]></wp:comment_author_email>
			<wp:comment_author_url>http://oracle-randolf.blogspot.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[77.176.241.105]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2016-08-06 13:03:46]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2016-08-06 11:03:46]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Hi Alberto,

thanks for publishing this - very helpful! I might add the formula to my XPLAN_ASH script to arrive at more meaningful average wait times derived from the sampled wait times.

Very concise implementation using your "ASH simulator"!

Cheers,
Randolf]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>209</wp:comment_id>
			<wp:comment_author><![CDATA[Alberto Dell'Era]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alberto.dellera@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://www.adellera.it</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[93.33.137.67]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2016-08-06 19:57:40]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2016-08-06 17:57:40]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[Thanks, Randolf ;)]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>208</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>14659</wp:comment_id>
			<wp:comment_author><![CDATA[Shana]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[arleen_landseer@aol.com]]></wp:comment_author_email>
			<wp:comment_author_url>https://twitter.com/londoncleopatra</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[194.88.143.36]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2020-03-03 05:56:22]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2020-03-03 04:56:22]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[I savour, lead tto I discovered just what I was looking for.

You have ended my 4 day lengthy hunt! God Bless you man. Have a nice day.Bye]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1583211382.4168041;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:3:{s:4:"time";d:1598802482.731286;s:5:"event";s:15:"status-approved";s:4:"user";s:15:"alberto.dellera";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>14756</wp:comment_id>
			<wp:comment_author><![CDATA[jjbi couple]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[alvabundey@googlemail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://jjbicouple.fun/reviews/</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[5.180.220.124]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2020-03-03 13:30:14]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2020-03-03 12:30:14]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[This is the right website for everyone who hopes too understand this topic.
You understand a whole lot its almot hard to argue witth you (not 
that I really will need to…HaHa). You certainly put a brand new spin on a subject 
that's been written about for decades. Wonderful stuff, just wonderful!]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1583238614.04059;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:3:{s:4:"time";d:1598802481.1144581;s:5:"event";s:15:"status-approved";s:4:"user";s:15:"alberto.dellera";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					<wp:comment>
			<wp:comment_id>26514</wp:comment_id>
			<wp:comment_author><![CDATA[Silke]]></wp:comment_author>
			<wp:comment_author_email><![CDATA[ferdinandbroderick@gmail.com]]></wp:comment_author_email>
			<wp:comment_author_url>http://wwayoverthenew.com</wp:comment_author_url>
			<wp:comment_author_IP><![CDATA[154.16.10.228]]></wp:comment_author_IP>
			<wp:comment_date><![CDATA[2020-04-25 03:27:47]]></wp:comment_date>
			<wp:comment_date_gmt><![CDATA[2020-04-25 02:27:47]]></wp:comment_date_gmt>
			<wp:comment_content><![CDATA[It's difficult to find well-informed people on this subject, but you sound like you know what you're talking about!
Thanks]]></wp:comment_content>
			<wp:comment_approved><![CDATA[1]]></wp:comment_approved>
			<wp:comment_type><![CDATA[comment]]></wp:comment_type>
			<wp:comment_parent>0</wp:comment_parent>
			<wp:comment_user_id>0</wp:comment_user_id>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_result]]></wp:meta_key>
			<wp:meta_value><![CDATA[false]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:2:{s:4:"time";d:1587781667.199162;s:5:"event";s:9:"check-ham";}]]></wp:meta_value>
			</wp:commentmeta>
						<wp:commentmeta>
	<wp:meta_key><![CDATA[akismet_history]]></wp:meta_key>
			<wp:meta_value><![CDATA[a:3:{s:4:"time";d:1598802470.06286;s:5:"event";s:15:"status-approved";s:4:"user";s:15:"alberto.dellera";}]]></wp:meta_value>
			</wp:commentmeta>
							</wp:comment>
					</item>
					<item>
		<title>Contact form 1</title>
		<link>http://www.adellera.it/?post_type=wpcf7_contact_form&#038;p=861</link>
		<pubDate>Sun, 06 May 2018 09:10:11 +0000</pubDate>
		<dc:creator><![CDATA[alberto.dellera]]></dc:creator>
		<guid isPermaLink="false">http://34.247.94.223/?post_type=wpcf7_contact_form&#038;p=861</guid>
		<description></description>
		<content:encoded><![CDATA[<label> Your Name (required)
    [text* your-name] </label>

<label> Your Email (required)
    [email* your-email] </label>

<label> Subject
    [text your-subject] </label>

<label> Your Message
    [textarea your-message] </label>

[submit "Send"]
Alberto Dell&#039;Era&#039;s blog "[your-subject]"
[your-name] <wordpress@34.247.94.223>
From: [your-name] <[your-email]>
Subject: [your-subject]

Message Body:
[your-message]

-- 
This e-mail was sent from a contact form on Alberto Dell&#039;Era&#039;s blog (http://34.247.94.223)
user@example.com
Reply-To: [your-email]

0
0

Alberto Dell&#039;Era&#039;s blog "[your-subject]"
Alberto Dell&#039;Era&#039;s blog <wordpress@34.247.94.223>
Message Body:
[your-message]

-- 
This e-mail was sent from a contact form on Alberto Dell&#039;Era&#039;s blog (http://34.247.94.223)
[your-email]
Reply-To: user@example.com

0
0
Thank you for your message. It has been sent.
There was an error trying to send your message. Please try again later.
One or more fields have an error. Please check and try again.
There was an error trying to send your message. Please try again later.
You must accept the terms and conditions before sending your message.
The field is required.
The field is too long.
The field is too short.]]></content:encoded>
		<excerpt:encoded><![CDATA[]]></excerpt:encoded>
		<wp:post_id>861</wp:post_id>
		<wp:post_date><![CDATA[2018-05-06 10:10:11]]></wp:post_date>
		<wp:post_date_gmt><![CDATA[2018-05-06 09:10:11]]></wp:post_date_gmt>
		<wp:comment_status><![CDATA[closed]]></wp:comment_status>
		<wp:ping_status><![CDATA[closed]]></wp:ping_status>
		<wp:post_name><![CDATA[contact-form-1]]></wp:post_name>
		<wp:status><![CDATA[publish]]></wp:status>
		<wp:post_parent>0</wp:post_parent>
		<wp:menu_order>0</wp:menu_order>
		<wp:post_type><![CDATA[wpcf7_contact_form]]></wp:post_type>
		<wp:post_password><![CDATA[]]></wp:post_password>
		<wp:is_sticky>0</wp:is_sticky>
														<wp:postmeta>
		<wp:meta_key><![CDATA[_form]]></wp:meta_key>
		<wp:meta_value><![CDATA[<label> Your Name (required)
    [text* your-name] </label>

<label> Your Email (required)
    [email* your-email] </label>

<label> Subject
    [text your-subject] </label>

<label> Your Message
    [textarea your-message] </label>

[submit "Send"]]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_mail]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:8:{s:7:"subject";s:50:"Alberto Dell&#039;Era&#039;s blog "[your-subject]"";s:6:"sender";s:37:"[your-name] <wordpress@34.247.94.223>";s:4:"body";s:192:"From: [your-name] <[your-email]>
Subject: [your-subject]

Message Body:
[your-message]

-- 
This e-mail was sent from a contact form on Alberto Dell&#039;Era&#039;s blog (http://34.247.94.223)";s:9:"recipient";s:16:"user@example.com";s:18:"additional_headers";s:22:"Reply-To: [your-email]";s:11:"attachments";s:0:"";s:8:"use_html";i:0;s:13:"exclude_blank";i:0;}]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_mail_2]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:9:{s:6:"active";b:0;s:7:"subject";s:50:"Alberto Dell&#039;Era&#039;s blog "[your-subject]"";s:6:"sender";s:59:"Alberto Dell&#039;Era&#039;s blog <wordpress@34.247.94.223>";s:4:"body";s:134:"Message Body:
[your-message]

-- 
This e-mail was sent from a contact form on Alberto Dell&#039;Era&#039;s blog (http://34.247.94.223)";s:9:"recipient";s:12:"[your-email]";s:18:"additional_headers";s:26:"Reply-To: user@example.com";s:11:"attachments";s:0:"";s:8:"use_html";i:0;s:13:"exclude_blank";i:0;}]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_messages]]></wp:meta_key>
		<wp:meta_value><![CDATA[a:8:{s:12:"mail_sent_ok";s:45:"Thank you for your message. It has been sent.";s:12:"mail_sent_ng";s:71:"There was an error trying to send your message. Please try again later.";s:16:"validation_error";s:61:"One or more fields have an error. Please check and try again.";s:4:"spam";s:71:"There was an error trying to send your message. Please try again later.";s:12:"accept_terms";s:69:"You must accept the terms and conditions before sending your message.";s:16:"invalid_required";s:22:"The field is required.";s:16:"invalid_too_long";s:22:"The field is too long.";s:17:"invalid_too_short";s:23:"The field is too short.";}]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_additional_settings]]></wp:meta_key>
		<wp:meta_value><![CDATA[]]></wp:meta_value>
		</wp:postmeta>
							<wp:postmeta>
		<wp:meta_key><![CDATA[_locale]]></wp:meta_key>
		<wp:meta_value><![CDATA[en_US]]></wp:meta_value>
		</wp:postmeta>
							</item>
				</channel>
</rss>
	